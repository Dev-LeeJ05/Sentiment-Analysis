{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c84beab-fdd3-4b92-b4ff-53216eb51626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from WordPieceTokenizer import WordPieceTokenizer as Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "dataFilePath = 'datasets/'\n",
    "saveFilePath = 'saves/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = Tokenizer(f'{dataFilePath}vocab.txt',do_lower_case=False,strip_accents=False,clean_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da38b69e-5ccd-4751-a66e-934077285c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화</th>\n",
       "      <th>감정</th>\n",
       "      <th>str_len</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 22 15163 5775 5784 10815 5784 15645 22483 13...</td>\n",
       "      <td>불안</td>\n",
       "      <td>24</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 22 30858 21623 16553 5776 14727 5775 5783 13...</td>\n",
       "      <td>불안</td>\n",
       "      <td>12</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 22 18064 21623 14268 5780 5776 14268 5780 58...</td>\n",
       "      <td>불안</td>\n",
       "      <td>14</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 22 13605 27417 10815 21884 5780 18064 5775 5...</td>\n",
       "      <td>불안</td>\n",
       "      <td>13</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 22 10850 14633 5883 29724 24527 14219 5775 5...</td>\n",
       "      <td>불안</td>\n",
       "      <td>11</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  발화  감정  str_len  \\\n",
       "0  2 22 15163 5775 5784 10815 5784 15645 22483 13...  불안       24   \n",
       "1  2 22 30858 21623 16553 5776 14727 5775 5783 13...  불안       12   \n",
       "2  2 22 18064 21623 14268 5780 5776 14268 5780 58...  불안       14   \n",
       "3  2 22 13605 27417 10815 21884 5780 18064 5775 5...  불안       13   \n",
       "4  2 22 10850 14633 5883 29724 24527 14219 5775 5...  불안       11   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "1  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "2  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "3  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "4  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...   \n",
       "\n",
       "                                      token_type_ids  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{dataFilePath}sentiment_train.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b88c422-88f4-4e80-9f82-53fdcb86b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['감정'] == '불안'),'감정'] = 0\n",
    "df.loc[(df['감정'] == '당황'),'감정'] = 1\n",
    "df.loc[(df['감정'] == '분노'),'감정'] = 2\n",
    "df.loc[(df['감정'] == '슬픔'),'감정'] = 3\n",
    "df.loc[(df['감정'] == '중립'),'감정'] = 4\n",
    "df.loc[(df['감정'] == '행복'),'감정'] = 5\n",
    "df.loc[(df['감정'] == '혐오'),'감정'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404c17eb-9dbf-4369-81f5-218c8a2be20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(data_frame, device,batch_size,shuffle=False):\n",
    "\n",
    "    tensor_x_list = []\n",
    "    attentions = []\n",
    "    for i in tqdm(range(len(data_frame))):\n",
    "        token = data_frame.iloc[i,0]\n",
    "        token = token.split(\" \")\n",
    "        token_list = []\n",
    "        for t in token:\n",
    "            token_list.append(int(t))\n",
    "        tensor_x_list.append(token_list)\n",
    "        \n",
    "        attention = data_frame.iloc[i,3]\n",
    "        attention = attention.split(\" \")\n",
    "        attention_list = []\n",
    "        for a in attention:\n",
    "            attention_list.append(int(a))\n",
    "        attentions.append(attention_list)\n",
    "\n",
    "    tensor_x = torch.tensor(tensor_x_list, dtype=torch.long, device=device)\n",
    "    tensor_attention = torch.tensor(attentions, dtype=torch.long, device=device)\n",
    "    tensor_t = torch.tensor(data_frame[\"감정\"].values.tolist(), dtype=torch.long, device=device)\n",
    "\n",
    "    print(len(tensor_x))\n",
    "    print(len(tensor_attention))\n",
    "    print(len(tensor_t))\n",
    "    \n",
    "    dataset = TensorDataset(tensor_x,tensor_attention,tensor_t)\n",
    "\n",
    "    loader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=True)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5776764d-05d3-46df-909d-2bc90d0f23ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트의 크기: 131713 행\n",
      "검증 세트의 크기: 14635 행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 131713/131713 [00:08<00:00, 15944.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131713\n",
      "131713\n",
      "131713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 14635/14635 [00:00<00:00, 17409.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14635\n",
      "14635\n",
      "14635\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df,train_size=0.9,test_size=0.1)\n",
    "\n",
    "print(f\"학습 세트의 크기: {len(train_df)} 행\")\n",
    "print(f\"검증 세트의 크기: {len(test_df)} 행\")\n",
    "\n",
    "train_loader = process_dataframe(train_df,device,200,True)\n",
    "test_loader = process_dataframe(test_df,device,1000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d111445-7445-4928-bd86-aaf64728a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import LSTM\n",
    "\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a68f657-9e9f-47d8-b477-2cb4ec4601f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch   1\t\tloss 1.587521802872\tacc 0.4457\tcnt 0\n",
      "\tepoch   2\t\tloss 1.498288842320\tacc 0.4563\tcnt 0\n",
      "\tepoch   3\t\tloss 1.472316711145\tacc 0.4601\tcnt 0\n",
      "\tepoch   4\t\tloss 1.446897592226\tacc 0.4743\tcnt 0\n",
      "\tepoch   5\t\tloss 1.421060779718\tacc 0.4878\tcnt 0\n",
      "\tepoch   6\t\tloss 1.397209973502\tacc 0.4729\tcnt 1\n",
      "\tepoch   7\t\tloss 1.378084034362\tacc 0.5079\tcnt 0\n",
      "\tepoch   8\t\tloss 1.360398544367\tacc 0.5185\tcnt 0\n",
      "\tepoch   9\t\tloss 1.345776856489\tacc 0.5188\tcnt 0\n",
      "\tepoch   10\t\tloss 1.332008816189\tacc 0.5272\tcnt 0\n",
      "\tepoch   11\t\tloss 1.318728181185\tacc 0.5396\tcnt 0\n",
      "\tepoch   12\t\tloss 1.307750316195\tacc 0.5420\tcnt 0\n",
      "\tepoch   13\t\tloss 1.299310188525\tacc 0.5484\tcnt 0\n",
      "\tepoch   14\t\tloss 1.285288080075\tacc 0.5472\tcnt 1\n",
      "\tepoch   15\t\tloss 1.278482861794\tacc 0.5516\tcnt 0\n",
      "\tepoch   16\t\tloss 1.268268342257\tacc 0.5577\tcnt 0\n",
      "\tepoch   17\t\tloss 1.262701432031\tacc 0.5601\tcnt 0\n",
      "\tepoch   18\t\tloss 1.253973746372\tacc 0.5649\tcnt 0\n",
      "\tepoch   19\t\tloss 1.247832800480\tacc 0.5642\tcnt 1\n",
      "\tepoch   20\t\tloss 1.239673898213\tacc 0.5677\tcnt 0\n",
      "\tepoch   21\t\tloss 1.234709841321\tacc 0.5709\tcnt 0\n",
      "\tepoch   22\t\tloss 1.230709721433\tacc 0.5718\tcnt 0\n",
      "\tepoch   23\t\tloss 1.222177870368\tacc 0.5748\tcnt 0\n",
      "\tepoch   24\t\tloss 1.218993007503\tacc 0.5750\tcnt 0\n",
      "\tepoch   25\t\tloss 1.214634656906\tacc 0.5766\tcnt 0\n",
      "\tepoch   26\t\tloss 1.209452467396\tacc 0.5765\tcnt 1\n",
      "\tepoch   27\t\tloss 1.205367648493\tacc 0.5767\tcnt 0\n",
      "\tepoch   28\t\tloss 1.202164733664\tacc 0.5817\tcnt 0\n",
      "\tepoch   29\t\tloss 1.197434854725\tacc 0.5826\tcnt 0\n",
      "\tepoch   30\t\tloss 1.194661532311\tacc 0.5814\tcnt 1\n",
      "\tepoch   31\t\tloss 1.190457149117\tacc 0.5849\tcnt 0\n",
      "\tepoch   32\t\tloss 1.185097271095\tacc 0.5899\tcnt 0\n",
      "\tepoch   33\t\tloss 1.183931103593\tacc 0.5919\tcnt 0\n",
      "\tepoch   34\t\tloss 1.179152852858\tacc 0.5944\tcnt 0\n",
      "\tepoch   35\t\tloss 1.174890489654\tacc 0.5952\tcnt 0\n",
      "\tepoch   36\t\tloss 1.171738320662\tacc 0.6014\tcnt 0\n",
      "\tepoch   37\t\tloss 1.165915350874\tacc 0.6032\tcnt 0\n",
      "\tepoch   38\t\tloss 1.161100565300\tacc 0.6072\tcnt 0\n",
      "\tepoch   39\t\tloss 1.159094184184\tacc 0.6069\tcnt 1\n",
      "\tepoch   40\t\tloss 1.155890172919\tacc 0.6099\tcnt 0\n",
      "\tepoch   41\t\tloss 1.152458207404\tacc 0.6093\tcnt 1\n",
      "\tepoch   42\t\tloss 1.150664269018\tacc 0.6138\tcnt 0\n",
      "\tepoch   43\t\tloss 1.144788848412\tacc 0.6156\tcnt 0\n",
      "\tepoch   44\t\tloss 1.141071862635\tacc 0.6164\tcnt 0\n",
      "\tepoch   45\t\tloss 1.139992254302\tacc 0.6180\tcnt 0\n",
      "\tepoch   46\t\tloss 1.134861233749\tacc 0.6176\tcnt 1\n",
      "\tepoch   47\t\tloss 1.132365623778\tacc 0.6176\tcnt 2\n",
      "\tepoch   48\t\tloss 1.129653429731\tacc 0.6211\tcnt 0\n",
      "\tepoch   49\t\tloss 1.127486484301\tacc 0.6215\tcnt 0\n",
      "\tepoch   50\t\tloss 1.125465410368\tacc 0.6221\tcnt 0\n",
      "\tepoch   51\t\tloss 1.123743273114\tacc 0.6219\tcnt 1\n",
      "\tepoch   52\t\tloss 1.120338046261\tacc 0.6255\tcnt 0\n",
      "\tepoch   53\t\tloss 1.117140505723\tacc 0.6272\tcnt 0\n",
      "\tepoch   54\t\tloss 1.113553243568\tacc 0.6279\tcnt 0\n",
      "\tepoch   55\t\tloss 1.110871479051\tacc 0.6269\tcnt 1\n",
      "\tepoch   56\t\tloss 1.109136085289\tacc 0.6303\tcnt 0\n",
      "\tepoch   57\t\tloss 1.108503257069\tacc 0.6309\tcnt 0\n",
      "\tepoch   58\t\tloss 1.104849889557\tacc 0.6291\tcnt 1\n",
      "\tepoch   59\t\tloss 1.104977561529\tacc 0.6324\tcnt 0\n",
      "\tepoch   60\t\tloss 1.102028253412\tacc 0.6328\tcnt 0\n",
      "\tepoch   61\t\tloss 1.098962058141\tacc 0.6337\tcnt 0\n",
      "\tepoch   62\t\tloss 1.097249926767\tacc 0.6324\tcnt 1\n",
      "\tepoch   63\t\tloss 1.094698774054\tacc 0.6335\tcnt 2\n",
      "\tepoch   64\t\tloss 1.093382791908\tacc 0.6344\tcnt 0\n",
      "\tepoch   65\t\tloss 1.091774556865\tacc 0.6369\tcnt 0\n",
      "\tepoch   66\t\tloss 1.091671982525\tacc 0.6369\tcnt 0\n",
      "\tepoch   67\t\tloss 1.090018809566\tacc 0.6352\tcnt 1\n",
      "\tepoch   68\t\tloss 1.089840159590\tacc 0.6375\tcnt 0\n",
      "\tepoch   69\t\tloss 1.086036322327\tacc 0.6370\tcnt 1\n",
      "\tepoch   70\t\tloss 1.084470391183\tacc 0.6375\tcnt 0\n",
      "\tepoch   71\t\tloss 1.082462929031\tacc 0.6341\tcnt 1\n",
      "\tepoch   72\t\tloss 1.081347481911\tacc 0.6384\tcnt 0\n",
      "\tepoch   73\t\tloss 1.080816935442\tacc 0.6389\tcnt 0\n",
      "\tepoch   74\t\tloss 1.079665055210\tacc 0.6384\tcnt 1\n",
      "\tepoch   75\t\tloss 1.078895720667\tacc 0.6423\tcnt 0\n",
      "\tepoch   76\t\tloss 1.077653238114\tacc 0.6410\tcnt 1\n",
      "\tepoch   77\t\tloss 1.074395800253\tacc 0.6379\tcnt 2\n",
      "\tepoch   78\t\tloss 1.074414743569\tacc 0.6428\tcnt 0\n",
      "\tepoch   79\t\tloss 1.072888225498\tacc 0.6426\tcnt 1\n",
      "\tepoch   80\t\tloss 1.071537792230\tacc 0.6429\tcnt 0\n",
      "\tepoch   81\t\tloss 1.072387316488\tacc 0.6426\tcnt 1\n",
      "\tepoch   82\t\tloss 1.070209472919\tacc 0.6423\tcnt 2\n",
      "\tepoch   83\t\tloss 1.069430516031\tacc 0.6453\tcnt 0\n",
      "\tepoch   84\t\tloss 1.069552899041\tacc 0.6457\tcnt 0\n",
      "\tepoch   85\t\tloss 1.067521292026\tacc 0.6460\tcnt 0\n",
      "\tepoch   86\t\tloss 1.067858114703\tacc 0.6453\tcnt 1\n",
      "\tepoch   87\t\tloss 1.066049525531\tacc 0.6458\tcnt 2\n",
      "\tepoch   88\t\tloss 1.064113218190\tacc 0.6479\tcnt 0\n",
      "\tepoch   89\t\tloss 1.062371253333\tacc 0.6478\tcnt 1\n",
      "\tepoch   90\t\tloss 1.062994556677\tacc 0.6480\tcnt 0\n",
      "\tepoch   91\t\tloss 1.060114511694\tacc 0.6466\tcnt 1\n",
      "\tepoch   92\t\tloss 1.058606451496\tacc 0.6477\tcnt 2\n",
      "\tepoch   93\t\tloss 1.058172173957\tacc 0.6493\tcnt 0\n",
      "\tepoch   94\t\tloss 1.056803046208\tacc 0.6491\tcnt 1\n",
      "\tepoch   95\t\tloss 1.059541809885\tacc 0.6473\tcnt 2\n",
      "\tepoch   96\t\tloss 1.056181970338\tacc 0.6491\tcnt 3\n",
      "\tepoch   97\t\tloss 1.056086345828\tacc 0.6504\tcnt 0\n",
      "\tepoch   98\t\tloss 1.054810230946\tacc 0.6508\tcnt 0\n",
      "\tepoch   99\t\tloss 1.053054582294\tacc 0.6515\tcnt 0\n",
      "\tepoch   100\t\tloss 1.052348276674\tacc 0.6512\tcnt 1\n",
      "\tepoch   101\t\tloss 1.052170639433\tacc 0.6523\tcnt 0\n",
      "\tepoch   102\t\tloss 1.050988859228\tacc 0.6516\tcnt 1\n",
      "\tepoch   103\t\tloss 1.051194731769\tacc 0.6486\tcnt 2\n",
      "\tepoch   104\t\tloss 1.052327963266\tacc 0.6519\tcnt 3\n",
      "\tepoch   105\t\tloss 1.048284247382\tacc 0.6514\tcnt 4\n",
      "\tepoch   106\t\tloss 1.048212878338\tacc 0.6531\tcnt 0\n",
      "\tepoch   107\t\tloss 1.049130641309\tacc 0.6516\tcnt 1\n",
      "\tepoch   108\t\tloss 1.047262576847\tacc 0.6535\tcnt 0\n",
      "\tepoch   109\t\tloss 1.046457746652\tacc 0.6510\tcnt 1\n",
      "\tepoch   110\t\tloss 1.047387884018\tacc 0.6543\tcnt 0\n",
      "\tepoch   111\t\tloss 1.046083157276\tacc 0.6540\tcnt 1\n",
      "\tepoch   112\t\tloss 1.045234232507\tacc 0.6500\tcnt 2\n",
      "\tepoch   113\t\tloss 1.045079906480\tacc 0.6534\tcnt 3\n",
      "\tepoch   114\t\tloss 1.043222231253\tacc 0.6556\tcnt 0\n",
      "\tepoch   115\t\tloss 1.042698366301\tacc 0.6528\tcnt 1\n",
      "\tepoch   116\t\tloss 1.043480513034\tacc 0.6559\tcnt 0\n",
      "\tepoch   117\t\tloss 1.041872802748\tacc 0.6550\tcnt 1\n",
      "\tepoch   118\t\tloss 1.040308129643\tacc 0.6542\tcnt 2\n",
      "\tepoch   119\t\tloss 1.040892518672\tacc 0.6547\tcnt 3\n",
      "\tepoch   120\t\tloss 1.038453443616\tacc 0.6542\tcnt 4\n",
      "\tepoch   121\t\tloss 1.038496320280\tacc 0.6560\tcnt 0\n",
      "\tepoch   122\t\tloss 1.038926573148\tacc 0.6571\tcnt 0\n",
      "\tepoch   123\t\tloss 1.038767407006\tacc 0.6567\tcnt 1\n",
      "\tepoch   124\t\tloss 1.037833708488\tacc 0.6554\tcnt 2\n",
      "\tepoch   125\t\tloss 1.035205978662\tacc 0.6561\tcnt 3\n",
      "\tepoch   126\t\tloss 1.038282094755\tacc 0.6573\tcnt 0\n",
      "\tepoch   127\t\tloss 1.036065444486\tacc 0.6560\tcnt 1\n",
      "\tepoch   128\t\tloss 1.034944378949\tacc 0.6583\tcnt 0\n",
      "\tepoch   129\t\tloss 1.037434232634\tacc 0.6566\tcnt 1\n",
      "\tepoch   130\t\tloss 1.034973034380\tacc 0.6578\tcnt 2\n",
      "\tepoch   131\t\tloss 1.035213694112\tacc 0.6594\tcnt 0\n",
      "\tepoch   132\t\tloss 1.033472101920\tacc 0.6567\tcnt 1\n",
      "\tepoch   133\t\tloss 1.035145321968\tacc 0.6582\tcnt 2\n",
      "\tepoch   134\t\tloss 1.033477510181\tacc 0.6585\tcnt 3\n",
      "\tepoch   135\t\tloss 1.034944385652\tacc 0.6575\tcnt 4\n",
      "\tepoch   136\t\tloss 1.032267192577\tacc 0.6584\tcnt 5\n",
      "train halted\n",
      "---------- 학습 종료 ----------\n"
     ]
    }
   ],
   "source": [
    "NN = LSTM(vocab_size=vocab_size,embedding_dim=embedding_dim,hidden_dim=10,output_dim=7,n_layers=2,bidirectional=True,dropout_p=0.1)\n",
    "NN.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NN.parameters(),lr=0.001)\n",
    "epoch = 500\n",
    "acc = 0\n",
    "prev_acc = 0\n",
    "\n",
    "for e in range(epoch):\n",
    "    NN.to(device)\n",
    "    loss_sum = 0\n",
    "    NN.train()\n",
    "    for x, attention,t in train_loader:\n",
    "        y = NN(x,attention)\n",
    "        loss = loss_function(y,t)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_sum /= len(train_loader)\n",
    "\n",
    "    NN.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,attention,t in train_loader:\n",
    "        y = NN(x,attention)\n",
    "        correct += (y.argmax(dim = -1) == t).sum().item()\n",
    "        total += len(x)\n",
    "    acc = correct / total\n",
    "\n",
    "    if acc <= prev_acc:\n",
    "        cnt += 1\n",
    "    else :\n",
    "        torch.save(NN.to('cpu'),\"Sentiment.pt\")\n",
    "        cnt = 0\n",
    "        prev_acc = acc\n",
    "    print(f\"\\tepoch   {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "    if cnt >= 5:\n",
    "        print(\"train halted\")\n",
    "        break\n",
    "print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8789baa-6fb4-4cac-84bc-84cf7971e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"Sentiment.pt\",weights_only=False)\n",
    "torch.save(model,f\"{saveFilePath}train_3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7028c5e-4cf0-4fd1-914d-ca3f77a267ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
