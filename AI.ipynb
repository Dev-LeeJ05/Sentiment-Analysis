{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c84beab-fdd3-4b92-b4ff-53216eb51626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from WordPieceTokenizer import WordPieceTokenizer as Tokenizer\n",
    "\n",
    "dataFilePath = 'datasets/'\n",
    "tokenizer = Tokenizer(f'{dataFilePath}vocab.txt',do_lower_case=False,strip_accents=False,clean_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da38b69e-5ccd-4751-a66e-934077285c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화</th>\n",
       "      <th>감정</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 19009 13925 10540 16229 5815 13244 3785 2859...</td>\n",
       "      <td>불안</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 11733 783 12006 5698 6039 23027 3 0 0 0 0 0 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 11033 5953 5954 6094 5662 14321 10752 5842 6...</td>\n",
       "      <td>불안</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 19393 13465 11005 27098 5677 5905 3 0 0 0 0 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 17124 12139 5706 6243 5842 6388 15275 3 0 0 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  발화  감정  \\\n",
       "0  2 19009 13925 10540 16229 5815 13244 3785 2859...  불안   \n",
       "1  2 11733 783 12006 5698 6039 23027 3 0 0 0 0 0 ...  불안   \n",
       "2  2 11033 5953 5954 6094 5662 14321 10752 5842 6...  불안   \n",
       "3  2 19393 13465 11005 27098 5677 5905 3 0 0 0 0 ...  불안   \n",
       "4  2 17124 12139 5706 6243 5842 6388 15275 3 0 0 ...  불안   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "1  1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "2  1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "3  1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "4  1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "\n",
       "                                      token_type_ids  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{dataFilePath}sentiment_train.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b88c422-88f4-4e80-9f82-53fdcb86b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['감정'] == '불안'),'감정'] = 0\n",
    "df.loc[(df['감정'] == '당황'),'감정'] = 1\n",
    "df.loc[(df['감정'] == '분노'),'감정'] = 2\n",
    "df.loc[(df['감정'] == '슬픔'),'감정'] = 3\n",
    "df.loc[(df['감정'] == '중립'),'감정'] = 4\n",
    "df.loc[(df['감정'] == '행복'),'감정'] = 5\n",
    "df.loc[(df['감정'] == '혐오'),'감정'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7539503-47ba-4ace-9273-2a43e85ec2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32696\n",
      "32696\n",
      "32696\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tensor_x_list = []\n",
    "attentions = []\n",
    "for i in range(len(df)):\n",
    "    token = df.iloc[i,0]\n",
    "    token = token.split(\" \")\n",
    "    token_list = []\n",
    "    for t in token:\n",
    "        token_list.append(int(t))\n",
    "    tensor_x_list.append(token_list)\n",
    "    \n",
    "    attention = df.iloc[i,2]\n",
    "    attention = attention.split(\" \")\n",
    "    attention_list = []\n",
    "    for a in attention:\n",
    "        attention_list.append(int(a))\n",
    "    attentions.append(attention_list)\n",
    "\n",
    "tensor_attention = torch.tensor(attentions,dtype=torch.long,device=device)\n",
    "tensor_x = torch.tensor(tensor_x_list,dtype=torch.long,device=device)\n",
    "tensor_t = torch.tensor(df[\"감정\"].values.tolist(),dtype=torch.long,device=device)\n",
    "\n",
    "print(len(tensor_attention))\n",
    "print(len(tensor_x))\n",
    "print(len(tensor_t))\n",
    "dataset = TensorDataset(tensor_x,tensor_attention,tensor_t)\n",
    "\n",
    "train_loader = DataLoader(dataset,batch_size=64,shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(dataset,batch_size=1000,shuffle=False,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c88d6e7-0bf1-45aa-b007-f33b83560e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "510\n",
      "torch.Size([32696, 64])\n",
      "torch.Size([32696])\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader))\n",
    "print(len(train_loader))\n",
    "print(tensor_x.shape)\n",
    "print(tensor_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d111445-7445-4928-bd86-aaf64728a581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import LSTM\n",
    "\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = tensor_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a68f657-9e9f-47d8-b477-2cb4ec4601f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tepoch   1\t\tloss 1.719350016351\tacc 0.3947\tcnt 0\n",
      "\tepoch   2\t\tloss 1.454423050086\tacc 0.4671\tcnt 0\n",
      "\tepoch   3\t\tloss 1.331133266056\tacc 0.5151\tcnt 0\n",
      "\tepoch   4\t\tloss 1.251220748238\tacc 0.5504\tcnt 0\n",
      "\tepoch   5\t\tloss 1.190830593016\tacc 0.5744\tcnt 0\n",
      "\tepoch   6\t\tloss 1.142400441918\tacc 0.5969\tcnt 0\n",
      "\tepoch   7\t\tloss 1.094172661094\tacc 0.6137\tcnt 0\n",
      "\tepoch   8\t\tloss 1.053157565874\tacc 0.6397\tcnt 0\n",
      "\tepoch   9\t\tloss 1.019314868193\tacc 0.6607\tcnt 0\n",
      "\tepoch   10\t\tloss 0.988265403112\tacc 0.6756\tcnt 0\n",
      "\tepoch   11\t\tloss 0.952950001114\tacc 0.6907\tcnt 0\n",
      "\tepoch   12\t\tloss 0.918875561158\tacc 0.7059\tcnt 0\n",
      "\tepoch   13\t\tloss 0.888095259666\tacc 0.7165\tcnt 0\n",
      "\tepoch   14\t\tloss 0.863135629425\tacc 0.7347\tcnt 0\n",
      "\tepoch   15\t\tloss 0.843000507472\tacc 0.7454\tcnt 0\n",
      "\tepoch   16\t\tloss 0.811209302907\tacc 0.7547\tcnt 0\n",
      "\tepoch   17\t\tloss 0.791326062001\tacc 0.7691\tcnt 0\n",
      "\tepoch   18\t\tloss 0.768125559886\tacc 0.7692\tcnt 0\n",
      "\tepoch   19\t\tloss 0.744674311900\tacc 0.7892\tcnt 0\n",
      "\tepoch   20\t\tloss 0.724641959924\tacc 0.7995\tcnt 0\n",
      "\tepoch   21\t\tloss 0.707943974348\tacc 0.8088\tcnt 0\n",
      "\tepoch   22\t\tloss 0.681148603500\tacc 0.8174\tcnt 0\n",
      "\tepoch   23\t\tloss 0.660289319941\tacc 0.8257\tcnt 0\n",
      "\tepoch   24\t\tloss 0.647747496530\tacc 0.8336\tcnt 0\n",
      "\tepoch   25\t\tloss 0.627590099094\tacc 0.8419\tcnt 0\n",
      "\tepoch   26\t\tloss 0.617047936192\tacc 0.8459\tcnt 0\n",
      "\tepoch   27\t\tloss 0.597618742083\tacc 0.8493\tcnt 0\n",
      "\tepoch   28\t\tloss 0.578895737903\tacc 0.8585\tcnt 0\n",
      "\tepoch   29\t\tloss 0.563984924672\tacc 0.8647\tcnt 0\n",
      "\tepoch   30\t\tloss 0.553006126659\tacc 0.8723\tcnt 0\n",
      "\tepoch   31\t\tloss 0.530896662731\tacc 0.8794\tcnt 0\n",
      "\tepoch   32\t\tloss 0.521744568091\tacc 0.8853\tcnt 0\n",
      "\tepoch   33\t\tloss 0.507857814051\tacc 0.8913\tcnt 0\n",
      "\tepoch   34\t\tloss 0.495112542808\tacc 0.8972\tcnt 0\n",
      "\tepoch   35\t\tloss 0.478109749626\tacc 0.9029\tcnt 0\n",
      "\tepoch   36\t\tloss 0.472051790561\tacc 0.9072\tcnt 0\n",
      "\tepoch   37\t\tloss 0.457819255339\tacc 0.9094\tcnt 0\n",
      "\tepoch   38\t\tloss 0.446551243756\tacc 0.9119\tcnt 0\n",
      "\tepoch   39\t\tloss 0.436456740837\tacc 0.9229\tcnt 0\n",
      "\tepoch   40\t\tloss 0.418983844974\tacc 0.9258\tcnt 0\n",
      "\tepoch   41\t\tloss 0.409044505276\tacc 0.9272\tcnt 0\n",
      "\tepoch   42\t\tloss 0.401854908087\tacc 0.9330\tcnt 0\n",
      "\tepoch   43\t\tloss 0.392542650185\tacc 0.9355\tcnt 0\n",
      "\tepoch   44\t\tloss 0.378707892725\tacc 0.9375\tcnt 0\n",
      "\tepoch   45\t\tloss 0.373538127103\tacc 0.9429\tcnt 0\n",
      "\tepoch   46\t\tloss 0.361486335756\tacc 0.9408\tcnt 1\n",
      "\tepoch   47\t\tloss 0.353454983351\tacc 0.9479\tcnt 0\n",
      "\tepoch   48\t\tloss 0.343047956742\tacc 0.9506\tcnt 0\n",
      "\tepoch   49\t\tloss 0.333312837560\tacc 0.9522\tcnt 0\n",
      "\tepoch   50\t\tloss 0.326669116099\tacc 0.9533\tcnt 0\n",
      "\tepoch   51\t\tloss 0.320678265451\tacc 0.9576\tcnt 0\n",
      "\tepoch   52\t\tloss 0.305957769179\tacc 0.9594\tcnt 0\n",
      "\tepoch   53\t\tloss 0.299991583444\tacc 0.9619\tcnt 0\n",
      "\tepoch   54\t\tloss 0.293599149117\tacc 0.9629\tcnt 0\n",
      "\tepoch   55\t\tloss 0.285962548092\tacc 0.9649\tcnt 0\n",
      "\tepoch   56\t\tloss 0.283055400980\tacc 0.9665\tcnt 0\n",
      "\tepoch   57\t\tloss 0.276744045200\tacc 0.9690\tcnt 0\n",
      "\tepoch   58\t\tloss 0.267431585710\tacc 0.9711\tcnt 0\n",
      "\tepoch   59\t\tloss 0.263579415771\tacc 0.9707\tcnt 1\n",
      "\tepoch   60\t\tloss 0.257650619234\tacc 0.9733\tcnt 0\n",
      "\tepoch   61\t\tloss 0.254001488683\tacc 0.9727\tcnt 1\n",
      "\tepoch   62\t\tloss 0.241735778413\tacc 0.9757\tcnt 0\n",
      "\tepoch   63\t\tloss 0.242082223501\tacc 0.9766\tcnt 0\n",
      "\tepoch   64\t\tloss 0.231715584356\tacc 0.9776\tcnt 0\n",
      "\tepoch   65\t\tloss 0.224190990583\tacc 0.9784\tcnt 0\n",
      "\tepoch   66\t\tloss 0.224598195988\tacc 0.9794\tcnt 0\n",
      "\tepoch   67\t\tloss 0.215771895413\tacc 0.9811\tcnt 0\n",
      "\tepoch   68\t\tloss 0.212335210381\tacc 0.9821\tcnt 0\n",
      "\tepoch   69\t\tloss 0.207759535795\tacc 0.9822\tcnt 0\n",
      "\tepoch   70\t\tloss 0.200993120415\tacc 0.9834\tcnt 0\n",
      "\tepoch   71\t\tloss 0.199698878408\tacc 0.9835\tcnt 0\n",
      "\tepoch   72\t\tloss 0.196114802981\tacc 0.9844\tcnt 0\n",
      "\tepoch   73\t\tloss 0.190071511057\tacc 0.9846\tcnt 0\n",
      "\tepoch   74\t\tloss 0.185166267780\tacc 0.9854\tcnt 0\n",
      "\tepoch   75\t\tloss 0.181502612666\tacc 0.9864\tcnt 0\n",
      "\tepoch   76\t\tloss 0.181703153326\tacc 0.9867\tcnt 0\n",
      "\tepoch   77\t\tloss 0.172391429763\tacc 0.9871\tcnt 0\n",
      "\tepoch   78\t\tloss 0.170105220198\tacc 0.9879\tcnt 0\n",
      "\tepoch   79\t\tloss 0.170096086824\tacc 0.9889\tcnt 0\n",
      "\tepoch   80\t\tloss 0.166127891663\tacc 0.9892\tcnt 0\n",
      "\tepoch   81\t\tloss 0.162181949981\tacc 0.9893\tcnt 0\n",
      "\tepoch   82\t\tloss 0.159378001112\tacc 0.9898\tcnt 0\n",
      "\tepoch   83\t\tloss 0.154715319124\tacc 0.9906\tcnt 0\n",
      "\tepoch   84\t\tloss 0.153648061053\tacc 0.9899\tcnt 1\n",
      "\tepoch   85\t\tloss 0.147905302157\tacc 0.9911\tcnt 0\n",
      "\tepoch   86\t\tloss 0.145046317165\tacc 0.9915\tcnt 0\n",
      "\tepoch   87\t\tloss 0.140845792386\tacc 0.9911\tcnt 1\n",
      "\tepoch   88\t\tloss 0.140211024325\tacc 0.9911\tcnt 2\n",
      "\tepoch   89\t\tloss 0.141531393670\tacc 0.9921\tcnt 0\n",
      "\tepoch   90\t\tloss 0.133449478776\tacc 0.9925\tcnt 0\n",
      "\tepoch   91\t\tloss 0.129413033503\tacc 0.9930\tcnt 0\n",
      "\tepoch   92\t\tloss 0.130525643802\tacc 0.9927\tcnt 1\n",
      "\tepoch   93\t\tloss 0.132856228595\tacc 0.9934\tcnt 0\n",
      "\tepoch   94\t\tloss 0.131342551578\tacc 0.9926\tcnt 1\n",
      "\tepoch   95\t\tloss 0.123142035039\tacc 0.9932\tcnt 2\n",
      "\tepoch   96\t\tloss 0.121445860856\tacc 0.9935\tcnt 0\n",
      "\tepoch   97\t\tloss 0.119681896843\tacc 0.9939\tcnt 0\n",
      "\tepoch   98\t\tloss 0.120075186952\tacc 0.9942\tcnt 0\n",
      "\tepoch   99\t\tloss 0.114311064579\tacc 0.9941\tcnt 1\n",
      "\tepoch   100\t\tloss 0.119234939867\tacc 0.9950\tcnt 0\n",
      "---------- 학습 종료 ----------\n"
     ]
    }
   ],
   "source": [
    "NN = LSTM(vocab_size=vocab_size,embedding_dim=embedding_dim,hidden_dim=10,output_dim=7,n_layers=2,bidirectional=True,dropout_p=0.1)\n",
    "NN.to(device)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NN.parameters(),lr=0.001)\n",
    "epoch = 100\n",
    "acc = 0\n",
    "prev_acc = 0\n",
    "\n",
    "for e in range(epoch):\n",
    "    loss_sum = 0\n",
    "    NN.train()\n",
    "    for x, attention,t in train_loader:\n",
    "        y = NN(x,attention)\n",
    "        loss = loss_function(y,t)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_sum /= len(train_loader)\n",
    "\n",
    "    NN.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x,attention,t in train_loader:\n",
    "        y = NN(x,attention)\n",
    "        correct += (y.argmax(dim = -1) == t).sum().item()\n",
    "        total += len(x)\n",
    "    acc = correct / total\n",
    "\n",
    "    if acc <= prev_acc:\n",
    "        cnt += 1\n",
    "    else :\n",
    "        cnt = 0\n",
    "        prev_acc = acc\n",
    "    print(f\"\\tepoch   {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "    if cnt >= 5:\n",
    "        print(\"train halted\")\n",
    "        break\n",
    "print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb793d2d-bb3b-49cd-af2f-ecd54ef5f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.eval()\n",
    "torch.save(NN.to('cpu'),\"Sentiment.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8789baa-6fb4-4cac-84bc-84cf7971e4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
