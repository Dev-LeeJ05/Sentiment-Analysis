{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c84beab-fdd3-4b92-b4ff-53216eb51626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from CustomDataCollatorForSequenceClassification import CustomDataCollatorForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from WordPieceTokenizer import WordPieceTokenizer as Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from CustomBertSequenceClassification import CustomBertSequenceClassification\n",
    "from CustomBert import CustomBertConfig\n",
    "import CustomBert\n",
    "import os\n",
    "from Model import LSTM\n",
    "from Model import Transformer, PositionalEncoding\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "dataFilePath = 'datasets/'\n",
    "saveFilePath = 'saves/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = Tokenizer(f'{saveFilePath}vocab.txt',do_lower_case=False,strip_accents=False,clean_text=True)\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "MAX_SEQUENCE_LENGTH = 64\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da38b69e-5ccd-4751-a66e-934077285c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화</th>\n",
       "      <th>감정</th>\n",
       "      <th>str_len</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 10955 4065 2006 7119 1191 12454 19817 9959 3...</td>\n",
       "      <td>불안</td>\n",
       "      <td>24</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 14186 143 7807 1225 1576 1366 1015 3 0 0 0 0...</td>\n",
       "      <td>불안</td>\n",
       "      <td>12</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 4127 1515 1024 1206 1062 28552 4037 1076 158...</td>\n",
       "      <td>불안</td>\n",
       "      <td>14</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 9388 2525 3097 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>불안</td>\n",
       "      <td>13</td>\n",
       "      <td>1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 98 1051 3092 1033 1330 1076 1836 25640 3 0 0...</td>\n",
       "      <td>불안</td>\n",
       "      <td>11</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  발화  감정  str_len  \\\n",
       "0  2 10955 4065 2006 7119 1191 12454 19817 9959 3...  불안       24   \n",
       "1  2 14186 143 7807 1225 1576 1366 1015 3 0 0 0 0...  불안       12   \n",
       "2  2 4127 1515 1024 1206 1062 28552 4037 1076 158...  불안       14   \n",
       "3  2 9388 2525 3097 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0...  불안       13   \n",
       "4  2 98 1051 3092 1033 1330 1076 1836 25640 3 0 0...  불안       11   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "1  1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "2  1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "3  1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "4  1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "\n",
       "                                      token_type_ids  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{dataFilePath}sentiment_train.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b88c422-88f4-4e80-9f82-53fdcb86b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['감정'] == '불안'),'감정'] = 0\n",
    "df.loc[(df['감정'] == '당황'),'감정'] = 1\n",
    "df.loc[(df['감정'] == '분노'),'감정'] = 2\n",
    "df.loc[(df['감정'] == '슬픔'),'감정'] = 3\n",
    "df.loc[(df['감정'] == '중립'),'감정'] = 4\n",
    "df.loc[(df['감정'] == '행복'),'감정'] = 5\n",
    "df.loc[(df['감정'] == '혐오'),'감정'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3590a8e3-5472-4959-ac1b-e4cd59645e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_classification_dataset(data_frame, tokenizer):\n",
    "    processed_tokens = []\n",
    "    processed_attentions = []\n",
    "    processed_token_type_ids = []\n",
    "\n",
    "    for i in tqdm(range(len(data_frame)), desc=\"데이터 파싱 중\"):\n",
    "        token_str = data_frame.iloc[i, 0]\n",
    "        attention_str = data_frame.iloc[i, 3]\n",
    "        token_type_ids_str = data_frame.iloc[i, 4]\n",
    "\n",
    "        processed_tokens.append([int(t) for t in token_str.split(\" \")])\n",
    "        processed_attentions.append([int(a) for a in attention_str.split(\" \")])\n",
    "        processed_token_type_ids.append([int(t) for t in token_type_ids_str.split(\" \")])\n",
    "\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": processed_tokens,\n",
    "        \"attention_mask\": processed_attentions,\n",
    "        \"token_type_ids\": processed_token_type_ids,\n",
    "        \"labels\": data_frame[\"감정\"].values.tolist()\n",
    "    }\n",
    "    \n",
    "    hf_dataset = Dataset.from_dict(dataset_dict)\n",
    "    hf_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'token_type_ids', 'labels'])\n",
    "    \n",
    "    return hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5776764d-05d3-46df-909d-2bc90d0f23ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트의 크기: 117078 행\n",
      "검증 세트의 크기: 29270 행\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7954161023dd409383c7d0fd9c85edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "데이터 파싱 중:   0%|          | 0/117078 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117078\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b68ef04eff5433fa3fc4b40f983458e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "데이터 파싱 중:   0%|          | 0/29270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29270\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df,train_size=0.8,test_size=0.2)\n",
    "\n",
    "print(f\"학습 세트의 크기: {len(train_df)} 행\")\n",
    "print(f\"검증 세트의 크기: {len(val_df)} 행\")\n",
    "\n",
    "train_datasets = prepare_classification_dataset(train_df,tokenizer)\n",
    "print(len(train_datasets))\n",
    "val_datasets = prepare_classification_dataset(val_df,tokenizer)\n",
    "print(len(val_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5d33c59-b51e-43c7-a0a1-c59828780848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830\n",
      "458\n"
     ]
    }
   ],
   "source": [
    "data_collator = CustomDataCollatorForSequenceClassification(tokenizer=tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=0\n",
    ")\n",
    "print(len(train_loader))\n",
    "val_loader = DataLoader(\n",
    "    val_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=0\n",
    ")\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1f979-cd2b-403d-adfa-28d9d39a6b92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404c17eb-9dbf-4369-81f5-218c8a2be20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_dataframe(data_frame, device,batch_size,shuffle=False):\n",
    "#     tensor_x_list = []\n",
    "#     attentions = []\n",
    "#     token_type_ids_ = []\n",
    "#     for i in tqdm(range(len(data_frame))):\n",
    "#         token = data_frame.iloc[i,0]\n",
    "#         token = token.split(\" \")\n",
    "#         token_list = []\n",
    "#         for t in token:\n",
    "#             token_list.append(int(t))\n",
    "#         tensor_x_list.append(token_list)\n",
    "        \n",
    "#         attention = data_frame.iloc[i,3]\n",
    "#         attention = attention.split(\" \")\n",
    "#         attention_list = []\n",
    "#         for a in attention:\n",
    "#             attention_list.append(int(a))\n",
    "#         attentions.append(attention_list)\n",
    "\n",
    "#         token_type_ids = data_frame.iloc[i,4]\n",
    "#         token_type_ids = token_type_ids.split(\" \")\n",
    "#         token_type_ids_list = []\n",
    "#         for t in token_type_ids:\n",
    "#             token_type_ids_list.append(int(t))\n",
    "#         token_type_ids_.append(attention_list)\n",
    "        \n",
    "#     tensor_x = torch.tensor(tensor_x_list, dtype=torch.long, device=device)\n",
    "#     tensor_attention = torch.tensor(attentions, dtype=torch.long, device=device)\n",
    "#     tensor_token_type_ids = torch.tensor(token_type_ids_, dtype=torch.long, device=device)\n",
    "#     tensor_t = torch.tensor(data_frame[\"감정\"].values.tolist(), dtype=torch.long, device=device)\n",
    "\n",
    "#     dataset = TensorDataset(tensor_x,tensor_attention,tensor_t,tensor_token_type_ids)\n",
    "#     loader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=True)\n",
    "#     return loader\n",
    "    \n",
    "#     dataset = {\"input_ids\" : tensor_x, \"attention_mask\":tensor_attention,\"token_type_ids\":tensor_token_type_ids,\"labels\":tensor_t}\n",
    "    \n",
    "    \n",
    "\n",
    "#     data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d065c33-266a-43af-924c-c76f35f47549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer):\n",
    "    acc = 0\n",
    "    prev_acc = 0\n",
    "    cnt = 0\n",
    "    for e in range(epoch):\n",
    "        NN.to(device)\n",
    "        loss_sum = 0\n",
    "        NN.train()\n",
    "        for x, attention,t in train_loader:\n",
    "            y = NN(x,attention)\n",
    "            loss = loss_function(y,t)\n",
    "            loss_sum += loss.item()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_sum /= len(train_loader)\n",
    "    \n",
    "        NN.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, attention, t in val_loader:\n",
    "                x = x.to(device)\n",
    "                attention = attention.to(device)\n",
    "                t = t.to(device)\n",
    "    \n",
    "                y = NN(x, attention)\n",
    "                correct += (y.argmax(dim=-1) == t).sum().item()\n",
    "                total += len(x)\n",
    "        acc = correct / total\n",
    "    \n",
    "        if acc <= prev_acc:\n",
    "            cnt += 1\n",
    "        else :\n",
    "            torch.save(NN.state_dict(), \"Sentiment.pt\")\n",
    "            cnt = 0\n",
    "            prev_acc = acc\n",
    "        \n",
    "        print(f\"epoch  {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "        \n",
    "        if cnt >= 5:\n",
    "            print(\"train halted\")\n",
    "            break\n",
    "            \n",
    "    print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a68f657-9e9f-47d8-b477-2cb4ec4601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN = LSTM(vocab_size=vocab_size,embedding_dim=embedding_dim,hidden_dim=64,output_dim=7,n_layers=4,bidirectional=True,dropout_p=0.1)\n",
    "# NN.to(device)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(NN.parameters(),lr=0.001)\n",
    "# epoch = 500\n",
    "# LSTM_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef3a0ef-22f3-4ed6-8b5d-4676131d5f34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b599944c-bab7-4d2e-986e-bf50e02b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformer_Train(epoch, device, train_loader, val_loader, NN, loss_function, optimizer,scheduler):\n",
    "    acc = 0\n",
    "    prev_acc = 0\n",
    "    cnt = 0\n",
    "    for e in range(epoch):\n",
    "        NN.to(device)\n",
    "        loss_sum = 0\n",
    "        NN.train()\n",
    "        for x, attention, t in tqdm(train_loader, desc=f\"Epoch {e+1} Training\",leave=False):\n",
    "            x = x.to(device)\n",
    "            attention = attention.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            y = NN(x, attention)\n",
    "            loss = loss_function(y, t)\n",
    "            loss_sum += loss.item()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(NN.parameters(),1.0)\n",
    "            optimizer.step()\n",
    "        loss_sum /= len(train_loader)\n",
    "        \n",
    "        NN.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, attention, t in tqdm(val_loader, desc=f\"Epoch {e+1} Validation\",leave=False):\n",
    "                x = x.to(device)\n",
    "                attention = attention.to(device)\n",
    "                t = t.to(device)\n",
    "        \n",
    "                y = NN(x, attention)\n",
    "                correct += (y.argmax(dim=-1) == t).sum().item()\n",
    "                total += len(x)\n",
    "        acc = correct / total\n",
    "        \n",
    "        if acc <= prev_acc:\n",
    "            cnt += 1\n",
    "        else :\n",
    "            torch.save(NN.state_dict(), \"Sentiment.pt\")\n",
    "            cnt = 0\n",
    "            prev_acc = acc\n",
    "\n",
    "        scheduler.step(acc)\n",
    "        \n",
    "        print(f\"epoch   {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "        \n",
    "        if cnt >= 5:\n",
    "            print(\"train halted\")\n",
    "            break\n",
    "            \n",
    "    print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1875b120-9a16-4755-ac20-2d2ffa247ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|                                                                       | 0/1170 [00:00<?, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24684\\2332016856.py:20: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  nn.utils.clip_grad_norm(NN.parameters(),1.0)\n",
      "Epoch 1 Validation:   0%|                                                                       | 0/29 [00:00<?, ?it/s]C:\\Users\\Administrator\\anaconda3\\envs\\tensor\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1\t\tloss 1.611574331308\tacc 0.4478\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   2\t\tloss 1.521470283749\tacc 0.4758\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   3\t\tloss 1.440676615279\tacc 0.5001\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   4\t\tloss 1.392663119186\tacc 0.5133\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   5\t\tloss 1.358114989191\tacc 0.5215\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   6\t\tloss 1.329676023304\tacc 0.5304\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   7\t\tloss 1.304244029420\tacc 0.5386\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   8\t\tloss 1.282142842020\tacc 0.5440\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   9\t\tloss 1.262910174254\tacc 0.5495\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10\t\tloss 1.244619312144\tacc 0.5542\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11\t\tloss 1.227673865129\tacc 0.5587\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m,factor=\u001b[32m0.5\u001b[39m,patience=\u001b[32m3\u001b[39m,)\n\u001b[32m      5\u001b[39m epoch = \u001b[32m500\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mTransformer_Train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mTransformer_Train\u001b[39m\u001b[34m(epoch, device, train_loader, val_loader, NN, loss_function, optimizer, scheduler)\u001b[39m\n\u001b[32m     14\u001b[39m y = NN(x, attention)\n\u001b[32m     15\u001b[39m loss = loss_function(y, t)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m loss_sum += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.zero_grad()\n\u001b[32m     19\u001b[39m loss.backward()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "NN = Transformer(vocab_size=VOCAB_SIZE,embedding_dim=128,hidden_dim=16,output_dim=7,n_layers=2,n_heads=4,dropout_p=0.05,max_len=150,pad_token_id=0)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(NN.parameters(),lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"max\",factor=0.5,patience=3,)\n",
    "epoch = 500\n",
    "Transformer_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8789baa-6fb4-4cac-84bc-84cf7971e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"Sentiment.pt\",weights_only=False)\n",
    "# torch.save(model,f\"{saveFilePath}train_15.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f8250-467c-435f-82c2-1f5712586b2b",
   "metadata": {},
   "source": [
    "# Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb6d29e-e63d-42cd-a414-6a3dcf835955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 가중치를 saves/Pretrain.pt에서 불러오는 중..\n",
      "모델 가중치 로드 완료\n",
      "모델 가중치 로드 중...\n",
      "모델 가중치 로드 완료.\n",
      "Custom Bert 모델 초기화 완료. 총 학습 가능 파라미터 수 : 110951943\n",
      "모델이 담긴 장치 : cuda\n"
     ]
    }
   ],
   "source": [
    "PRETRAIN_MODEL_SAVE_PATH = \"saves/Pretrain.pt\"\n",
    "MODEL_SAVE_PATH = \"Sentiment.pt\"\n",
    "HIDDEN_SIZE = 768\n",
    "NUM_HIDDEN_LAYERS = 12\n",
    "NUM_ATTENTION_HEADS = 12\n",
    "INTERMEDIATE_SIZE = 3072\n",
    "TYPE_VOCAB_SIZE = 2\n",
    "DROPOUT_PROB = 0.1\n",
    "\n",
    "config = CustomBertConfig(\n",
    "    VOCAB_SIZE=VOCAB_SIZE,\n",
    "    HIDDEN_SIZE=HIDDEN_SIZE,\n",
    "    NUM_HIDDEN_LAYERS=NUM_HIDDEN_LAYERS,\n",
    "    NUM_ATTENTION_HEADS=NUM_ATTENTION_HEADS,\n",
    "    INTERMEDIATE_SIZE=INTERMEDIATE_SIZE,\n",
    "    MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH,\n",
    "    TYPE_VOCAB_SIZE=TYPE_VOCAB_SIZE,\n",
    "    DROPOUT_PROB=DROPOUT_PROB\n",
    ")\n",
    "\n",
    "model = CustomBertSequenceClassification(config,PRETRAIN_MODEL_SAVE_PATH,7)\n",
    "\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(\"모델 가중치 로드 중...\")\n",
    "    # 먼저 CPU에 로드한 후 모델에 로드합니다.\n",
    "    loaded_state_dict = torch.load(MODEL_SAVE_PATH, map_location='cpu')\n",
    "    model.load_state_dict(loaded_state_dict)\n",
    "    print(\"모델 가중치 로드 완료.\")\n",
    "else:\n",
    "    print(\"새로운 모델 초기화 완료. 저장된 가중치를 찾을 수 없습니다.\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Custom Bert 모델 초기화 완료. 총 학습 가능 파라미터 수 : {num_params}')\n",
    "print(f'모델이 담긴 장치 : {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65436a37-b78a-436c-9259-ad29a14e72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "LEARNING_RATE = 5e-8\n",
    "WEIGHT_DECAY = 0.1\n",
    "optimizer = AdamW(model.parameters(),lr=LEARNING_RATE,weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa1c339f-7124-4cc3-9651-f163b1053f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<--- 학습 시작 ---> (3 에폭)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e17b812dbf243e5b8b9b564bed9e7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 1:   0%|          | 0/1830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     15\u001b[39m outputs = model.forward(\n\u001b[32m     16\u001b[39m     input_ids=batch[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     17\u001b[39m     attention_mask=batch[\u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     18\u001b[39m     token_type_ids=batch[\u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     19\u001b[39m     labels=batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m loss = outputs[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m optimizer.step()\n\u001b[32m     25\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tensor\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tensor\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\tensor\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "acc = 0\n",
    "prev_acc = 0\n",
    "cnt = 0\n",
    "\n",
    "print(f\"\\n<--- 학습 시작 ---> ({EPOCHS} 에폭)\")\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    loss_sum = 0\n",
    "    progress_bar = tqdm(train_loader,desc=f\"Train Epoch {e+1}\")\n",
    "    model.train()\n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model.forward(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            token_type_ids=batch[\"token_type_ids\"],\n",
    "            labels=batch[\"labels\"]\n",
    "        )\n",
    "        loss = outputs[\"loss\"]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        progress_bar.set_postfix({'loss':f\"{(loss_sum/(step+1)):.4f}\"})\n",
    "        del outputs, loss\n",
    "        if 'ccuda' in str(device):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    avg_train_loss = loss_sum / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    print(f\"Train Epoch {e+1} 완료. 평균 학습 손실 : {avg_train_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_progress = tqdm(val_loader, desc=f\"Validation Epoch {e+1}\")\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(val_progress):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            y = model.forward(input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                token_type_ids=batch[\"token_type_ids\"]\n",
    "            )\n",
    "            y_logits = y[\"logits\"]\n",
    "            t = batch[\"labels\"]\n",
    "            correct += (y_logits.argmax(dim=-1) == t).sum().item()\n",
    "            total += len(batch[\"input_ids\"])\n",
    "            val_progress.set_postfix({\"acc\" : f\"{((correct/total)*100):.2f}%\"})\n",
    "            \n",
    "    acc = correct / total\n",
    "    \n",
    "    print(f\"Validation Epoch {e+1} 완료. 검증 정확도 : {(acc*100):.2f}%\")\n",
    "    \n",
    "    if acc <= prev_acc:\n",
    "        cnt += 1\n",
    "    else :\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        cnt = 0\n",
    "        prev_acc = acc\n",
    "\n",
    "    if cnt >= 5:\n",
    "        print(\"train halted\")\n",
    "        break\n",
    "       \n",
    "print(\"\\n<--- 학습 완료 --->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cadfc-c327-42f7-ad3c-86197a281f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
