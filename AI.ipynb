{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c84beab-fdd3-4b92-b4ff-53216eb51626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from WordPieceTokenizer import WordPieceTokenizer as Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "dataFilePath = 'datasets/'\n",
    "saveFilePath = 'saves/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = Tokenizer(f'{dataFilePath}sentiment_vocab/vocab.txt',do_lower_case=False,strip_accents=False,clean_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da38b69e-5ccd-4751-a66e-934077285c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화</th>\n",
       "      <th>감정</th>\n",
       "      <th>str_len</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 2383 2354 2003 10368 1094 2706 16474 1015 3 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>24</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 2092 163 2420 18281 2154 3 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>불안</td>\n",
       "      <td>12</td>\n",
       "      <td>1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 2106 4701 1076 18939 1007 5406 1252 3 0 0 0 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>14</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 10103 21602 2671 18048 2603 3 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>13</td>\n",
       "      <td>1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 2255 2913 11078 1111 1209 2677 3 0 0 0 0 0 0...</td>\n",
       "      <td>불안</td>\n",
       "      <td>11</td>\n",
       "      <td>1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  발화  감정  str_len  \\\n",
       "0  2 2383 2354 2003 10368 1094 2706 16474 1015 3 ...  불안       24   \n",
       "1  2 2092 163 2420 18281 2154 3 0 0 0 0 0 0 0 0 0...  불안       12   \n",
       "2  2 2106 4701 1076 18939 1007 5406 1252 3 0 0 0 ...  불안       14   \n",
       "3  2 10103 21602 2671 18048 2603 3 0 0 0 0 0 0 0 ...  불안       13   \n",
       "4  2 2255 2913 11078 1111 1209 2677 3 0 0 0 0 0 0...  불안       11   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "1  1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "2  1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "3  1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "4  1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "\n",
       "                                      token_type_ids  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{dataFilePath}sentiment_train.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b88c422-88f4-4e80-9f82-53fdcb86b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['감정'] == '불안'),'감정'] = 0\n",
    "df.loc[(df['감정'] == '당황'),'감정'] = 1\n",
    "df.loc[(df['감정'] == '분노'),'감정'] = 2\n",
    "df.loc[(df['감정'] == '슬픔'),'감정'] = 3\n",
    "df.loc[(df['감정'] == '중립'),'감정'] = 4\n",
    "df.loc[(df['감정'] == '행복'),'감정'] = 5\n",
    "df.loc[(df['감정'] == '혐오'),'감정'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404c17eb-9dbf-4369-81f5-218c8a2be20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(data_frame, device,batch_size,shuffle=False):\n",
    "    tensor_x_list = []\n",
    "    attentions = []\n",
    "    for i in tqdm(range(len(data_frame))):\n",
    "        token = data_frame.iloc[i,0]\n",
    "        token = token.split(\" \")\n",
    "        token_list = []\n",
    "        for t in token:\n",
    "            token_list.append(int(t))\n",
    "        tensor_x_list.append(token_list)\n",
    "        \n",
    "        attention = data_frame.iloc[i,3]\n",
    "        attention = attention.split(\" \")\n",
    "        attention_list = []\n",
    "        for a in attention:\n",
    "            attention_list.append(int(a))\n",
    "        attentions.append(attention_list)\n",
    "\n",
    "    tensor_x = torch.tensor(tensor_x_list, dtype=torch.long, device=device)\n",
    "    tensor_attention = torch.tensor(attentions, dtype=torch.long, device=device)\n",
    "    tensor_t = torch.tensor(data_frame[\"감정\"].values.tolist(), dtype=torch.long, device=device)\n",
    "\n",
    "    dataset = TensorDataset(tensor_x,tensor_attention,tensor_t)\n",
    "\n",
    "    loader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=True)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5776764d-05d3-46df-909d-2bc90d0f23ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트의 크기: 117078 행\n",
      "검증 세트의 크기: 29270 행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 117078/117078 [00:12<00:00, 9114.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 29270/29270 [00:02<00:00, 9894.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df,train_size=0.8,test_size=0.2)\n",
    "\n",
    "print(f\"학습 세트의 크기: {len(train_df)} 행\")\n",
    "print(f\"검증 세트의 크기: {len(val_df)} 행\")\n",
    "\n",
    "train_loader = process_dataframe(train_df,device,100,True)\n",
    "val_loader = process_dataframe(val_df,device,1000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47c1b26f-219c-4611-9725-09273f1ef0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import LSTM\n",
    "from Model import Transformer, PositionalEncoding\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1f979-cd2b-403d-adfa-28d9d39a6b92",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d065c33-266a-43af-924c-c76f35f47549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer):\n",
    "    acc = 0\n",
    "    prev_acc = 0\n",
    "    cnt = 0\n",
    "    for e in range(epoch):\n",
    "        NN.to(device)\n",
    "        loss_sum = 0\n",
    "        NN.train()\n",
    "        for x, attention,t in train_loader:\n",
    "            y = NN(x,attention)\n",
    "            loss = loss_function(y,t)\n",
    "            loss_sum += loss.item()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_sum /= len(train_loader)\n",
    "    \n",
    "        NN.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, attention, t in val_loader:\n",
    "                x = x.to(device)\n",
    "                attention = attention.to(device)\n",
    "                t = t.to(device)\n",
    "    \n",
    "                y = NN(x, attention)\n",
    "                correct += (y.argmax(dim=-1) == t).sum().item()\n",
    "                total += len(x)\n",
    "        acc = correct / total\n",
    "    \n",
    "        if acc <= prev_acc:\n",
    "            cnt += 1\n",
    "        else :\n",
    "            torch.save(NN.state_dict(), \"Sentiment.pt\")\n",
    "            cnt = 0\n",
    "            prev_acc = acc\n",
    "        \n",
    "        print(f\"epoch  {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "        \n",
    "        if cnt >= 5:\n",
    "            print(\"train halted\")\n",
    "            break\n",
    "            \n",
    "    print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a68f657-9e9f-47d8-b477-2cb4ec4601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN = LSTM(vocab_size=vocab_size,embedding_dim=embedding_dim,hidden_dim=64,output_dim=7,n_layers=4,bidirectional=True,dropout_p=0.1)\n",
    "# NN.to(device)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(NN.parameters(),lr=0.001)\n",
    "# epoch = 500\n",
    "# LSTM_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef3a0ef-22f3-4ed6-8b5d-4676131d5f34",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b599944c-bab7-4d2e-986e-bf50e02b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformer_Train(epoch, device, train_loader, val_loader, NN, loss_function, optimizer,scheduler):\n",
    "    acc = 0\n",
    "    prev_acc = 0\n",
    "    cnt = 0\n",
    "    for e in range(epoch):\n",
    "        NN.to(device)\n",
    "        loss_sum = 0\n",
    "        NN.train()\n",
    "        for x, attention, t in tqdm(train_loader, desc=f\"Epoch {e+1} Training\",leave=False):\n",
    "            x = x.to(device)\n",
    "            attention = attention.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            y = NN(x, attention)\n",
    "            loss = loss_function(y, t)\n",
    "            loss_sum += loss.item()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm(NN.parameters(),1.0)\n",
    "            optimizer.step()\n",
    "        loss_sum /= len(train_loader)\n",
    "        \n",
    "        NN.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, attention, t in tqdm(val_loader, desc=f\"Epoch {e+1} Validation\",leave=False):\n",
    "                x = x.to(device)\n",
    "                attention = attention.to(device)\n",
    "                t = t.to(device)\n",
    "        \n",
    "                y = NN(x, attention)\n",
    "                correct += (y.argmax(dim=-1) == t).sum().item()\n",
    "                total += len(x)\n",
    "        acc = correct / total\n",
    "        \n",
    "        if acc <= prev_acc:\n",
    "            cnt += 1\n",
    "        else :\n",
    "            torch.save(NN.state_dict(), \"Sentiment.pt\")\n",
    "            cnt = 0\n",
    "            prev_acc = acc\n",
    "\n",
    "        scheduler.step(acc)\n",
    "        \n",
    "        print(f\"epoch   {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "        \n",
    "        if cnt >= 5:\n",
    "            print(\"train halted\")\n",
    "            break\n",
    "            \n",
    "    print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1875b120-9a16-4755-ac20-2d2ffa247ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|                                                                       | 0/1170 [00:00<?, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_24684\\2332016856.py:20: FutureWarning: `torch.nn.utils.clip_grad_norm` is now deprecated in favor of `torch.nn.utils.clip_grad_norm_`.\n",
      "  nn.utils.clip_grad_norm(NN.parameters(),1.0)\n",
      "Epoch 1 Validation:   0%|                                                                       | 0/29 [00:00<?, ?it/s]C:\\Users\\Administrator\\anaconda3\\envs\\tensor\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n",
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1\t\tloss 1.611574331308\tacc 0.4478\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   2\t\tloss 1.521470283749\tacc 0.4758\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   3\t\tloss 1.440676615279\tacc 0.5001\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   4\t\tloss 1.392663119186\tacc 0.5133\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   5\t\tloss 1.358114989191\tacc 0.5215\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   6\t\tloss 1.329676023304\tacc 0.5304\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   7\t\tloss 1.304244029420\tacc 0.5386\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   8\t\tloss 1.282142842020\tacc 0.5440\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   9\t\tloss 1.262910174254\tacc 0.5495\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10\t\tloss 1.244619312144\tacc 0.5542\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11\t\tloss 1.227673865129\tacc 0.5587\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\u001b[33m\"\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m\"\u001b[39m,factor=\u001b[32m0.5\u001b[39m,patience=\u001b[32m3\u001b[39m,)\n\u001b[32m      5\u001b[39m epoch = \u001b[32m500\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mTransformer_Train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mTransformer_Train\u001b[39m\u001b[34m(epoch, device, train_loader, val_loader, NN, loss_function, optimizer, scheduler)\u001b[39m\n\u001b[32m     14\u001b[39m y = NN(x, attention)\n\u001b[32m     15\u001b[39m loss = loss_function(y, t)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m loss_sum += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.zero_grad()\n\u001b[32m     19\u001b[39m loss.backward()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "NN = Transformer(vocab_size=vocab_size,embedding_dim=128,hidden_dim=16,output_dim=7,n_layers=2,n_heads=4,dropout_p=0.05,max_len=150,pad_token_id=0)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(NN.parameters(),lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"max\",factor=0.5,patience=3,)\n",
    "epoch = 500\n",
    "Transformer_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8789baa-6fb4-4cac-84bc-84cf7971e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"Sentiment.pt\",weights_only=False)\n",
    "# torch.save(model,f\"{saveFilePath}train_15.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7028c5e-4cf0-4fd1-914d-ca3f77a267ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
