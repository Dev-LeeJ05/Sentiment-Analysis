{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c84beab-fdd3-4b92-b4ff-53216eb51626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from WordPieceTokenizer import WordPieceTokenizer as Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "dataFilePath = 'datasets/'\n",
    "saveFilePath = 'saves/'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = Tokenizer(f'{dataFilePath}sentiment_vocab/vocab.txt',do_lower_case=False,strip_accents=False,clean_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da38b69e-5ccd-4751-a66e-934077285c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>발화</th>\n",
       "      <th>감정</th>\n",
       "      <th>str_len</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 2376 2347 1993 10402 1051 2699 16526 1047 3 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>24</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 2083 189 2413 18370 2145 3 0 0 0 0 0 0 0 0 0...</td>\n",
       "      <td>불안</td>\n",
       "      <td>12</td>\n",
       "      <td>1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 2097 4680 1398 18353 1037 5411 1191 3 0 0 0 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>14</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 10126 21684 2664 18111 2596 3 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>불안</td>\n",
       "      <td>13</td>\n",
       "      <td>1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 2246 2907 10620 1011 1271 2670 3 0 0 0 0 0 0...</td>\n",
       "      <td>불안</td>\n",
       "      <td>11</td>\n",
       "      <td>1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  발화  감정  str_len  \\\n",
       "0  2 2376 2347 1993 10402 1051 2699 16526 1047 3 ...  불안       24   \n",
       "1  2 2083 189 2413 18370 2145 3 0 0 0 0 0 0 0 0 0...  불안       12   \n",
       "2  2 2097 4680 1398 18353 1037 5411 1191 3 0 0 0 ...  불안       14   \n",
       "3  2 10126 21684 2664 18111 2596 3 0 0 0 0 0 0 0 ...  불안       13   \n",
       "4  2 2246 2907 10620 1011 1271 2670 3 0 0 0 0 0 0...  불안       11   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "1  1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "2  1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "3  1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "4  1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...   \n",
       "\n",
       "                                      token_type_ids  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "4  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{dataFilePath}sentiment_train.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b88c422-88f4-4e80-9f82-53fdcb86b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['감정'] == '불안'),'감정'] = 0\n",
    "df.loc[(df['감정'] == '당황'),'감정'] = 1\n",
    "df.loc[(df['감정'] == '분노'),'감정'] = 2\n",
    "df.loc[(df['감정'] == '슬픔'),'감정'] = 3\n",
    "df.loc[(df['감정'] == '중립'),'감정'] = 4\n",
    "df.loc[(df['감정'] == '행복'),'감정'] = 5\n",
    "df.loc[(df['감정'] == '혐오'),'감정'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404c17eb-9dbf-4369-81f5-218c8a2be20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(data_frame, device,batch_size,shuffle=False):\n",
    "    tensor_x_list = []\n",
    "    attentions = []\n",
    "    for i in tqdm(range(len(data_frame))):\n",
    "        token = data_frame.iloc[i,0]\n",
    "        token = token.split(\" \")\n",
    "        token_list = []\n",
    "        for t in token:\n",
    "            token_list.append(int(t))\n",
    "        tensor_x_list.append(token_list)\n",
    "        \n",
    "        attention = data_frame.iloc[i,3]\n",
    "        attention = attention.split(\" \")\n",
    "        attention_list = []\n",
    "        for a in attention:\n",
    "            attention_list.append(int(a))\n",
    "        attentions.append(attention_list)\n",
    "\n",
    "    tensor_x = torch.tensor(tensor_x_list, dtype=torch.long, device=device)\n",
    "    tensor_attention = torch.tensor(attentions, dtype=torch.long, device=device)\n",
    "    tensor_t = torch.tensor(data_frame[\"감정\"].values.tolist(), dtype=torch.long, device=device)\n",
    "\n",
    "    dataset = TensorDataset(tensor_x,tensor_attention,tensor_t)\n",
    "\n",
    "    loader = DataLoader(dataset,batch_size=batch_size,shuffle=shuffle,drop_last=True)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5776764d-05d3-46df-909d-2bc90d0f23ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트의 크기: 131713 행\n",
      "검증 세트의 크기: 14635 행\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 131713/131713 [00:16<00:00, 8091.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 14635/14635 [00:01<00:00, 8431.57it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df,train_size=0.9,test_size=0.1)\n",
    "\n",
    "print(f\"학습 세트의 크기: {len(train_df)} 행\")\n",
    "print(f\"검증 세트의 크기: {len(val_df)} 행\")\n",
    "\n",
    "train_loader = process_dataframe(train_df,device,100,True)\n",
    "val_loader = process_dataframe(val_df,device,1000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c1b26f-219c-4611-9725-09273f1ef0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Model import LSTM\n",
    "from Model import Transformer, PositionalEncoding\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1f979-cd2b-403d-adfa-28d9d39a6b92",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d065c33-266a-43af-924c-c76f35f47549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer):\n",
    "    acc = 0\n",
    "    prev_acc = 0\n",
    "    cnt = 0\n",
    "    for e in range(epoch):\n",
    "        NN.to(device)\n",
    "        loss_sum = 0\n",
    "        NN.train()\n",
    "        for x, attention,t in train_loader:\n",
    "            y = NN(x,attention)\n",
    "            loss = loss_function(y,t)\n",
    "            loss_sum += loss.item()\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_sum /= len(train_loader)\n",
    "    \n",
    "        NN.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, attention, t in val_loader:\n",
    "                x = x.to(device)\n",
    "                attention = attention.to(device)\n",
    "                t = t.to(device)\n",
    "    \n",
    "                y = NN(x, attention)\n",
    "                correct += (y.argmax(dim=-1) == t).sum().item()\n",
    "                total += len(x)\n",
    "        acc = correct / total\n",
    "    \n",
    "        if acc <= prev_acc:\n",
    "            cnt += 1\n",
    "        else :\n",
    "            torch.save(NN.state_dict(), \"Sentiment.pt\")\n",
    "            cnt = 0\n",
    "            prev_acc = acc\n",
    "        \n",
    "        print(f\"epoch  {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "        \n",
    "        if cnt >= 5:\n",
    "            print(\"train halted\")\n",
    "            break\n",
    "            \n",
    "    print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a68f657-9e9f-47d8-b477-2cb4ec4601f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN = LSTM(vocab_size=vocab_size,embedding_dim=embedding_dim,hidden_dim=64,output_dim=7,n_layers=4,bidirectional=True,dropout_p=0.1)\n",
    "# NN.to(device)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(NN.parameters(),lr=0.001)\n",
    "# epoch = 500\n",
    "# LSTM_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef3a0ef-22f3-4ed6-8b5d-4676131d5f34",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b599944c-bab7-4d2e-986e-bf50e02b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformer_Train(epoch, device, train_loader, val_loader, NN, loss_function, optimizer):\n",
    "    acc = 0\n",
    "    prev_acc = 0\n",
    "    cnt = 0\n",
    "    for e in range(epoch):\n",
    "        NN.to(device)\n",
    "        loss_sum = 0\n",
    "        NN.train()\n",
    "        for x, attention, t in tqdm(train_loader, desc=f\"Epoch {e+1} Training\"):\n",
    "            x = x.to(device)\n",
    "            attention = attention.to(device)\n",
    "            t = t.to(device)\n",
    "\n",
    "            y = NN(x, attention)\n",
    "            loss = loss_function(y, t)\n",
    "            loss_sum += loss.item()\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_sum /= len(train_loader)\n",
    "        \n",
    "        NN.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, attention, t in tqdm(val_loader, desc=f\"Epoch {e+1} Validation\"):\n",
    "                x = x.to(device)\n",
    "                attention = attention.to(device)\n",
    "                t = t.to(device)\n",
    "        \n",
    "                y = NN(x, attention)\n",
    "                correct += (y.argmax(dim=-1) == t).sum().item()\n",
    "                total += len(x)\n",
    "        acc = correct / total\n",
    "        \n",
    "        if acc <= prev_acc:\n",
    "            cnt += 1\n",
    "        else :\n",
    "            torch.save(NN.state_dict(), \"Sentiment.pt\")\n",
    "            cnt = 0\n",
    "            prev_acc = acc\n",
    "        \n",
    "        print(f\"epoch   {e+1}\\t\\tloss {loss_sum:.12f}\\tacc {acc:.4f}\\tcnt {cnt}\")\n",
    "        \n",
    "        if cnt >= 5:\n",
    "            print(\"train halted\")\n",
    "            break\n",
    "            \n",
    "    print(\"---------- 학습 종료 ----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1875b120-9a16-4755-ac20-2d2ffa247ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.81it/s]\n",
      "Epoch 1 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1\t\tloss 1.371431331971\tacc 0.5767\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.81it/s]\n",
      "Epoch 2 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   2\t\tloss 1.160224917176\tacc 0.5956\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.83it/s]\n",
      "Epoch 3 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   3\t\tloss 1.063455206613\tacc 0.6102\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.82it/s]\n",
      "Epoch 4 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   4\t\tloss 1.000909667850\tacc 0.6222\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.82it/s]\n",
      "Epoch 5 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   5\t\tloss 0.964767390838\tacc 0.6279\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.82it/s]\n",
      "Epoch 6 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   6\t\tloss 0.931987685739\tacc 0.6256\tcnt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.81it/s]\n",
      "Epoch 7 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   7\t\tloss 0.909927549150\tacc 0.6274\tcnt 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.82it/s]\n",
      "Epoch 8 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   8\t\tloss 0.895576115395\tacc 0.6229\tcnt 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|████████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.82it/s]\n",
      "Epoch 9 Validation: 100%|██████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   9\t\tloss 0.881080329011\tacc 0.6344\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.85it/s]\n",
      "Epoch 10 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10\t\tloss 0.870104484605\tacc 0.6347\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.84it/s]\n",
      "Epoch 11 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11\t\tloss 0.859852410485\tacc 0.6361\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.85it/s]\n",
      "Epoch 12 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12\t\tloss 0.857323152420\tacc 0.6302\tcnt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.84it/s]\n",
      "Epoch 13 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13\t\tloss 0.847469815768\tacc 0.6240\tcnt 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.84it/s]\n",
      "Epoch 14 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14\t\tloss 0.858280455423\tacc 0.6275\tcnt 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.84it/s]\n",
      "Epoch 15 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   15\t\tloss 0.844552876330\tacc 0.6320\tcnt 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.84it/s]\n",
      "Epoch 16 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   16\t\tloss 0.844311154694\tacc 0.6365\tcnt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:45<00:00,  5.84it/s]\n",
      "Epoch 17 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   17\t\tloss 0.860271964050\tacc 0.6330\tcnt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:46<00:00,  5.80it/s]\n",
      "Epoch 18 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   18\t\tloss 0.846316316857\tacc 0.6264\tcnt 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|███████████████████████████████████████████████████████████| 1317/1317 [03:47<00:00,  5.80it/s]\n",
      "Epoch 19 Validation: 100%|█████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   19\t\tloss 0.847210977914\tacc 0.6284\tcnt 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training:   3%|██                                                           | 45/1317 [00:07<03:41,  5.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(NN\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      4\u001b[0m epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m----> 5\u001b[0m Transformer_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer)\n",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m, in \u001b[0;36mTransformer_Train\u001b[1;34m(epoch, device, train_loader, val_loader, NN, loss_function, optimizer)\u001b[0m\n\u001b[0;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m NN(x, attention)\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(y, t)\n\u001b[1;32m---> 16\u001b[0m loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NN = Transformer(vocab_size=vocab_size,embedding_dim=256,hidden_dim=16,output_dim=7,n_layers=4,n_heads=16,dropout_p=0.1,max_len=250,pad_token_id=0)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NN.parameters(),lr=0.001)\n",
    "epoch = 500\n",
    "Transformer_Train(epoch,device,train_loader,val_loader,NN,loss_function,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8789baa-6fb4-4cac-84bc-84cf7971e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"Sentiment.pt\",weights_only=False)\n",
    "torch.save(model,f\"{saveFilePath}train_14.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7028c5e-4cf0-4fd1-914d-ca3f77a267ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
