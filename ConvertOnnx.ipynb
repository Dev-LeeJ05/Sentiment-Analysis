{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76fd80ee-edb5-4a8b-a9b5-69cc48f81fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.onnx\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "# import onnxoptimizer\n",
    "from Model import Transformer, PositionalEncoding\n",
    "from WordPieceTokenizer import WordPieceTokenizer as Tokenizer\n",
    "\n",
    "saveFilePath = 'saves/'\n",
    "tokenizer = Tokenizer(f'{saveFilePath}vocab.txt',do_lower_case=False,strip_accents=False,clean_text=True)\n",
    "VOCAB_SIZE = tokenizer.get_vocab_size()\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18ff46a-dcbf-4530-89ed-6f0c60535615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 saves/onnx/Sentiment_model.onnx으로 성공적으로 변환되었습니다.\n"
     ]
    }
   ],
   "source": [
    "save_NN = Transformer(vocab_size=VOCAB_SIZE,embedding_dim=128,hidden_dim=32,output_dim=7,n_layers=2,n_heads=16,dropout_p=0.1,max_len=128,pad_token_id=0)\n",
    "load_model_path = \"Sentiment.pt\"\n",
    "save_NN.load_state_dict(torch.load(load_model_path, map_location=device))\n",
    "save_NN.eval()\n",
    "save_NN.to(device)\n",
    "\n",
    "batch_size = 1\n",
    "dummy_text_input = torch.randint(0, VOCAB_SIZE, (batch_size, MAX_SEQUENCE_LENGTH),dtype=torch.long).to(device)\n",
    "dummy_attention_mask = torch.ones(batch_size,MAX_SEQUENCE_LENGTH,dtype=torch.long).to(device)\n",
    "dummy_attention_mask[:, 64:] = 0\n",
    "\n",
    "onnx_filename = f\"{saveFilePath}onnx/Sentiment_model.onnx\"\n",
    "\n",
    "input_names = [\"text_input\",\"attention_mask\"]\n",
    "output_names = [\"output_logits\"]\n",
    "dynamic_axes = {\n",
    "    \"text_input\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "    \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "    \"output_logits\": {0: \"batch_size\"}\n",
    "}\n",
    "\n",
    "try:\n",
    "    torch.onnx.export(save_NN,                           # 변환할 모델\n",
    "                      (dummy_text_input, dummy_attention_mask), # 모델 입력 (튜플 형태)\n",
    "                      onnx_filename,                # 저장할 ONNX 파일명\n",
    "                      export_params=True,           # 모델의 학습된 파라미터 포함 여부\n",
    "                      opset_version=15,             # ONNX opset 버전 (일반적으로 9, 11, 13, 14, 15, 16, 17)\n",
    "                                                    # 높을수록 최신 연산을 지원하지만, 런타임 호환성 고려\n",
    "                      do_constant_folding=True,     # 상수 폴딩 최적화\n",
    "                      input_names=input_names,      # 입력 노드의 이름\n",
    "                      output_names=output_names,    # 출력 노드의 이름\n",
    "                      dynamic_axes=dynamic_axes     # 동적 차원 설정 (선택 사항)\n",
    "                     )\n",
    "    print(f\"모델이 {onnx_filename}으로 성공적으로 변환되었습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ONNX 변환 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6513800-e41e-4870-9c86-42e3718be352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX 모델 유효성 검사 통과.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    onnx_model = onnx.load(onnx_filename)\n",
    "    onnx.checker.check_model(onnx_model) # 모델의 유효성 검사\n",
    "    print(\"ONNX 모델 유효성 검사 통과.\")\n",
    "except ImportError:\n",
    "    print(\"onnx 패키지가 설치되어 있지 않습니다. pip install onnx로 설치하세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"ONNX 모델 검사 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4336eb4a-a3a3-440a-8375-2a6be0a55366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 모델 출력 형태: (1, 7)\n",
      "PyTorch 모델 출력 (상위 5개 값): [ 0.06537803 -2.1254883   1.4423075   0.34495094 -0.649205  ]\n",
      "\n",
      "ONNX 모델 입력 이름: ['text_input', 'attention_mask']\n",
      "ONNX 모델 출력 이름: ['output_logits']\n",
      "ONNX Runtime 출력 형태: (1, 7)\n",
      "ONNX Runtime 출력 (상위 5개 값): [ 0.06537812 -2.125488    1.4423069   0.34495088 -0.6492054 ]\n",
      "\n",
      "PyTorch와 ONNX Runtime 모델 출력이 일치합니다! ✅\n"
     ]
    }
   ],
   "source": [
    "# --- 1. PyTorch 모델 준비 (기존 코드에서 사용한 것과 동일) ---\n",
    "NN = Transformer(vocab_size=VOCAB_SIZE, embedding_dim=128, hidden_dim=32, output_dim=7,\n",
    "                n_layers=2, n_heads=16, dropout_p=0.1, max_len=128, pad_token_id=0)\n",
    "NN.load_state_dict(torch.load(load_model_path, map_location='cpu'))\n",
    "NN.eval()\n",
    "\n",
    "# --- 2. 더미 입력 준비 (ONNX 변환 시 사용한 것과 동일) ---\n",
    "batch_size = 1\n",
    "\n",
    "dummy_text_input_cpu = torch.randint(0, VOCAB_SIZE, (batch_size, MAX_SEQUENCE_LENGTH), dtype=torch.long).cpu()\n",
    "dummy_attention_mask_cpu = torch.ones(batch_size, MAX_SEQUENCE_LENGTH, dtype=torch.long).cpu()\n",
    "\n",
    "# --- 3. PyTorch 모델로 추론 ---\n",
    "with torch.no_grad():\n",
    "    pytorch_output = NN(dummy_text_input_cpu, dummy_attention_mask_cpu).cpu().numpy()\n",
    "\n",
    "print(f\"PyTorch 모델 출력 형태: {pytorch_output.shape}\")\n",
    "print(f\"PyTorch 모델 출력 (상위 5개 값): {pytorch_output[0, :5]}\")\n",
    "\n",
    "# --- 4. ONNX Runtime 세션 생성 ---\n",
    "onnx_model_path = onnx_filename\n",
    "\n",
    "try:\n",
    "    providers = ['CPUExecutionProvider'] \n",
    "\n",
    "    ort_session = ort.InferenceSession(onnx_model_path, providers=providers)\n",
    "    \n",
    "    onnx_inputs = {inp.name: inp for inp in ort_session.get_inputs()}\n",
    "    onnx_outputs = {out.name: out for out in ort_session.get_outputs()}\n",
    "\n",
    "    print(f\"\\nONNX 모델 입력 이름: {[inp.name for inp in ort_session.get_inputs()]}\")\n",
    "    print(f\"ONNX 모델 출력 이름: {[out.name for out in ort_session.get_outputs()]}\")\n",
    "\n",
    "    # --- 5. ONNX Runtime으로 추론 ---\n",
    "    ort_inputs = {\n",
    "        \"text_input\": dummy_text_input_cpu.numpy(),\n",
    "        \"attention_mask\": dummy_attention_mask_cpu.numpy()\n",
    "    }\n",
    "\n",
    "    ort_output = ort_session.run(\n",
    "        [onnx_outputs['output_logits'].name], \n",
    "        ort_inputs\n",
    "    )[0]\n",
    "\n",
    "    print(f\"ONNX Runtime 출력 형태: {ort_output.shape}\")\n",
    "    print(f\"ONNX Runtime 출력 (상위 5개 값): {ort_output[0, :5]}\")\n",
    "\n",
    "    # --- 6. PyTorch와 ONNX Runtime 출력 비교 ---\n",
    "    tolerance = 1e-5 \n",
    "    if np.allclose(pytorch_output, ort_output, atol=tolerance):\n",
    "        print(\"\\nPyTorch와 ONNX Runtime 모델 출력이 일치합니다! ✅\")\n",
    "    else:\n",
    "        print(\"\\nPyTorch와 ONNX Runtime 모델 출력이 다릅니다! ❌\")\n",
    "        diff = np.abs(pytorch_output - ort_output)\n",
    "        print(f\"최대 절대 오차: {np.max(diff)}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"onnxruntime 패키지가 설치되어 있지 않습니다. pip install onnxruntime로 설치하세요.\")\n",
    "except Exception as e:\n",
    "    print(f\"ONNX Runtime 추론 또는 비교 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae37b28-e27b-4a1e-860d-1700f1e7f0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
