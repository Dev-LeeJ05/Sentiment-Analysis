{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bbb771d-ddc3-4574-8c67-fe4a5005099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (BertConfig,BertForMaskedLM,get_linear_schedule_with_warmup)\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from PretrainDataset import TokenizedDataset\n",
    "from PretrainDataset import CustomDataCollatorForMLM\n",
    "import shutil\n",
    "from WordPieceTokenizer import WordPieceTokenizer\n",
    "\n",
    "datasetsPath = \"datasets/\"\n",
    "PREPROCESSED_TEXT_DIR = f'{datasetsPath}preprocessed_wiki_text'\n",
    "TOKENIZER_OUTPUT_DIR = f'{datasetsPath}custom_tokenizer_output'\n",
    "VOCAB_FILE_PATH = os.path.join(TOKENIZER_OUTPUT_DIR, 'vocab.txt')\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_TRAIN_EPOCHS = 5\n",
    "LEARNING_RATE = 5e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_STEPS = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e2509f0-27d1-4a27-81d0-9ec5a2df6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    concatenated_text = \" \".join(examples[\"text\"])\n",
    "    \n",
    "    encoded_output = tokenizer.encode(\n",
    "        concatenated_text,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    return {k: [v] for k, v in encoded_output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54d834f-9755-4f65-877a-637f0932798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 정의 WordPieceTokenizer 로드 중...\n",
      "사용자 정의 WordPieceTokenizer 로드 완료. 어휘집 크기: 32000\n",
      "총 8개의 텍스트 파일 로드 시작...\n",
      "원시 데이터셋 로드 완료. 총 702964개의 샘플.\n"
     ]
    }
   ],
   "source": [
    "print(\"사용자 정의 WordPieceTokenizer 로드 중...\")\n",
    "try:\n",
    "    tokenizer = WordPieceTokenizer(vocab_file_path=VOCAB_FILE_PATH, do_lower_case=False, strip_accents=False, clean_text=True)\n",
    "    print(f\"사용자 정의 WordPieceTokenizer 로드 완료. 어휘집 크기: {tokenizer.get_vocab_size()}\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: 토크나이저 로드 중 오류 발생: {e}\")\n",
    "    print(f\"오류: '{VOCAB_FILE_PATH}' 파일이 올바르게 존재하는지 확인하세요.\")\n",
    "    exit()\n",
    "\n",
    "text_files = [os.path.join(PREPROCESSED_TEXT_DIR, f) for f in os.listdir(PREPROCESSED_TEXT_DIR) if f.endswith('.txt')]\n",
    "\n",
    "if not text_files:\n",
    "    print(f\"오류: '{PREPROCESSED_TEXT_DIR}' 디렉토리에 텍스트 파일이 없습니다. 전처리 단계를 먼저 완료하세요.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"총 {len(text_files)}개의 텍스트 파일 로드 시작...\")\n",
    "raw_dataset = load_dataset(\"text\", data_files={\"train\": text_files}, split=\"train\")\n",
    "print(f\"원시 데이터셋 로드 완료. 총 {len(raw_dataset)}개의 샘플.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235d8085-4dfe-4881-8fbe-a7a45e126515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 토큰화 및 청킹 시작...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b492ad57581d458bb340476e8a80ab59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/702964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 토큰화 및 청킹 완료.\n",
      "토큰화된 데이터셋 샘플 수: 703\n",
      "토큰화된 데이터셋 첫 번째 샘플 예시: dict_keys(['input_ids', 'attention_mask', 'token_type_ids'])\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터셋 토큰화 및 청킹 시작...\")\n",
    "tokenized_dataset = raw_dataset.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=[\"text\"],\n",
    ")\n",
    "\n",
    "train_dataset = TokenizedDataset(tokenized_dataset)\n",
    "\n",
    "print(\"데이터셋 토큰화 및 청킹 완료.\")\n",
    "print(f\"토큰화된 데이터셋 샘플 수: {len(train_dataset)}\")\n",
    "print(f\"토큰화된 데이터셋 첫 번째 샘플 예시: {train_dataset[0].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6d1ecd-c4e0-4497-a15a-092e05502990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch DataLoader 생성 완료. 배치 크기: 16\n"
     ]
    }
   ],
   "source": [
    "data_collator = CustomDataCollatorForMLM(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=os.cpu_count() // 2 or 1\n",
    ")\n",
    "print(f\"PyTorch DataLoader 생성 완료. 배치 크기: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c429a5f9-967b-427a-b61c-3ce65c7a2a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT 모델 초기화 완료. 총 파라미터 수: 110355968\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.get_vocab_size(),\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=MAX_SEQUENCE_LENGTH,\n",
    "    type_vocab_size=2,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict=True\n",
    ")\n",
    "\n",
    "model = BertForMaskedLM(config=config)\n",
    "print(f\"BERT 모델 초기화 완료. 총 파라미터 수: {model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58a595e-4c47-4319-9aba-034d4431fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PyTorch 수동 학습 루프 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████| 44/44 [00:31<00:00,  1.38it/s, loss=6.7826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 완료. 평균 손실: 6.7285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████| 44/44 [00:30<00:00,  1.43it/s, loss=6.4677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 완료. 평균 손실: 6.7321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████| 44/44 [00:31<00:00,  1.42it/s, loss=6.8644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 완료. 평균 손실: 6.6983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████| 44/44 [00:31<00:00,  1.41it/s, loss=6.5809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 완료. 평균 손실: 6.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████████████████| 44/44 [00:31<00:00,  1.40it/s, loss=6.6636]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 완료. 평균 손실: 6.6617\n",
      "수동 학습 루프 완료.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\n--- PyTorch 수동 학습 루프 시작 ---\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "total_training_steps = len(train_dataloader) * NUM_TRAIN_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=total_training_steps\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_TRAIN_EPOCHS):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1} 완료. 평균 손실: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"수동 학습 루프 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d662c0-7018-4fc0-a038-abcacf20fb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 모델과 사용자 정의 토크나이저의 vocab.txt가 './Pretrained'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_MODEL_DIR = \"./Pretrained\"\n",
    "os.makedirs(OUTPUT_MODEL_DIR, exist_ok=True)\n",
    "model.save_pretrained(OUTPUT_MODEL_DIR)\n",
    "import shutil\n",
    "shutil.copy(VOCAB_FILE_PATH, os.path.join(OUTPUT_MODEL_DIR, 'vocab.txt'))\n",
    "print(f\"학습된 모델과 사용자 정의 토크나이저의 vocab.txt가 '{OUTPUT_MODEL_DIR}'에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34dbcc-686e-4256-9c1f-6c403e56a3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
