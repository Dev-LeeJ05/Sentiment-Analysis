{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051e5a6d-f416-43d1-a8b7-6311dab86336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from Model import Transformer, PositionalEncoding\n",
    "from TrainDataset import prepare_classification_dataset, tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61aac92-20b7-4d5b-87f6-9b21419e9e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 df 크기: 138664\n",
      "원본 df 감정 분포 (매핑 후): Counter({4: 48501, 3: 24748, 2: 18171, 0: 14651, 5: 13727, 1: 13224, 6: 5642})\n",
      "학습 데이터프레임 크기: 110931\n",
      "검증 데이터프레임 크기: 27733\n",
      "학습 데이터프레임 감정 분포: Counter({4: 38801, 3: 19798, 2: 14537, 0: 11721, 5: 10981, 1: 10579, 6: 4514})\n",
      "검증 데이터프레임 감정 분포: Counter({4: 9700, 3: 4950, 2: 3634, 0: 2930, 5: 2746, 1: 2645, 6: 1128})\n",
      "학습 데이터 파싱 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a6b4a79ec24324a1d32677a8bffdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "데이터 파싱 중:   0%|          | 0/110931 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증 데이터 파싱 중...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e10d4ee94894af0ae268fb3d1c54cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "데이터 파싱 중:   0%|          | 0/27733 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋 크기: 110931\n",
      "검증 데이터셋 크기: 27733\n",
      "학습 DataLoader 배치 수: 3467\n",
      "검증 DataLoader 배치 수: 867\n",
      "\n",
      "설정된 전역 변수:\n",
      "  VOCAB_SIZE: 32000\n",
      "  MAX_LEN: 128\n",
      "  OUTPUT_DIM: 7\n",
      "  PAD_TOKEN_ID: 0\n",
      "\n",
      "사용 가능한 장치: cuda\n",
      "\n",
      "Optuna 최적화 버전: v2 (버전 파일: saves\\optuna_version.txt)\n",
      "모든 Optuna Trial 로그 및 모델은 'optuna_runs\\v2' 아래에 저장됩니다.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'datasets/sentiment_train.csv', index_col=0)\n",
    "\n",
    "# '감정' 레이블을 숫자로 매핑\n",
    "df.loc[(df['감정'] == '불안'), '감정'] = 0\n",
    "df.loc[(df['감정'] == '당황'), '감정'] = 1\n",
    "df.loc[(df['감정'] == '분노'), '감정'] = 2\n",
    "df.loc[(df['감정'] == '슬픔'), '감정'] = 3\n",
    "df.loc[(df['감정'] == '중립'), '감정'] = 4\n",
    "df.loc[(df['감정'] == '행복'), '감정'] = 5\n",
    "df.loc[(df['감정'] == '혐오'), '감정'] = 6\n",
    "\n",
    "print(f\"원본 df 크기: {len(df)}\")\n",
    "print(f\"원본 df 감정 분포 (매핑 후): {Counter(df['감정'])}\")\n",
    "\n",
    "train_df, val_df = train_test_split(df, train_size=0.8, test_size=0.2, stratify=df['감정'], random_state=42) # 재현성을 위해 random_state 추가\n",
    "\n",
    "print(f\"학습 데이터프레임 크기: {len(train_df)}\")\n",
    "print(f\"검증 데이터프레임 크기: {len(val_df)}\")\n",
    "print(f\"학습 데이터프레임 감정 분포: {Counter(train_df['감정'])}\")\n",
    "print(f\"검증 데이터프레임 감정 분포: {Counter(val_df['감정'])}\")\n",
    "\n",
    "\n",
    "print(\"학습 데이터 파싱 중...\")\n",
    "train_datasets_dict = prepare_classification_dataset(train_df)\n",
    "print(\"검증 데이터 파싱 중...\")\n",
    "val_datasets_dict = prepare_classification_dataset(val_df)\n",
    "\n",
    "train_datasets = tensor_dataset(train_datasets_dict)\n",
    "val_datasets = tensor_dataset(val_datasets_dict)\n",
    "\n",
    "print(f\"학습 데이터셋 크기: {len(train_datasets)}\")\n",
    "print(f\"검증 데이터셋 크기: {len(val_datasets)}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(\n",
    "    train_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "print(f\"학습 DataLoader 배치 수: {len(train_loader)}\")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_datasets,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "print(f\"검증 DataLoader 배치 수: {len(val_loader)}\")\n",
    "\n",
    "VOCAB_SIZE = 32000\n",
    "MAX_LEN =128\n",
    "OUTPUT_DIM = int(df['감정'].nunique())\n",
    "PAD_TOKEN_ID = 0\n",
    "\n",
    "print(f\"\\n설정된 전역 변수:\")\n",
    "print(f\"  VOCAB_SIZE: {VOCAB_SIZE}\")\n",
    "print(f\"  MAX_LEN: {MAX_LEN}\")\n",
    "print(f\"  OUTPUT_DIM: {OUTPUT_DIM}\")\n",
    "print(f\"  PAD_TOKEN_ID: {PAD_TOKEN_ID}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n사용 가능한 장치: {device}\")\n",
    "\n",
    "VERSION_FILE_PATH = os.path.join('saves', 'optuna_version.txt')\n",
    "\n",
    "OPTUNA_LOG_MODEL_ROOT_DIR = 'optuna_runs'\n",
    "\n",
    "def get_next_version():\n",
    "    os.makedirs('saves', exist_ok=True) \n",
    "    current_version = 0\n",
    "    if os.path.exists(VERSION_FILE_PATH):\n",
    "        with open(VERSION_FILE_PATH, 'r') as f:\n",
    "            try:\n",
    "                current_version = int(f.read().strip())\n",
    "            except ValueError:\n",
    "                current_version = 0\n",
    "    next_version = current_version + 1\n",
    "    with open(VERSION_FILE_PATH, 'w') as f:\n",
    "        f.write(str(next_version))\n",
    "    return next_version\n",
    "\n",
    "CURRENT_OPTUNA_VERSION = get_next_version()\n",
    "print(f\"\\nOptuna 최적화 버전: v{CURRENT_OPTUNA_VERSION} (버전 파일: {VERSION_FILE_PATH})\")\n",
    "\n",
    "OPTUNA_VERSION_DIR = os.path.join(OPTUNA_LOG_MODEL_ROOT_DIR, f'v{CURRENT_OPTUNA_VERSION}')\n",
    "os.makedirs(OPTUNA_VERSION_DIR, exist_ok=True)\n",
    "print(f\"모든 Optuna Trial 로그 및 모델은 '{OPTUNA_VERSION_DIR}' 아래에 저장됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f581c3-96ac-42de-9c85-80590f798ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transformer_Train(epoch, device, train_loader, val_loader, NN, loss_function, optimizer, scheduler_plateau,\n",
    "                      warmup_epochs, log_dir, save_path, patience, trial=None):\n",
    "    best_val_f1_weighted = 0.0\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    print(f\"  [Trial {trial.number}] TensorBoard 로그 디렉토리: {log_dir}\")\n",
    "\n",
    "    if warmup_epochs > 0:\n",
    "        initial_lr = optimizer.param_groups[0]['lr']\n",
    "        warmup_lr_schedule = lambda e: (e + 1) / warmup_epochs if e < warmup_epochs else 1.0\n",
    "\n",
    "    for e in range(1, epoch + 1):\n",
    "        NN.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        if warmup_epochs > 0 and e <= warmup_epochs:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = initial_lr * warmup_lr_schedule(e - 1)\n",
    "\n",
    "        for batch_idx, (data, attention_mask, labels) in enumerate(train_loader):\n",
    "            data, attention_mask, labels = data.to(device), attention_mask.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = NN(data, attention_mask)\n",
    "            loss = loss_function(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        NN.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        with torch.no_grad():\n",
    "            for data, attention_mask, labels in val_loader:\n",
    "                data, attention_mask, labels = data.to(device), attention_mask.to(device), labels.to(device)\n",
    "                predictions = NN(data, attention_mask)\n",
    "                val_preds.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_true, val_preds)\n",
    "        val_f1_weighted = f1_score(val_true, val_preds, average='weighted', zero_division=0)\n",
    "        val_f1_macro = f1_score(val_true, val_preds, average='macro', zero_division=0)\n",
    "\n",
    "        if e > warmup_epochs:\n",
    "            scheduler_plateau.step(val_f1_weighted)\n",
    "\n",
    "        if val_f1_weighted > best_val_f1_weighted:\n",
    "            best_val_f1_weighted = val_f1_weighted\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "\n",
    "        print(f\"  [Trial {trial.number}] Epoch {e}\\tTrain Loss: {avg_train_loss:.5f}\\tVal Acc: {val_acc:.4f}\\tVal F1 (Weighted): {val_f1_weighted:.4f}\\tVal F1 (Macro): {val_f1_macro:.4f}\\tNo Improve Epochs: {no_improve_epochs}\")\n",
    "\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, e)\n",
    "        writer.add_scalar('Metrics/Val_Accuracy', val_acc, e)\n",
    "        writer.add_scalar('Metrics/Val_F1_Weighted', val_f1_weighted, e)\n",
    "        writer.add_scalar('Metrics/Val_F1_Macro', val_f1_macro, e)\n",
    "        writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], e)\n",
    "\n",
    "        if trial:\n",
    "            trial.report(val_f1_weighted, e)\n",
    "            if trial.should_prune():\n",
    "                print(f\"Trial {trial.number} is pruned at epoch {e}.\")\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f\"조기 종료: {patience} 에포크 동안 성능 개선 없음. Trial {trial.number} 종료.\")\n",
    "            break\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    return best_val_f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "916700d2-0084-45d5-9fc1-60ea071e7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 1. 하이퍼파라미터 제안\n",
    "    embedding_dim = trial.suggest_categorical('embedding_dim', [128, 256])\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [128, 256, 512])\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 4)\n",
    "    n_heads = trial.suggest_categorical('n_heads', [4, 8, 16])\n",
    "    dropout_p = trial.suggest_float('dropout_p', 0.1, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 5e-6, 5e-5)\n",
    "    warmup_epochs = trial.suggest_int('warmup_epochs', 5, 15)\n",
    "    patience = trial.suggest_int('patience', 10, 20)\n",
    "    use_class_weights = trial.suggest_categorical('use_class_weights', [True, False])\n",
    "\n",
    "    if hidden_dim % n_heads != 0:\n",
    "        raise optuna.exceptions.TrialPruned(f\"hidden_dim ({hidden_dim}) is not divisible by n_heads ({n_heads})\")\n",
    "\n",
    "    # 2. 모델 인스턴스 생성 및 하이퍼파라미터 적용\n",
    "    NN = Transformer(vocab_size=VOCAB_SIZE, embedding_dim=embedding_dim, hidden_dim=hidden_dim,\n",
    "                     output_dim=OUTPUT_DIM, n_layers=n_layers, n_heads=n_heads, dropout_p=dropout_p,\n",
    "                     max_len=MAX_LEN, pad_token_id=PAD_TOKEN_ID).to(device)\n",
    "\n",
    "    class_weights = None\n",
    "    if use_class_weights:\n",
    "        all_train_labels_original = train_df['감정'].values.astype(int)\n",
    "        num_classes = NN.output_dim\n",
    "        label_counts_original = np.bincount(all_train_labels_original, minlength=num_classes)\n",
    "        class_counts_tensor = torch.tensor(label_counts_original, dtype=torch.float)\n",
    "        # 0으로 나누는 것을 방지 (매우 드물게 발생할 수 있는 0개 클래스 방지)\n",
    "        class_counts_tensor = torch.where(class_counts_tensor == 0, torch.tensor(1.0), class_counts_tensor) \n",
    "        class_weights = (class_counts_tensor.sum() / class_counts_tensor).to(device)\n",
    "        print(f\"Trial {trial.number}: 계산된 클래스 가중치: {class_weights.tolist()}\")\n",
    "    else:\n",
    "        print(f\"Trial {trial.number}: 클래스 가중치 미사용.\")\n",
    "\n",
    "\n",
    "    # 4. 손실 함수 (클래스 가중치 적용 여부에 따라 초기화)\n",
    "    if use_class_weights:\n",
    "        loss_function = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 5. 옵티마이저\n",
    "    optimizer = optim.AdamW(NN.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 6. 스케줄러\n",
    "    scheduler_plateau = ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.8, patience=5, min_lr=1e-7)\n",
    "\n",
    "    # 7. 학습 실행 (Transformer_Train 함수 호출)\n",
    "    log_dir = os.path.join(OPTUNA_VERSION_DIR, f\"trial_{trial.number}_params_emb{embedding_dim}_heads{n_heads}_lr{learning_rate:.1e}_cw{use_class_weights}\")\n",
    "    save_path = os.path.join(OPTUNA_VERSION_DIR, f\"model_trial_{trial.number}.pt\")\n",
    "    \n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    val_f1_weighted = Transformer_Train(\n",
    "        epoch=10000,\n",
    "        device=device,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        NN=NN,\n",
    "        loss_function=loss_function,\n",
    "        optimizer=optimizer,\n",
    "        scheduler_plateau=scheduler_plateau,\n",
    "        warmup_epochs=warmup_epochs,\n",
    "        log_dir=log_dir,\n",
    "        save_path=save_path,\n",
    "        patience=patience,\n",
    "        trial=trial\n",
    "    )\n",
    "\n",
    "    return val_f1_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d693493-8cb2-4cb7-a3f6-4c3b41ed1434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 18:22:57,606] A new study created in memory with name: no-name-339e6655-9311-49c8-a9ee-bb14a44ae796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna 최적화 시작...\n",
      "Trial 0: 클래스 가중치 미사용.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19932\\2319572601.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 5e-6, 5e-5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 0] TensorBoard 로그 디렉토리: optuna_runs\\v2\\trial_0_params_emb128_heads4_lr1.2e-05_cwFalse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\tensor\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:505: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 0] Epoch 1\tTrain Loss: 2.07962\tVal Acc: 0.3496\tVal F1 (Weighted): 0.1813\tVal F1 (Macro): 0.0741\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 2\tTrain Loss: 1.96103\tVal Acc: 0.3498\tVal F1 (Weighted): 0.1813\tVal F1 (Macro): 0.0740\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 3\tTrain Loss: 1.90220\tVal Acc: 0.4092\tVal F1 (Weighted): 0.2697\tVal F1 (Macro): 0.1348\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 4\tTrain Loss: 1.84237\tVal Acc: 0.4431\tVal F1 (Weighted): 0.3061\tVal F1 (Macro): 0.1548\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 5\tTrain Loss: 1.78280\tVal Acc: 0.4442\tVal F1 (Weighted): 0.3094\tVal F1 (Macro): 0.1563\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 6\tTrain Loss: 1.73279\tVal Acc: 0.4447\tVal F1 (Weighted): 0.3094\tVal F1 (Macro): 0.1563\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 7\tTrain Loss: 1.69920\tVal Acc: 0.4460\tVal F1 (Weighted): 0.3088\tVal F1 (Macro): 0.1560\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 8\tTrain Loss: 1.66752\tVal Acc: 0.4470\tVal F1 (Weighted): 0.3095\tVal F1 (Macro): 0.1563\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 9\tTrain Loss: 1.64536\tVal Acc: 0.4470\tVal F1 (Weighted): 0.3088\tVal F1 (Macro): 0.1560\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 10\tTrain Loss: 1.62551\tVal Acc: 0.4482\tVal F1 (Weighted): 0.3095\tVal F1 (Macro): 0.1563\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 11\tTrain Loss: 1.60814\tVal Acc: 0.4494\tVal F1 (Weighted): 0.3098\tVal F1 (Macro): 0.1566\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 12\tTrain Loss: 1.59308\tVal Acc: 0.4518\tVal F1 (Weighted): 0.3121\tVal F1 (Macro): 0.1580\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 13\tTrain Loss: 1.57826\tVal Acc: 0.4521\tVal F1 (Weighted): 0.3138\tVal F1 (Macro): 0.1609\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 14\tTrain Loss: 1.56789\tVal Acc: 0.4530\tVal F1 (Weighted): 0.3159\tVal F1 (Macro): 0.1664\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 15\tTrain Loss: 1.55676\tVal Acc: 0.4550\tVal F1 (Weighted): 0.3203\tVal F1 (Macro): 0.1727\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 16\tTrain Loss: 1.54894\tVal Acc: 0.4559\tVal F1 (Weighted): 0.3216\tVal F1 (Macro): 0.1767\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 17\tTrain Loss: 1.54495\tVal Acc: 0.4571\tVal F1 (Weighted): 0.3228\tVal F1 (Macro): 0.1770\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 18\tTrain Loss: 1.53906\tVal Acc: 0.4574\tVal F1 (Weighted): 0.3236\tVal F1 (Macro): 0.1780\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 19\tTrain Loss: 1.53449\tVal Acc: 0.4573\tVal F1 (Weighted): 0.3211\tVal F1 (Macro): 0.1732\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 20\tTrain Loss: 1.53097\tVal Acc: 0.4572\tVal F1 (Weighted): 0.3239\tVal F1 (Macro): 0.1800\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 21\tTrain Loss: 1.52774\tVal Acc: 0.4573\tVal F1 (Weighted): 0.3231\tVal F1 (Macro): 0.1781\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 22\tTrain Loss: 1.52485\tVal Acc: 0.4585\tVal F1 (Weighted): 0.3256\tVal F1 (Macro): 0.1809\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 23\tTrain Loss: 1.52245\tVal Acc: 0.4577\tVal F1 (Weighted): 0.3234\tVal F1 (Macro): 0.1782\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 24\tTrain Loss: 1.51817\tVal Acc: 0.4579\tVal F1 (Weighted): 0.3248\tVal F1 (Macro): 0.1807\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 25\tTrain Loss: 1.51683\tVal Acc: 0.4590\tVal F1 (Weighted): 0.3268\tVal F1 (Macro): 0.1834\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 26\tTrain Loss: 1.51236\tVal Acc: 0.4598\tVal F1 (Weighted): 0.3277\tVal F1 (Macro): 0.1835\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 27\tTrain Loss: 1.51262\tVal Acc: 0.4600\tVal F1 (Weighted): 0.3283\tVal F1 (Macro): 0.1849\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 28\tTrain Loss: 1.51034\tVal Acc: 0.4594\tVal F1 (Weighted): 0.3253\tVal F1 (Macro): 0.1797\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 29\tTrain Loss: 1.50827\tVal Acc: 0.4600\tVal F1 (Weighted): 0.3266\tVal F1 (Macro): 0.1821\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 30\tTrain Loss: 1.50427\tVal Acc: 0.4607\tVal F1 (Weighted): 0.3279\tVal F1 (Macro): 0.1838\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 31\tTrain Loss: 1.50455\tVal Acc: 0.4609\tVal F1 (Weighted): 0.3284\tVal F1 (Macro): 0.1843\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 32\tTrain Loss: 1.50252\tVal Acc: 0.4608\tVal F1 (Weighted): 0.3284\tVal F1 (Macro): 0.1844\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 33\tTrain Loss: 1.49991\tVal Acc: 0.4615\tVal F1 (Weighted): 0.3303\tVal F1 (Macro): 0.1875\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 34\tTrain Loss: 1.49883\tVal Acc: 0.4629\tVal F1 (Weighted): 0.3327\tVal F1 (Macro): 0.1908\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 35\tTrain Loss: 1.49832\tVal Acc: 0.4619\tVal F1 (Weighted): 0.3303\tVal F1 (Macro): 0.1876\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 36\tTrain Loss: 1.49533\tVal Acc: 0.4629\tVal F1 (Weighted): 0.3323\tVal F1 (Macro): 0.1906\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 37\tTrain Loss: 1.49445\tVal Acc: 0.4628\tVal F1 (Weighted): 0.3302\tVal F1 (Macro): 0.1860\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 38\tTrain Loss: 1.49116\tVal Acc: 0.4642\tVal F1 (Weighted): 0.3341\tVal F1 (Macro): 0.1922\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 39\tTrain Loss: 1.49065\tVal Acc: 0.4642\tVal F1 (Weighted): 0.3340\tVal F1 (Macro): 0.1926\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 40\tTrain Loss: 1.48805\tVal Acc: 0.4637\tVal F1 (Weighted): 0.3340\tVal F1 (Macro): 0.1935\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 41\tTrain Loss: 1.48684\tVal Acc: 0.4636\tVal F1 (Weighted): 0.3319\tVal F1 (Macro): 0.1888\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 42\tTrain Loss: 1.48561\tVal Acc: 0.4655\tVal F1 (Weighted): 0.3362\tVal F1 (Macro): 0.1949\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 43\tTrain Loss: 1.48296\tVal Acc: 0.4653\tVal F1 (Weighted): 0.3347\tVal F1 (Macro): 0.1922\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 44\tTrain Loss: 1.48309\tVal Acc: 0.4654\tVal F1 (Weighted): 0.3374\tVal F1 (Macro): 0.1967\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 45\tTrain Loss: 1.48204\tVal Acc: 0.4664\tVal F1 (Weighted): 0.3379\tVal F1 (Macro): 0.1969\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 46\tTrain Loss: 1.47886\tVal Acc: 0.4662\tVal F1 (Weighted): 0.3360\tVal F1 (Macro): 0.1943\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 47\tTrain Loss: 1.47858\tVal Acc: 0.4661\tVal F1 (Weighted): 0.3381\tVal F1 (Macro): 0.1981\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 48\tTrain Loss: 1.47671\tVal Acc: 0.4669\tVal F1 (Weighted): 0.3402\tVal F1 (Macro): 0.1997\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 49\tTrain Loss: 1.47428\tVal Acc: 0.4668\tVal F1 (Weighted): 0.3394\tVal F1 (Macro): 0.1993\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 50\tTrain Loss: 1.47486\tVal Acc: 0.4673\tVal F1 (Weighted): 0.3405\tVal F1 (Macro): 0.2009\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 51\tTrain Loss: 1.47281\tVal Acc: 0.4690\tVal F1 (Weighted): 0.3438\tVal F1 (Macro): 0.2043\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 52\tTrain Loss: 1.47012\tVal Acc: 0.4686\tVal F1 (Weighted): 0.3440\tVal F1 (Macro): 0.2051\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 53\tTrain Loss: 1.46890\tVal Acc: 0.4682\tVal F1 (Weighted): 0.3416\tVal F1 (Macro): 0.2026\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 54\tTrain Loss: 1.46743\tVal Acc: 0.4698\tVal F1 (Weighted): 0.3447\tVal F1 (Macro): 0.2055\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 55\tTrain Loss: 1.46594\tVal Acc: 0.4701\tVal F1 (Weighted): 0.3448\tVal F1 (Macro): 0.2056\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 56\tTrain Loss: 1.46510\tVal Acc: 0.4712\tVal F1 (Weighted): 0.3475\tVal F1 (Macro): 0.2088\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 57\tTrain Loss: 1.46246\tVal Acc: 0.4715\tVal F1 (Weighted): 0.3484\tVal F1 (Macro): 0.2103\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 58\tTrain Loss: 1.46104\tVal Acc: 0.4722\tVal F1 (Weighted): 0.3509\tVal F1 (Macro): 0.2137\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 59\tTrain Loss: 1.45966\tVal Acc: 0.4729\tVal F1 (Weighted): 0.3522\tVal F1 (Macro): 0.2152\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 60\tTrain Loss: 1.45909\tVal Acc: 0.4722\tVal F1 (Weighted): 0.3516\tVal F1 (Macro): 0.2147\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 61\tTrain Loss: 1.45693\tVal Acc: 0.4726\tVal F1 (Weighted): 0.3501\tVal F1 (Macro): 0.2139\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 62\tTrain Loss: 1.45590\tVal Acc: 0.4737\tVal F1 (Weighted): 0.3541\tVal F1 (Macro): 0.2177\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 63\tTrain Loss: 1.45229\tVal Acc: 0.4741\tVal F1 (Weighted): 0.3565\tVal F1 (Macro): 0.2209\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 64\tTrain Loss: 1.45147\tVal Acc: 0.4754\tVal F1 (Weighted): 0.3591\tVal F1 (Macro): 0.2240\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 65\tTrain Loss: 1.45093\tVal Acc: 0.4756\tVal F1 (Weighted): 0.3605\tVal F1 (Macro): 0.2261\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 66\tTrain Loss: 1.44950\tVal Acc: 0.4778\tVal F1 (Weighted): 0.3646\tVal F1 (Macro): 0.2314\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 67\tTrain Loss: 1.44471\tVal Acc: 0.4799\tVal F1 (Weighted): 0.3689\tVal F1 (Macro): 0.2369\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 68\tTrain Loss: 1.44330\tVal Acc: 0.4829\tVal F1 (Weighted): 0.3744\tVal F1 (Macro): 0.2437\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 69\tTrain Loss: 1.44320\tVal Acc: 0.4867\tVal F1 (Weighted): 0.3828\tVal F1 (Macro): 0.2561\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 70\tTrain Loss: 1.43833\tVal Acc: 0.4909\tVal F1 (Weighted): 0.3901\tVal F1 (Macro): 0.2662\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 71\tTrain Loss: 1.43524\tVal Acc: 0.4954\tVal F1 (Weighted): 0.4010\tVal F1 (Macro): 0.2813\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 72\tTrain Loss: 1.43315\tVal Acc: 0.4978\tVal F1 (Weighted): 0.4050\tVal F1 (Macro): 0.2860\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 73\tTrain Loss: 1.43141\tVal Acc: 0.5017\tVal F1 (Weighted): 0.4114\tVal F1 (Macro): 0.2943\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 74\tTrain Loss: 1.42931\tVal Acc: 0.5034\tVal F1 (Weighted): 0.4168\tVal F1 (Macro): 0.3018\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 75\tTrain Loss: 1.42590\tVal Acc: 0.5056\tVal F1 (Weighted): 0.4181\tVal F1 (Macro): 0.3033\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 76\tTrain Loss: 1.42151\tVal Acc: 0.5065\tVal F1 (Weighted): 0.4200\tVal F1 (Macro): 0.3064\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 77\tTrain Loss: 1.42149\tVal Acc: 0.5080\tVal F1 (Weighted): 0.4226\tVal F1 (Macro): 0.3094\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 78\tTrain Loss: 1.41560\tVal Acc: 0.5092\tVal F1 (Weighted): 0.4256\tVal F1 (Macro): 0.3133\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 79\tTrain Loss: 1.41503\tVal Acc: 0.5092\tVal F1 (Weighted): 0.4269\tVal F1 (Macro): 0.3149\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 80\tTrain Loss: 1.41179\tVal Acc: 0.5123\tVal F1 (Weighted): 0.4301\tVal F1 (Macro): 0.3196\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 81\tTrain Loss: 1.40967\tVal Acc: 0.5150\tVal F1 (Weighted): 0.4347\tVal F1 (Macro): 0.3258\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 82\tTrain Loss: 1.40676\tVal Acc: 0.5166\tVal F1 (Weighted): 0.4396\tVal F1 (Macro): 0.3326\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 83\tTrain Loss: 1.40491\tVal Acc: 0.5178\tVal F1 (Weighted): 0.4413\tVal F1 (Macro): 0.3347\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 84\tTrain Loss: 1.40318\tVal Acc: 0.5198\tVal F1 (Weighted): 0.4420\tVal F1 (Macro): 0.3354\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 85\tTrain Loss: 1.39609\tVal Acc: 0.5210\tVal F1 (Weighted): 0.4458\tVal F1 (Macro): 0.3408\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 86\tTrain Loss: 1.39692\tVal Acc: 0.5210\tVal F1 (Weighted): 0.4470\tVal F1 (Macro): 0.3418\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 87\tTrain Loss: 1.39231\tVal Acc: 0.5240\tVal F1 (Weighted): 0.4506\tVal F1 (Macro): 0.3465\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 88\tTrain Loss: 1.39091\tVal Acc: 0.5248\tVal F1 (Weighted): 0.4525\tVal F1 (Macro): 0.3486\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 89\tTrain Loss: 1.38707\tVal Acc: 0.5261\tVal F1 (Weighted): 0.4569\tVal F1 (Macro): 0.3541\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 90\tTrain Loss: 1.38454\tVal Acc: 0.5286\tVal F1 (Weighted): 0.4596\tVal F1 (Macro): 0.3570\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 91\tTrain Loss: 1.38121\tVal Acc: 0.5311\tVal F1 (Weighted): 0.4640\tVal F1 (Macro): 0.3617\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 92\tTrain Loss: 1.37851\tVal Acc: 0.5337\tVal F1 (Weighted): 0.4707\tVal F1 (Macro): 0.3703\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 93\tTrain Loss: 1.37598\tVal Acc: 0.5365\tVal F1 (Weighted): 0.4756\tVal F1 (Macro): 0.3754\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 94\tTrain Loss: 1.37092\tVal Acc: 0.5391\tVal F1 (Weighted): 0.4817\tVal F1 (Macro): 0.3824\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 95\tTrain Loss: 1.37004\tVal Acc: 0.5407\tVal F1 (Weighted): 0.4826\tVal F1 (Macro): 0.3826\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 96\tTrain Loss: 1.36719\tVal Acc: 0.5427\tVal F1 (Weighted): 0.4858\tVal F1 (Macro): 0.3867\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 97\tTrain Loss: 1.36240\tVal Acc: 0.5439\tVal F1 (Weighted): 0.4887\tVal F1 (Macro): 0.3908\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 98\tTrain Loss: 1.36038\tVal Acc: 0.5435\tVal F1 (Weighted): 0.4886\tVal F1 (Macro): 0.3909\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 99\tTrain Loss: 1.35854\tVal Acc: 0.5450\tVal F1 (Weighted): 0.4897\tVal F1 (Macro): 0.3931\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 100\tTrain Loss: 1.35753\tVal Acc: 0.5457\tVal F1 (Weighted): 0.4916\tVal F1 (Macro): 0.3943\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 101\tTrain Loss: 1.35730\tVal Acc: 0.5468\tVal F1 (Weighted): 0.4940\tVal F1 (Macro): 0.3976\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 102\tTrain Loss: 1.35116\tVal Acc: 0.5476\tVal F1 (Weighted): 0.4924\tVal F1 (Macro): 0.3962\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 103\tTrain Loss: 1.35073\tVal Acc: 0.5483\tVal F1 (Weighted): 0.4947\tVal F1 (Macro): 0.3982\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 104\tTrain Loss: 1.34897\tVal Acc: 0.5488\tVal F1 (Weighted): 0.4953\tVal F1 (Macro): 0.3992\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 105\tTrain Loss: 1.34717\tVal Acc: 0.5495\tVal F1 (Weighted): 0.4969\tVal F1 (Macro): 0.4012\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 106\tTrain Loss: 1.34452\tVal Acc: 0.5497\tVal F1 (Weighted): 0.4982\tVal F1 (Macro): 0.4027\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 107\tTrain Loss: 1.34238\tVal Acc: 0.5504\tVal F1 (Weighted): 0.4983\tVal F1 (Macro): 0.4028\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 108\tTrain Loss: 1.33918\tVal Acc: 0.5517\tVal F1 (Weighted): 0.5010\tVal F1 (Macro): 0.4067\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 109\tTrain Loss: 1.33940\tVal Acc: 0.5529\tVal F1 (Weighted): 0.5000\tVal F1 (Macro): 0.4058\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 110\tTrain Loss: 1.33548\tVal Acc: 0.5541\tVal F1 (Weighted): 0.5016\tVal F1 (Macro): 0.4077\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 111\tTrain Loss: 1.33392\tVal Acc: 0.5540\tVal F1 (Weighted): 0.5025\tVal F1 (Macro): 0.4086\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 112\tTrain Loss: 1.33325\tVal Acc: 0.5550\tVal F1 (Weighted): 0.5031\tVal F1 (Macro): 0.4092\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 113\tTrain Loss: 1.32974\tVal Acc: 0.5546\tVal F1 (Weighted): 0.5021\tVal F1 (Macro): 0.4077\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 114\tTrain Loss: 1.32924\tVal Acc: 0.5567\tVal F1 (Weighted): 0.5061\tVal F1 (Macro): 0.4133\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 115\tTrain Loss: 1.32734\tVal Acc: 0.5571\tVal F1 (Weighted): 0.5050\tVal F1 (Macro): 0.4119\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 116\tTrain Loss: 1.32535\tVal Acc: 0.5576\tVal F1 (Weighted): 0.5061\tVal F1 (Macro): 0.4129\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 117\tTrain Loss: 1.32281\tVal Acc: 0.5584\tVal F1 (Weighted): 0.5092\tVal F1 (Macro): 0.4171\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 118\tTrain Loss: 1.32214\tVal Acc: 0.5585\tVal F1 (Weighted): 0.5088\tVal F1 (Macro): 0.4168\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 119\tTrain Loss: 1.31932\tVal Acc: 0.5586\tVal F1 (Weighted): 0.5075\tVal F1 (Macro): 0.4154\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 120\tTrain Loss: 1.31714\tVal Acc: 0.5601\tVal F1 (Weighted): 0.5105\tVal F1 (Macro): 0.4185\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 121\tTrain Loss: 1.31566\tVal Acc: 0.5592\tVal F1 (Weighted): 0.5112\tVal F1 (Macro): 0.4195\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 122\tTrain Loss: 1.31301\tVal Acc: 0.5599\tVal F1 (Weighted): 0.5104\tVal F1 (Macro): 0.4188\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 123\tTrain Loss: 1.31103\tVal Acc: 0.5613\tVal F1 (Weighted): 0.5113\tVal F1 (Macro): 0.4194\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 124\tTrain Loss: 1.31051\tVal Acc: 0.5602\tVal F1 (Weighted): 0.5117\tVal F1 (Macro): 0.4206\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 125\tTrain Loss: 1.30862\tVal Acc: 0.5621\tVal F1 (Weighted): 0.5131\tVal F1 (Macro): 0.4206\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 126\tTrain Loss: 1.30959\tVal Acc: 0.5641\tVal F1 (Weighted): 0.5156\tVal F1 (Macro): 0.4256\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 127\tTrain Loss: 1.30616\tVal Acc: 0.5638\tVal F1 (Weighted): 0.5156\tVal F1 (Macro): 0.4255\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 128\tTrain Loss: 1.30416\tVal Acc: 0.5631\tVal F1 (Weighted): 0.5154\tVal F1 (Macro): 0.4246\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 129\tTrain Loss: 1.30240\tVal Acc: 0.5636\tVal F1 (Weighted): 0.5151\tVal F1 (Macro): 0.4246\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 130\tTrain Loss: 1.30176\tVal Acc: 0.5659\tVal F1 (Weighted): 0.5180\tVal F1 (Macro): 0.4281\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 131\tTrain Loss: 1.29944\tVal Acc: 0.5659\tVal F1 (Weighted): 0.5192\tVal F1 (Macro): 0.4303\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 132\tTrain Loss: 1.29841\tVal Acc: 0.5663\tVal F1 (Weighted): 0.5189\tVal F1 (Macro): 0.4297\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 133\tTrain Loss: 1.29738\tVal Acc: 0.5667\tVal F1 (Weighted): 0.5203\tVal F1 (Macro): 0.4311\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 134\tTrain Loss: 1.29456\tVal Acc: 0.5681\tVal F1 (Weighted): 0.5214\tVal F1 (Macro): 0.4335\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 135\tTrain Loss: 1.29304\tVal Acc: 0.5674\tVal F1 (Weighted): 0.5201\tVal F1 (Macro): 0.4308\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 136\tTrain Loss: 1.29286\tVal Acc: 0.5689\tVal F1 (Weighted): 0.5225\tVal F1 (Macro): 0.4341\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 137\tTrain Loss: 1.29103\tVal Acc: 0.5688\tVal F1 (Weighted): 0.5219\tVal F1 (Macro): 0.4336\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 138\tTrain Loss: 1.28741\tVal Acc: 0.5688\tVal F1 (Weighted): 0.5223\tVal F1 (Macro): 0.4344\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 139\tTrain Loss: 1.28696\tVal Acc: 0.5687\tVal F1 (Weighted): 0.5223\tVal F1 (Macro): 0.4339\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 140\tTrain Loss: 1.28468\tVal Acc: 0.5688\tVal F1 (Weighted): 0.5230\tVal F1 (Macro): 0.4347\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 141\tTrain Loss: 1.28425\tVal Acc: 0.5708\tVal F1 (Weighted): 0.5245\tVal F1 (Macro): 0.4373\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 142\tTrain Loss: 1.28296\tVal Acc: 0.5721\tVal F1 (Weighted): 0.5274\tVal F1 (Macro): 0.4403\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 143\tTrain Loss: 1.28221\tVal Acc: 0.5725\tVal F1 (Weighted): 0.5284\tVal F1 (Macro): 0.4419\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 144\tTrain Loss: 1.27855\tVal Acc: 0.5707\tVal F1 (Weighted): 0.5244\tVal F1 (Macro): 0.4368\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 145\tTrain Loss: 1.27881\tVal Acc: 0.5735\tVal F1 (Weighted): 0.5291\tVal F1 (Macro): 0.4427\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 146\tTrain Loss: 1.27757\tVal Acc: 0.5739\tVal F1 (Weighted): 0.5309\tVal F1 (Macro): 0.4451\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 147\tTrain Loss: 1.27574\tVal Acc: 0.5735\tVal F1 (Weighted): 0.5291\tVal F1 (Macro): 0.4426\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 148\tTrain Loss: 1.27406\tVal Acc: 0.5742\tVal F1 (Weighted): 0.5293\tVal F1 (Macro): 0.4429\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 149\tTrain Loss: 1.27043\tVal Acc: 0.5759\tVal F1 (Weighted): 0.5318\tVal F1 (Macro): 0.4467\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 150\tTrain Loss: 1.27206\tVal Acc: 0.5770\tVal F1 (Weighted): 0.5336\tVal F1 (Macro): 0.4481\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 151\tTrain Loss: 1.26772\tVal Acc: 0.5762\tVal F1 (Weighted): 0.5329\tVal F1 (Macro): 0.4475\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 152\tTrain Loss: 1.26540\tVal Acc: 0.5780\tVal F1 (Weighted): 0.5353\tVal F1 (Macro): 0.4506\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 153\tTrain Loss: 1.26584\tVal Acc: 0.5783\tVal F1 (Weighted): 0.5368\tVal F1 (Macro): 0.4526\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 154\tTrain Loss: 1.26482\tVal Acc: 0.5785\tVal F1 (Weighted): 0.5352\tVal F1 (Macro): 0.4511\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 155\tTrain Loss: 1.25795\tVal Acc: 0.5806\tVal F1 (Weighted): 0.5410\tVal F1 (Macro): 0.4567\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 156\tTrain Loss: 1.26084\tVal Acc: 0.5802\tVal F1 (Weighted): 0.5389\tVal F1 (Macro): 0.4545\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 157\tTrain Loss: 1.25961\tVal Acc: 0.5815\tVal F1 (Weighted): 0.5412\tVal F1 (Macro): 0.4572\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 158\tTrain Loss: 1.25880\tVal Acc: 0.5816\tVal F1 (Weighted): 0.5411\tVal F1 (Macro): 0.4577\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 159\tTrain Loss: 1.25373\tVal Acc: 0.5833\tVal F1 (Weighted): 0.5444\tVal F1 (Macro): 0.4616\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 160\tTrain Loss: 1.25849\tVal Acc: 0.5831\tVal F1 (Weighted): 0.5434\tVal F1 (Macro): 0.4604\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 161\tTrain Loss: 1.25276\tVal Acc: 0.5822\tVal F1 (Weighted): 0.5407\tVal F1 (Macro): 0.4570\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 162\tTrain Loss: 1.25062\tVal Acc: 0.5836\tVal F1 (Weighted): 0.5446\tVal F1 (Macro): 0.4609\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 163\tTrain Loss: 1.24996\tVal Acc: 0.5847\tVal F1 (Weighted): 0.5455\tVal F1 (Macro): 0.4626\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 164\tTrain Loss: 1.25003\tVal Acc: 0.5841\tVal F1 (Weighted): 0.5439\tVal F1 (Macro): 0.4618\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 165\tTrain Loss: 1.24763\tVal Acc: 0.5848\tVal F1 (Weighted): 0.5451\tVal F1 (Macro): 0.4633\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 166\tTrain Loss: 1.24679\tVal Acc: 0.5865\tVal F1 (Weighted): 0.5480\tVal F1 (Macro): 0.4669\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 167\tTrain Loss: 1.24633\tVal Acc: 0.5872\tVal F1 (Weighted): 0.5492\tVal F1 (Macro): 0.4681\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 168\tTrain Loss: 1.24404\tVal Acc: 0.5861\tVal F1 (Weighted): 0.5469\tVal F1 (Macro): 0.4653\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 169\tTrain Loss: 1.24350\tVal Acc: 0.5876\tVal F1 (Weighted): 0.5488\tVal F1 (Macro): 0.4681\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 170\tTrain Loss: 1.24416\tVal Acc: 0.5884\tVal F1 (Weighted): 0.5499\tVal F1 (Macro): 0.4679\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 171\tTrain Loss: 1.23978\tVal Acc: 0.5879\tVal F1 (Weighted): 0.5484\tVal F1 (Macro): 0.4668\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 172\tTrain Loss: 1.23724\tVal Acc: 0.5890\tVal F1 (Weighted): 0.5504\tVal F1 (Macro): 0.4691\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 173\tTrain Loss: 1.23894\tVal Acc: 0.5885\tVal F1 (Weighted): 0.5496\tVal F1 (Macro): 0.4683\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 174\tTrain Loss: 1.23559\tVal Acc: 0.5902\tVal F1 (Weighted): 0.5513\tVal F1 (Macro): 0.4696\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 175\tTrain Loss: 1.23197\tVal Acc: 0.5910\tVal F1 (Weighted): 0.5541\tVal F1 (Macro): 0.4727\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 176\tTrain Loss: 1.23327\tVal Acc: 0.5907\tVal F1 (Weighted): 0.5536\tVal F1 (Macro): 0.4730\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 177\tTrain Loss: 1.22971\tVal Acc: 0.5919\tVal F1 (Weighted): 0.5550\tVal F1 (Macro): 0.4749\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 178\tTrain Loss: 1.23183\tVal Acc: 0.5927\tVal F1 (Weighted): 0.5569\tVal F1 (Macro): 0.4769\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 179\tTrain Loss: 1.23042\tVal Acc: 0.5920\tVal F1 (Weighted): 0.5557\tVal F1 (Macro): 0.4755\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 180\tTrain Loss: 1.22706\tVal Acc: 0.5934\tVal F1 (Weighted): 0.5578\tVal F1 (Macro): 0.4783\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 181\tTrain Loss: 1.22478\tVal Acc: 0.5943\tVal F1 (Weighted): 0.5605\tVal F1 (Macro): 0.4809\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 182\tTrain Loss: 1.22539\tVal Acc: 0.5942\tVal F1 (Weighted): 0.5587\tVal F1 (Macro): 0.4793\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 183\tTrain Loss: 1.22533\tVal Acc: 0.5944\tVal F1 (Weighted): 0.5596\tVal F1 (Macro): 0.4798\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 184\tTrain Loss: 1.22471\tVal Acc: 0.5947\tVal F1 (Weighted): 0.5592\tVal F1 (Macro): 0.4796\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 185\tTrain Loss: 1.21865\tVal Acc: 0.5966\tVal F1 (Weighted): 0.5621\tVal F1 (Macro): 0.4833\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 186\tTrain Loss: 1.22057\tVal Acc: 0.5963\tVal F1 (Weighted): 0.5628\tVal F1 (Macro): 0.4839\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 187\tTrain Loss: 1.21881\tVal Acc: 0.5964\tVal F1 (Weighted): 0.5614\tVal F1 (Macro): 0.4822\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 188\tTrain Loss: 1.21444\tVal Acc: 0.5956\tVal F1 (Weighted): 0.5596\tVal F1 (Macro): 0.4814\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 189\tTrain Loss: 1.21561\tVal Acc: 0.5970\tVal F1 (Weighted): 0.5630\tVal F1 (Macro): 0.4833\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 190\tTrain Loss: 1.21489\tVal Acc: 0.5971\tVal F1 (Weighted): 0.5613\tVal F1 (Macro): 0.4827\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 191\tTrain Loss: 1.21413\tVal Acc: 0.5991\tVal F1 (Weighted): 0.5657\tVal F1 (Macro): 0.4889\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 192\tTrain Loss: 1.21164\tVal Acc: 0.5986\tVal F1 (Weighted): 0.5657\tVal F1 (Macro): 0.4878\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 193\tTrain Loss: 1.21133\tVal Acc: 0.5998\tVal F1 (Weighted): 0.5672\tVal F1 (Macro): 0.4913\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 194\tTrain Loss: 1.20987\tVal Acc: 0.5994\tVal F1 (Weighted): 0.5678\tVal F1 (Macro): 0.4902\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 195\tTrain Loss: 1.20863\tVal Acc: 0.6014\tVal F1 (Weighted): 0.5693\tVal F1 (Macro): 0.4937\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 196\tTrain Loss: 1.20576\tVal Acc: 0.6007\tVal F1 (Weighted): 0.5670\tVal F1 (Macro): 0.4895\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 197\tTrain Loss: 1.20343\tVal Acc: 0.6004\tVal F1 (Weighted): 0.5696\tVal F1 (Macro): 0.4928\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 198\tTrain Loss: 1.20382\tVal Acc: 0.6022\tVal F1 (Weighted): 0.5710\tVal F1 (Macro): 0.4954\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 199\tTrain Loss: 1.19944\tVal Acc: 0.6012\tVal F1 (Weighted): 0.5697\tVal F1 (Macro): 0.4922\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 200\tTrain Loss: 1.19987\tVal Acc: 0.6019\tVal F1 (Weighted): 0.5700\tVal F1 (Macro): 0.4935\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 201\tTrain Loss: 1.19976\tVal Acc: 0.6029\tVal F1 (Weighted): 0.5719\tVal F1 (Macro): 0.4950\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 202\tTrain Loss: 1.19990\tVal Acc: 0.6011\tVal F1 (Weighted): 0.5700\tVal F1 (Macro): 0.4930\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 203\tTrain Loss: 1.19624\tVal Acc: 0.6035\tVal F1 (Weighted): 0.5723\tVal F1 (Macro): 0.4960\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 204\tTrain Loss: 1.19865\tVal Acc: 0.6041\tVal F1 (Weighted): 0.5736\tVal F1 (Macro): 0.4980\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 205\tTrain Loss: 1.19852\tVal Acc: 0.6046\tVal F1 (Weighted): 0.5746\tVal F1 (Macro): 0.4995\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 206\tTrain Loss: 1.19631\tVal Acc: 0.6043\tVal F1 (Weighted): 0.5730\tVal F1 (Macro): 0.4971\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 207\tTrain Loss: 1.19465\tVal Acc: 0.6050\tVal F1 (Weighted): 0.5751\tVal F1 (Macro): 0.4996\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 208\tTrain Loss: 1.19184\tVal Acc: 0.6052\tVal F1 (Weighted): 0.5742\tVal F1 (Macro): 0.4979\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 209\tTrain Loss: 1.19141\tVal Acc: 0.6042\tVal F1 (Weighted): 0.5730\tVal F1 (Macro): 0.4971\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 210\tTrain Loss: 1.18953\tVal Acc: 0.6056\tVal F1 (Weighted): 0.5761\tVal F1 (Macro): 0.5018\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 211\tTrain Loss: 1.19131\tVal Acc: 0.6057\tVal F1 (Weighted): 0.5762\tVal F1 (Macro): 0.5018\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 212\tTrain Loss: 1.18904\tVal Acc: 0.6067\tVal F1 (Weighted): 0.5761\tVal F1 (Macro): 0.5008\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 213\tTrain Loss: 1.18705\tVal Acc: 0.6072\tVal F1 (Weighted): 0.5772\tVal F1 (Macro): 0.5028\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 214\tTrain Loss: 1.18689\tVal Acc: 0.6074\tVal F1 (Weighted): 0.5767\tVal F1 (Macro): 0.5014\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 215\tTrain Loss: 1.18496\tVal Acc: 0.6085\tVal F1 (Weighted): 0.5795\tVal F1 (Macro): 0.5045\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 216\tTrain Loss: 1.18411\tVal Acc: 0.6083\tVal F1 (Weighted): 0.5778\tVal F1 (Macro): 0.5024\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 217\tTrain Loss: 1.18197\tVal Acc: 0.6071\tVal F1 (Weighted): 0.5780\tVal F1 (Macro): 0.5031\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 218\tTrain Loss: 1.18111\tVal Acc: 0.6108\tVal F1 (Weighted): 0.5826\tVal F1 (Macro): 0.5076\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 219\tTrain Loss: 1.17995\tVal Acc: 0.6087\tVal F1 (Weighted): 0.5789\tVal F1 (Macro): 0.5041\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 220\tTrain Loss: 1.18089\tVal Acc: 0.6089\tVal F1 (Weighted): 0.5792\tVal F1 (Macro): 0.5043\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 221\tTrain Loss: 1.17768\tVal Acc: 0.6095\tVal F1 (Weighted): 0.5790\tVal F1 (Macro): 0.5037\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 222\tTrain Loss: 1.17585\tVal Acc: 0.6099\tVal F1 (Weighted): 0.5808\tVal F1 (Macro): 0.5058\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 223\tTrain Loss: 1.17622\tVal Acc: 0.6099\tVal F1 (Weighted): 0.5817\tVal F1 (Macro): 0.5078\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 224\tTrain Loss: 1.17638\tVal Acc: 0.6117\tVal F1 (Weighted): 0.5818\tVal F1 (Macro): 0.5073\tNo Improve Epochs: 6\n",
      "  [Trial 0] Epoch 225\tTrain Loss: 1.17527\tVal Acc: 0.6118\tVal F1 (Weighted): 0.5843\tVal F1 (Macro): 0.5103\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 226\tTrain Loss: 1.17380\tVal Acc: 0.6127\tVal F1 (Weighted): 0.5837\tVal F1 (Macro): 0.5095\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 227\tTrain Loss: 1.17360\tVal Acc: 0.6119\tVal F1 (Weighted): 0.5826\tVal F1 (Macro): 0.5088\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 228\tTrain Loss: 1.17222\tVal Acc: 0.6125\tVal F1 (Weighted): 0.5853\tVal F1 (Macro): 0.5117\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 229\tTrain Loss: 1.17100\tVal Acc: 0.6119\tVal F1 (Weighted): 0.5833\tVal F1 (Macro): 0.5096\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 230\tTrain Loss: 1.16946\tVal Acc: 0.6127\tVal F1 (Weighted): 0.5847\tVal F1 (Macro): 0.5121\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 231\tTrain Loss: 1.16895\tVal Acc: 0.6128\tVal F1 (Weighted): 0.5844\tVal F1 (Macro): 0.5103\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 232\tTrain Loss: 1.17108\tVal Acc: 0.6134\tVal F1 (Weighted): 0.5862\tVal F1 (Macro): 0.5124\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 233\tTrain Loss: 1.16738\tVal Acc: 0.6144\tVal F1 (Weighted): 0.5873\tVal F1 (Macro): 0.5139\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 234\tTrain Loss: 1.16639\tVal Acc: 0.6133\tVal F1 (Weighted): 0.5864\tVal F1 (Macro): 0.5128\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 235\tTrain Loss: 1.16626\tVal Acc: 0.6141\tVal F1 (Weighted): 0.5865\tVal F1 (Macro): 0.5129\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 236\tTrain Loss: 1.16508\tVal Acc: 0.6135\tVal F1 (Weighted): 0.5861\tVal F1 (Macro): 0.5138\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 237\tTrain Loss: 1.16672\tVal Acc: 0.6144\tVal F1 (Weighted): 0.5853\tVal F1 (Macro): 0.5112\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 238\tTrain Loss: 1.16554\tVal Acc: 0.6144\tVal F1 (Weighted): 0.5869\tVal F1 (Macro): 0.5130\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 239\tTrain Loss: 1.16490\tVal Acc: 0.6155\tVal F1 (Weighted): 0.5896\tVal F1 (Macro): 0.5160\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 240\tTrain Loss: 1.16279\tVal Acc: 0.6144\tVal F1 (Weighted): 0.5878\tVal F1 (Macro): 0.5147\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 241\tTrain Loss: 1.15991\tVal Acc: 0.6152\tVal F1 (Weighted): 0.5892\tVal F1 (Macro): 0.5164\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 242\tTrain Loss: 1.16073\tVal Acc: 0.6163\tVal F1 (Weighted): 0.5897\tVal F1 (Macro): 0.5180\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 243\tTrain Loss: 1.15872\tVal Acc: 0.6166\tVal F1 (Weighted): 0.5914\tVal F1 (Macro): 0.5199\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 244\tTrain Loss: 1.16073\tVal Acc: 0.6167\tVal F1 (Weighted): 0.5898\tVal F1 (Macro): 0.5176\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 245\tTrain Loss: 1.15700\tVal Acc: 0.6164\tVal F1 (Weighted): 0.5913\tVal F1 (Macro): 0.5188\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 246\tTrain Loss: 1.15789\tVal Acc: 0.6161\tVal F1 (Weighted): 0.5902\tVal F1 (Macro): 0.5183\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 247\tTrain Loss: 1.15748\tVal Acc: 0.6174\tVal F1 (Weighted): 0.5911\tVal F1 (Macro): 0.5185\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 248\tTrain Loss: 1.15620\tVal Acc: 0.6178\tVal F1 (Weighted): 0.5926\tVal F1 (Macro): 0.5206\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 249\tTrain Loss: 1.15714\tVal Acc: 0.6180\tVal F1 (Weighted): 0.5923\tVal F1 (Macro): 0.5208\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 250\tTrain Loss: 1.15342\tVal Acc: 0.6175\tVal F1 (Weighted): 0.5914\tVal F1 (Macro): 0.5196\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 251\tTrain Loss: 1.15487\tVal Acc: 0.6177\tVal F1 (Weighted): 0.5919\tVal F1 (Macro): 0.5197\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 252\tTrain Loss: 1.15216\tVal Acc: 0.6191\tVal F1 (Weighted): 0.5943\tVal F1 (Macro): 0.5224\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 253\tTrain Loss: 1.15180\tVal Acc: 0.6195\tVal F1 (Weighted): 0.5953\tVal F1 (Macro): 0.5233\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 254\tTrain Loss: 1.15272\tVal Acc: 0.6186\tVal F1 (Weighted): 0.5930\tVal F1 (Macro): 0.5220\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 255\tTrain Loss: 1.15083\tVal Acc: 0.6183\tVal F1 (Weighted): 0.5918\tVal F1 (Macro): 0.5202\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 256\tTrain Loss: 1.14946\tVal Acc: 0.6199\tVal F1 (Weighted): 0.5949\tVal F1 (Macro): 0.5224\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 257\tTrain Loss: 1.14798\tVal Acc: 0.6186\tVal F1 (Weighted): 0.5933\tVal F1 (Macro): 0.5208\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 258\tTrain Loss: 1.14656\tVal Acc: 0.6184\tVal F1 (Weighted): 0.5927\tVal F1 (Macro): 0.5208\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 259\tTrain Loss: 1.14850\tVal Acc: 0.6204\tVal F1 (Weighted): 0.5949\tVal F1 (Macro): 0.5235\tNo Improve Epochs: 6\n",
      "  [Trial 0] Epoch 260\tTrain Loss: 1.15093\tVal Acc: 0.6198\tVal F1 (Weighted): 0.5942\tVal F1 (Macro): 0.5220\tNo Improve Epochs: 7\n",
      "  [Trial 0] Epoch 261\tTrain Loss: 1.14842\tVal Acc: 0.6198\tVal F1 (Weighted): 0.5942\tVal F1 (Macro): 0.5219\tNo Improve Epochs: 8\n",
      "  [Trial 0] Epoch 262\tTrain Loss: 1.14828\tVal Acc: 0.6202\tVal F1 (Weighted): 0.5948\tVal F1 (Macro): 0.5232\tNo Improve Epochs: 9\n",
      "  [Trial 0] Epoch 263\tTrain Loss: 1.14561\tVal Acc: 0.6209\tVal F1 (Weighted): 0.5963\tVal F1 (Macro): 0.5241\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 264\tTrain Loss: 1.14433\tVal Acc: 0.6201\tVal F1 (Weighted): 0.5944\tVal F1 (Macro): 0.5223\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 265\tTrain Loss: 1.14294\tVal Acc: 0.6202\tVal F1 (Weighted): 0.5946\tVal F1 (Macro): 0.5229\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 266\tTrain Loss: 1.14570\tVal Acc: 0.6202\tVal F1 (Weighted): 0.5952\tVal F1 (Macro): 0.5234\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 267\tTrain Loss: 1.14355\tVal Acc: 0.6196\tVal F1 (Weighted): 0.5947\tVal F1 (Macro): 0.5227\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 268\tTrain Loss: 1.14150\tVal Acc: 0.6206\tVal F1 (Weighted): 0.5963\tVal F1 (Macro): 0.5240\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 269\tTrain Loss: 1.14080\tVal Acc: 0.6207\tVal F1 (Weighted): 0.5953\tVal F1 (Macro): 0.5240\tNo Improve Epochs: 6\n",
      "  [Trial 0] Epoch 270\tTrain Loss: 1.14428\tVal Acc: 0.6212\tVal F1 (Weighted): 0.5962\tVal F1 (Macro): 0.5248\tNo Improve Epochs: 7\n",
      "  [Trial 0] Epoch 271\tTrain Loss: 1.13978\tVal Acc: 0.6220\tVal F1 (Weighted): 0.5975\tVal F1 (Macro): 0.5265\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 272\tTrain Loss: 1.13995\tVal Acc: 0.6226\tVal F1 (Weighted): 0.5988\tVal F1 (Macro): 0.5274\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 273\tTrain Loss: 1.14274\tVal Acc: 0.6219\tVal F1 (Weighted): 0.5965\tVal F1 (Macro): 0.5250\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 274\tTrain Loss: 1.13889\tVal Acc: 0.6224\tVal F1 (Weighted): 0.5983\tVal F1 (Macro): 0.5262\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 275\tTrain Loss: 1.13968\tVal Acc: 0.6222\tVal F1 (Weighted): 0.5977\tVal F1 (Macro): 0.5255\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 276\tTrain Loss: 1.13899\tVal Acc: 0.6229\tVal F1 (Weighted): 0.5986\tVal F1 (Macro): 0.5272\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 277\tTrain Loss: 1.13982\tVal Acc: 0.6220\tVal F1 (Weighted): 0.5975\tVal F1 (Macro): 0.5259\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 278\tTrain Loss: 1.13976\tVal Acc: 0.6225\tVal F1 (Weighted): 0.5985\tVal F1 (Macro): 0.5274\tNo Improve Epochs: 6\n",
      "  [Trial 0] Epoch 279\tTrain Loss: 1.13835\tVal Acc: 0.6228\tVal F1 (Weighted): 0.5992\tVal F1 (Macro): 0.5284\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 280\tTrain Loss: 1.13930\tVal Acc: 0.6229\tVal F1 (Weighted): 0.5997\tVal F1 (Macro): 0.5286\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 281\tTrain Loss: 1.14031\tVal Acc: 0.6238\tVal F1 (Weighted): 0.6000\tVal F1 (Macro): 0.5292\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 282\tTrain Loss: 1.13741\tVal Acc: 0.6234\tVal F1 (Weighted): 0.6000\tVal F1 (Macro): 0.5290\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 283\tTrain Loss: 1.13786\tVal Acc: 0.6241\tVal F1 (Weighted): 0.6009\tVal F1 (Macro): 0.5306\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 284\tTrain Loss: 1.13714\tVal Acc: 0.6242\tVal F1 (Weighted): 0.6005\tVal F1 (Macro): 0.5303\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 285\tTrain Loss: 1.13803\tVal Acc: 0.6236\tVal F1 (Weighted): 0.6004\tVal F1 (Macro): 0.5297\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 286\tTrain Loss: 1.13597\tVal Acc: 0.6240\tVal F1 (Weighted): 0.6009\tVal F1 (Macro): 0.5304\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 287\tTrain Loss: 1.13670\tVal Acc: 0.6238\tVal F1 (Weighted): 0.6000\tVal F1 (Macro): 0.5293\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 288\tTrain Loss: 1.13495\tVal Acc: 0.6242\tVal F1 (Weighted): 0.6004\tVal F1 (Macro): 0.5294\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 289\tTrain Loss: 1.13494\tVal Acc: 0.6243\tVal F1 (Weighted): 0.6007\tVal F1 (Macro): 0.5289\tNo Improve Epochs: 6\n",
      "  [Trial 0] Epoch 290\tTrain Loss: 1.13506\tVal Acc: 0.6238\tVal F1 (Weighted): 0.6005\tVal F1 (Macro): 0.5295\tNo Improve Epochs: 7\n",
      "  [Trial 0] Epoch 291\tTrain Loss: 1.13263\tVal Acc: 0.6248\tVal F1 (Weighted): 0.6014\tVal F1 (Macro): 0.5304\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 292\tTrain Loss: 1.13501\tVal Acc: 0.6250\tVal F1 (Weighted): 0.6016\tVal F1 (Macro): 0.5304\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 293\tTrain Loss: 1.13195\tVal Acc: 0.6248\tVal F1 (Weighted): 0.6014\tVal F1 (Macro): 0.5306\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 294\tTrain Loss: 1.13384\tVal Acc: 0.6246\tVal F1 (Weighted): 0.6013\tVal F1 (Macro): 0.5305\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 295\tTrain Loss: 1.13247\tVal Acc: 0.6244\tVal F1 (Weighted): 0.6009\tVal F1 (Macro): 0.5299\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 296\tTrain Loss: 1.13419\tVal Acc: 0.6252\tVal F1 (Weighted): 0.6022\tVal F1 (Macro): 0.5316\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 297\tTrain Loss: 1.13247\tVal Acc: 0.6250\tVal F1 (Weighted): 0.6017\tVal F1 (Macro): 0.5312\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 298\tTrain Loss: 1.13283\tVal Acc: 0.6255\tVal F1 (Weighted): 0.6027\tVal F1 (Macro): 0.5321\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 299\tTrain Loss: 1.13298\tVal Acc: 0.6244\tVal F1 (Weighted): 0.6007\tVal F1 (Macro): 0.5300\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 300\tTrain Loss: 1.13116\tVal Acc: 0.6252\tVal F1 (Weighted): 0.6021\tVal F1 (Macro): 0.5310\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 301\tTrain Loss: 1.13000\tVal Acc: 0.6249\tVal F1 (Weighted): 0.6013\tVal F1 (Macro): 0.5303\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 302\tTrain Loss: 1.13065\tVal Acc: 0.6246\tVal F1 (Weighted): 0.6010\tVal F1 (Macro): 0.5303\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 303\tTrain Loss: 1.13202\tVal Acc: 0.6245\tVal F1 (Weighted): 0.6006\tVal F1 (Macro): 0.5292\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 304\tTrain Loss: 1.13237\tVal Acc: 0.6258\tVal F1 (Weighted): 0.6027\tVal F1 (Macro): 0.5319\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 305\tTrain Loss: 1.13034\tVal Acc: 0.6253\tVal F1 (Weighted): 0.6027\tVal F1 (Macro): 0.5319\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 306\tTrain Loss: 1.13122\tVal Acc: 0.6249\tVal F1 (Weighted): 0.6018\tVal F1 (Macro): 0.5314\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 307\tTrain Loss: 1.13083\tVal Acc: 0.6258\tVal F1 (Weighted): 0.6028\tVal F1 (Macro): 0.5326\tNo Improve Epochs: 0\n",
      "  [Trial 0] Epoch 308\tTrain Loss: 1.13213\tVal Acc: 0.6250\tVal F1 (Weighted): 0.6020\tVal F1 (Macro): 0.5308\tNo Improve Epochs: 1\n",
      "  [Trial 0] Epoch 309\tTrain Loss: 1.12816\tVal Acc: 0.6254\tVal F1 (Weighted): 0.6027\tVal F1 (Macro): 0.5317\tNo Improve Epochs: 2\n",
      "  [Trial 0] Epoch 310\tTrain Loss: 1.13282\tVal Acc: 0.6255\tVal F1 (Weighted): 0.6026\tVal F1 (Macro): 0.5316\tNo Improve Epochs: 3\n",
      "  [Trial 0] Epoch 311\tTrain Loss: 1.13024\tVal Acc: 0.6255\tVal F1 (Weighted): 0.6023\tVal F1 (Macro): 0.5312\tNo Improve Epochs: 4\n",
      "  [Trial 0] Epoch 312\tTrain Loss: 1.12954\tVal Acc: 0.6260\tVal F1 (Weighted): 0.6027\tVal F1 (Macro): 0.5319\tNo Improve Epochs: 5\n",
      "  [Trial 0] Epoch 313\tTrain Loss: 1.12898\tVal Acc: 0.6255\tVal F1 (Weighted): 0.6017\tVal F1 (Macro): 0.5311\tNo Improve Epochs: 6\n",
      "  [Trial 0] Epoch 314\tTrain Loss: 1.12898\tVal Acc: 0.6250\tVal F1 (Weighted): 0.6018\tVal F1 (Macro): 0.5306\tNo Improve Epochs: 7\n",
      "  [Trial 0] Epoch 315\tTrain Loss: 1.13009\tVal Acc: 0.6258\tVal F1 (Weighted): 0.6027\tVal F1 (Macro): 0.5317\tNo Improve Epochs: 8\n",
      "  [Trial 0] Epoch 316\tTrain Loss: 1.12739\tVal Acc: 0.6253\tVal F1 (Weighted): 0.6026\tVal F1 (Macro): 0.5316\tNo Improve Epochs: 9\n",
      "  [Trial 0] Epoch 317\tTrain Loss: 1.12952\tVal Acc: 0.6252\tVal F1 (Weighted): 0.6021\tVal F1 (Macro): 0.5305\tNo Improve Epochs: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 20:24:58,060] Trial 0 finished with value: 0.6027983382725753 and parameters: {'embedding_dim': 128, 'hidden_dim': 128, 'n_layers': 2, 'n_heads': 4, 'dropout_p': 0.5, 'learning_rate': 1.1933217143832069e-05, 'warmup_epochs': 11, 'patience': 11, 'use_class_weights': False}. Best is trial 0 with value: 0.6027983382725753.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 0] Epoch 318\tTrain Loss: 1.12879\tVal Acc: 0.6253\tVal F1 (Weighted): 0.6015\tVal F1 (Macro): 0.5305\tNo Improve Epochs: 11\n",
      "조기 종료: 11 에포크 동안 성능 개선 없음. Trial 0 종료.\n",
      "Trial 1: 클래스 가중치 미사용.\n",
      "  [Trial 1] TensorBoard 로그 디렉토리: optuna_runs\\v2\\trial_1_params_emb128_heads16_lr3.0e-05_cwFalse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19932\\2319572601.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 5e-6, 5e-5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 1] Epoch 1\tTrain Loss: 1.72195\tVal Acc: 0.4432\tVal F1 (Weighted): 0.3093\tVal F1 (Macro): 0.1561\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 2\tTrain Loss: 1.59924\tVal Acc: 0.4474\tVal F1 (Weighted): 0.3141\tVal F1 (Macro): 0.1588\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 3\tTrain Loss: 1.54342\tVal Acc: 0.4530\tVal F1 (Weighted): 0.3277\tVal F1 (Macro): 0.1785\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 4\tTrain Loss: 1.50110\tVal Acc: 0.4707\tVal F1 (Weighted): 0.3669\tVal F1 (Macro): 0.2318\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 5\tTrain Loss: 1.45777\tVal Acc: 0.4870\tVal F1 (Weighted): 0.3954\tVal F1 (Macro): 0.2698\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 6\tTrain Loss: 1.40739\tVal Acc: 0.5192\tVal F1 (Weighted): 0.4569\tVal F1 (Macro): 0.3484\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 7\tTrain Loss: 1.35749\tVal Acc: 0.5376\tVal F1 (Weighted): 0.4891\tVal F1 (Macro): 0.3901\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 8\tTrain Loss: 1.31375\tVal Acc: 0.5523\tVal F1 (Weighted): 0.5073\tVal F1 (Macro): 0.4079\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 9\tTrain Loss: 1.27496\tVal Acc: 0.5654\tVal F1 (Weighted): 0.5268\tVal F1 (Macro): 0.4356\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 10\tTrain Loss: 1.24368\tVal Acc: 0.5717\tVal F1 (Weighted): 0.5337\tVal F1 (Macro): 0.4428\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 11\tTrain Loss: 1.21474\tVal Acc: 0.5834\tVal F1 (Weighted): 0.5504\tVal F1 (Macro): 0.4653\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 12\tTrain Loss: 1.19400\tVal Acc: 0.5911\tVal F1 (Weighted): 0.5591\tVal F1 (Macro): 0.4670\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 13\tTrain Loss: 1.17270\tVal Acc: 0.5962\tVal F1 (Weighted): 0.5672\tVal F1 (Macro): 0.4759\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 14\tTrain Loss: 1.15430\tVal Acc: 0.6002\tVal F1 (Weighted): 0.5738\tVal F1 (Macro): 0.4837\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 15\tTrain Loss: 1.13959\tVal Acc: 0.6051\tVal F1 (Weighted): 0.5805\tVal F1 (Macro): 0.4969\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 16\tTrain Loss: 1.12364\tVal Acc: 0.6078\tVal F1 (Weighted): 0.5794\tVal F1 (Macro): 0.4842\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 17\tTrain Loss: 1.11269\tVal Acc: 0.6124\tVal F1 (Weighted): 0.5878\tVal F1 (Macro): 0.5016\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 18\tTrain Loss: 1.09893\tVal Acc: 0.6125\tVal F1 (Weighted): 0.5881\tVal F1 (Macro): 0.5058\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 19\tTrain Loss: 1.08980\tVal Acc: 0.6183\tVal F1 (Weighted): 0.5981\tVal F1 (Macro): 0.5154\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 20\tTrain Loss: 1.08025\tVal Acc: 0.6209\tVal F1 (Weighted): 0.5997\tVal F1 (Macro): 0.5218\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 21\tTrain Loss: 1.07163\tVal Acc: 0.6217\tVal F1 (Weighted): 0.5992\tVal F1 (Macro): 0.5102\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 22\tTrain Loss: 1.06118\tVal Acc: 0.6210\tVal F1 (Weighted): 0.6050\tVal F1 (Macro): 0.5297\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 23\tTrain Loss: 1.05336\tVal Acc: 0.6246\tVal F1 (Weighted): 0.6011\tVal F1 (Macro): 0.5198\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 24\tTrain Loss: 1.04726\tVal Acc: 0.6257\tVal F1 (Weighted): 0.6041\tVal F1 (Macro): 0.5186\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 25\tTrain Loss: 1.03704\tVal Acc: 0.6280\tVal F1 (Weighted): 0.6055\tVal F1 (Macro): 0.5225\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 26\tTrain Loss: 1.03448\tVal Acc: 0.6299\tVal F1 (Weighted): 0.6111\tVal F1 (Macro): 0.5336\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 27\tTrain Loss: 1.02650\tVal Acc: 0.6312\tVal F1 (Weighted): 0.6113\tVal F1 (Macro): 0.5297\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 28\tTrain Loss: 1.01915\tVal Acc: 0.6337\tVal F1 (Weighted): 0.6155\tVal F1 (Macro): 0.5361\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 29\tTrain Loss: 1.01519\tVal Acc: 0.6331\tVal F1 (Weighted): 0.6143\tVal F1 (Macro): 0.5327\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 30\tTrain Loss: 1.00848\tVal Acc: 0.6335\tVal F1 (Weighted): 0.6183\tVal F1 (Macro): 0.5423\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 31\tTrain Loss: 1.00357\tVal Acc: 0.6374\tVal F1 (Weighted): 0.6196\tVal F1 (Macro): 0.5415\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 32\tTrain Loss: 0.99611\tVal Acc: 0.6363\tVal F1 (Weighted): 0.6192\tVal F1 (Macro): 0.5387\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 33\tTrain Loss: 0.99160\tVal Acc: 0.6374\tVal F1 (Weighted): 0.6192\tVal F1 (Macro): 0.5394\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 34\tTrain Loss: 0.98449\tVal Acc: 0.6381\tVal F1 (Weighted): 0.6185\tVal F1 (Macro): 0.5388\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 35\tTrain Loss: 0.97929\tVal Acc: 0.6362\tVal F1 (Weighted): 0.6221\tVal F1 (Macro): 0.5419\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 36\tTrain Loss: 0.97722\tVal Acc: 0.6381\tVal F1 (Weighted): 0.6202\tVal F1 (Macro): 0.5361\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 37\tTrain Loss: 0.97025\tVal Acc: 0.6374\tVal F1 (Weighted): 0.6246\tVal F1 (Macro): 0.5493\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 38\tTrain Loss: 0.96614\tVal Acc: 0.6398\tVal F1 (Weighted): 0.6225\tVal F1 (Macro): 0.5438\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 39\tTrain Loss: 0.96216\tVal Acc: 0.6404\tVal F1 (Weighted): 0.6242\tVal F1 (Macro): 0.5482\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 40\tTrain Loss: 0.96091\tVal Acc: 0.6394\tVal F1 (Weighted): 0.6258\tVal F1 (Macro): 0.5489\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 41\tTrain Loss: 0.95367\tVal Acc: 0.6420\tVal F1 (Weighted): 0.6234\tVal F1 (Macro): 0.5472\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 42\tTrain Loss: 0.94891\tVal Acc: 0.6405\tVal F1 (Weighted): 0.6227\tVal F1 (Macro): 0.5406\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 43\tTrain Loss: 0.94432\tVal Acc: 0.6418\tVal F1 (Weighted): 0.6235\tVal F1 (Macro): 0.5479\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 44\tTrain Loss: 0.94222\tVal Acc: 0.6430\tVal F1 (Weighted): 0.6243\tVal F1 (Macro): 0.5431\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 45\tTrain Loss: 0.93695\tVal Acc: 0.6408\tVal F1 (Weighted): 0.6279\tVal F1 (Macro): 0.5484\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 46\tTrain Loss: 0.93481\tVal Acc: 0.6446\tVal F1 (Weighted): 0.6281\tVal F1 (Macro): 0.5501\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 47\tTrain Loss: 0.92783\tVal Acc: 0.6436\tVal F1 (Weighted): 0.6292\tVal F1 (Macro): 0.5508\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 48\tTrain Loss: 0.92791\tVal Acc: 0.6435\tVal F1 (Weighted): 0.6287\tVal F1 (Macro): 0.5536\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 49\tTrain Loss: 0.92087\tVal Acc: 0.6452\tVal F1 (Weighted): 0.6275\tVal F1 (Macro): 0.5460\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 50\tTrain Loss: 0.92071\tVal Acc: 0.6446\tVal F1 (Weighted): 0.6290\tVal F1 (Macro): 0.5534\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 51\tTrain Loss: 0.91564\tVal Acc: 0.6453\tVal F1 (Weighted): 0.6288\tVal F1 (Macro): 0.5505\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 52\tTrain Loss: 0.90996\tVal Acc: 0.6449\tVal F1 (Weighted): 0.6282\tVal F1 (Macro): 0.5523\tNo Improve Epochs: 5\n",
      "  [Trial 1] Epoch 53\tTrain Loss: 0.90645\tVal Acc: 0.6443\tVal F1 (Weighted): 0.6271\tVal F1 (Macro): 0.5484\tNo Improve Epochs: 6\n",
      "  [Trial 1] Epoch 54\tTrain Loss: 0.90270\tVal Acc: 0.6460\tVal F1 (Weighted): 0.6321\tVal F1 (Macro): 0.5519\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 55\tTrain Loss: 0.89751\tVal Acc: 0.6471\tVal F1 (Weighted): 0.6320\tVal F1 (Macro): 0.5534\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 56\tTrain Loss: 0.89828\tVal Acc: 0.6459\tVal F1 (Weighted): 0.6306\tVal F1 (Macro): 0.5494\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 57\tTrain Loss: 0.89367\tVal Acc: 0.6462\tVal F1 (Weighted): 0.6306\tVal F1 (Macro): 0.5538\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 58\tTrain Loss: 0.88991\tVal Acc: 0.6463\tVal F1 (Weighted): 0.6306\tVal F1 (Macro): 0.5532\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 59\tTrain Loss: 0.88825\tVal Acc: 0.6468\tVal F1 (Weighted): 0.6329\tVal F1 (Macro): 0.5586\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 60\tTrain Loss: 0.88528\tVal Acc: 0.6471\tVal F1 (Weighted): 0.6322\tVal F1 (Macro): 0.5541\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 61\tTrain Loss: 0.88291\tVal Acc: 0.6462\tVal F1 (Weighted): 0.6333\tVal F1 (Macro): 0.5592\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 62\tTrain Loss: 0.87842\tVal Acc: 0.6462\tVal F1 (Weighted): 0.6326\tVal F1 (Macro): 0.5562\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 63\tTrain Loss: 0.87664\tVal Acc: 0.6465\tVal F1 (Weighted): 0.6324\tVal F1 (Macro): 0.5575\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 64\tTrain Loss: 0.87415\tVal Acc: 0.6456\tVal F1 (Weighted): 0.6324\tVal F1 (Macro): 0.5542\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 65\tTrain Loss: 0.87211\tVal Acc: 0.6473\tVal F1 (Weighted): 0.6338\tVal F1 (Macro): 0.5578\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 66\tTrain Loss: 0.87112\tVal Acc: 0.6440\tVal F1 (Weighted): 0.6330\tVal F1 (Macro): 0.5545\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 67\tTrain Loss: 0.86853\tVal Acc: 0.6480\tVal F1 (Weighted): 0.6339\tVal F1 (Macro): 0.5573\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 68\tTrain Loss: 0.86488\tVal Acc: 0.6477\tVal F1 (Weighted): 0.6343\tVal F1 (Macro): 0.5637\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 69\tTrain Loss: 0.86325\tVal Acc: 0.6454\tVal F1 (Weighted): 0.6344\tVal F1 (Macro): 0.5575\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 70\tTrain Loss: 0.86150\tVal Acc: 0.6466\tVal F1 (Weighted): 0.6346\tVal F1 (Macro): 0.5579\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 71\tTrain Loss: 0.85703\tVal Acc: 0.6481\tVal F1 (Weighted): 0.6349\tVal F1 (Macro): 0.5585\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 72\tTrain Loss: 0.85513\tVal Acc: 0.6447\tVal F1 (Weighted): 0.6345\tVal F1 (Macro): 0.5588\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 73\tTrain Loss: 0.85528\tVal Acc: 0.6480\tVal F1 (Weighted): 0.6345\tVal F1 (Macro): 0.5592\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 74\tTrain Loss: 0.85116\tVal Acc: 0.6458\tVal F1 (Weighted): 0.6331\tVal F1 (Macro): 0.5567\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 75\tTrain Loss: 0.85096\tVal Acc: 0.6467\tVal F1 (Weighted): 0.6335\tVal F1 (Macro): 0.5590\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 76\tTrain Loss: 0.84645\tVal Acc: 0.6486\tVal F1 (Weighted): 0.6353\tVal F1 (Macro): 0.5594\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 77\tTrain Loss: 0.84400\tVal Acc: 0.6474\tVal F1 (Weighted): 0.6335\tVal F1 (Macro): 0.5551\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 78\tTrain Loss: 0.84086\tVal Acc: 0.6478\tVal F1 (Weighted): 0.6357\tVal F1 (Macro): 0.5617\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 79\tTrain Loss: 0.83792\tVal Acc: 0.6482\tVal F1 (Weighted): 0.6352\tVal F1 (Macro): 0.5579\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 80\tTrain Loss: 0.83648\tVal Acc: 0.6474\tVal F1 (Weighted): 0.6365\tVal F1 (Macro): 0.5609\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 81\tTrain Loss: 0.83726\tVal Acc: 0.6463\tVal F1 (Weighted): 0.6354\tVal F1 (Macro): 0.5605\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 82\tTrain Loss: 0.83417\tVal Acc: 0.6448\tVal F1 (Weighted): 0.6340\tVal F1 (Macro): 0.5599\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 83\tTrain Loss: 0.83038\tVal Acc: 0.6458\tVal F1 (Weighted): 0.6357\tVal F1 (Macro): 0.5637\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 84\tTrain Loss: 0.82856\tVal Acc: 0.6456\tVal F1 (Weighted): 0.6360\tVal F1 (Macro): 0.5617\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 85\tTrain Loss: 0.82571\tVal Acc: 0.6462\tVal F1 (Weighted): 0.6362\tVal F1 (Macro): 0.5624\tNo Improve Epochs: 5\n",
      "  [Trial 1] Epoch 86\tTrain Loss: 0.82661\tVal Acc: 0.6475\tVal F1 (Weighted): 0.6362\tVal F1 (Macro): 0.5585\tNo Improve Epochs: 6\n",
      "  [Trial 1] Epoch 87\tTrain Loss: 0.81813\tVal Acc: 0.6475\tVal F1 (Weighted): 0.6379\tVal F1 (Macro): 0.5654\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 88\tTrain Loss: 0.81809\tVal Acc: 0.6456\tVal F1 (Weighted): 0.6338\tVal F1 (Macro): 0.5586\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 89\tTrain Loss: 0.81682\tVal Acc: 0.6455\tVal F1 (Weighted): 0.6363\tVal F1 (Macro): 0.5620\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 90\tTrain Loss: 0.81588\tVal Acc: 0.6471\tVal F1 (Weighted): 0.6355\tVal F1 (Macro): 0.5599\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 91\tTrain Loss: 0.81101\tVal Acc: 0.6468\tVal F1 (Weighted): 0.6359\tVal F1 (Macro): 0.5627\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 92\tTrain Loss: 0.81201\tVal Acc: 0.6478\tVal F1 (Weighted): 0.6370\tVal F1 (Macro): 0.5643\tNo Improve Epochs: 5\n",
      "  [Trial 1] Epoch 93\tTrain Loss: 0.80856\tVal Acc: 0.6479\tVal F1 (Weighted): 0.6362\tVal F1 (Macro): 0.5590\tNo Improve Epochs: 6\n",
      "  [Trial 1] Epoch 94\tTrain Loss: 0.80405\tVal Acc: 0.6468\tVal F1 (Weighted): 0.6360\tVal F1 (Macro): 0.5599\tNo Improve Epochs: 7\n",
      "  [Trial 1] Epoch 95\tTrain Loss: 0.80436\tVal Acc: 0.6482\tVal F1 (Weighted): 0.6366\tVal F1 (Macro): 0.5627\tNo Improve Epochs: 8\n",
      "  [Trial 1] Epoch 96\tTrain Loss: 0.80322\tVal Acc: 0.6492\tVal F1 (Weighted): 0.6358\tVal F1 (Macro): 0.5597\tNo Improve Epochs: 9\n",
      "  [Trial 1] Epoch 97\tTrain Loss: 0.80165\tVal Acc: 0.6476\tVal F1 (Weighted): 0.6368\tVal F1 (Macro): 0.5634\tNo Improve Epochs: 10\n",
      "  [Trial 1] Epoch 98\tTrain Loss: 0.80085\tVal Acc: 0.6477\tVal F1 (Weighted): 0.6375\tVal F1 (Macro): 0.5644\tNo Improve Epochs: 11\n",
      "  [Trial 1] Epoch 99\tTrain Loss: 0.79832\tVal Acc: 0.6493\tVal F1 (Weighted): 0.6382\tVal F1 (Macro): 0.5633\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 100\tTrain Loss: 0.79637\tVal Acc: 0.6464\tVal F1 (Weighted): 0.6371\tVal F1 (Macro): 0.5639\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 101\tTrain Loss: 0.79520\tVal Acc: 0.6486\tVal F1 (Weighted): 0.6367\tVal F1 (Macro): 0.5613\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 102\tTrain Loss: 0.79509\tVal Acc: 0.6463\tVal F1 (Weighted): 0.6379\tVal F1 (Macro): 0.5646\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 103\tTrain Loss: 0.79512\tVal Acc: 0.6493\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5645\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 104\tTrain Loss: 0.79396\tVal Acc: 0.6491\tVal F1 (Weighted): 0.6375\tVal F1 (Macro): 0.5605\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 105\tTrain Loss: 0.78939\tVal Acc: 0.6469\tVal F1 (Weighted): 0.6363\tVal F1 (Macro): 0.5611\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 106\tTrain Loss: 0.78895\tVal Acc: 0.6479\tVal F1 (Weighted): 0.6355\tVal F1 (Macro): 0.5622\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 107\tTrain Loss: 0.78797\tVal Acc: 0.6473\tVal F1 (Weighted): 0.6364\tVal F1 (Macro): 0.5610\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 108\tTrain Loss: 0.78725\tVal Acc: 0.6465\tVal F1 (Weighted): 0.6359\tVal F1 (Macro): 0.5622\tNo Improve Epochs: 5\n",
      "  [Trial 1] Epoch 109\tTrain Loss: 0.78671\tVal Acc: 0.6483\tVal F1 (Weighted): 0.6367\tVal F1 (Macro): 0.5610\tNo Improve Epochs: 6\n",
      "  [Trial 1] Epoch 110\tTrain Loss: 0.78213\tVal Acc: 0.6444\tVal F1 (Weighted): 0.6374\tVal F1 (Macro): 0.5645\tNo Improve Epochs: 7\n",
      "  [Trial 1] Epoch 111\tTrain Loss: 0.78217\tVal Acc: 0.6483\tVal F1 (Weighted): 0.6373\tVal F1 (Macro): 0.5612\tNo Improve Epochs: 8\n",
      "  [Trial 1] Epoch 112\tTrain Loss: 0.78253\tVal Acc: 0.6481\tVal F1 (Weighted): 0.6376\tVal F1 (Macro): 0.5648\tNo Improve Epochs: 9\n",
      "  [Trial 1] Epoch 113\tTrain Loss: 0.78049\tVal Acc: 0.6488\tVal F1 (Weighted): 0.6374\tVal F1 (Macro): 0.5624\tNo Improve Epochs: 10\n",
      "  [Trial 1] Epoch 114\tTrain Loss: 0.77980\tVal Acc: 0.6481\tVal F1 (Weighted): 0.6378\tVal F1 (Macro): 0.5647\tNo Improve Epochs: 11\n",
      "  [Trial 1] Epoch 115\tTrain Loss: 0.77820\tVal Acc: 0.6470\tVal F1 (Weighted): 0.6383\tVal F1 (Macro): 0.5668\tNo Improve Epochs: 12\n",
      "  [Trial 1] Epoch 116\tTrain Loss: 0.77687\tVal Acc: 0.6488\tVal F1 (Weighted): 0.6391\tVal F1 (Macro): 0.5674\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 117\tTrain Loss: 0.77495\tVal Acc: 0.6480\tVal F1 (Weighted): 0.6395\tVal F1 (Macro): 0.5669\tNo Improve Epochs: 0\n",
      "  [Trial 1] Epoch 118\tTrain Loss: 0.77674\tVal Acc: 0.6472\tVal F1 (Weighted): 0.6382\tVal F1 (Macro): 0.5657\tNo Improve Epochs: 1\n",
      "  [Trial 1] Epoch 119\tTrain Loss: 0.77478\tVal Acc: 0.6480\tVal F1 (Weighted): 0.6386\tVal F1 (Macro): 0.5656\tNo Improve Epochs: 2\n",
      "  [Trial 1] Epoch 120\tTrain Loss: 0.77345\tVal Acc: 0.6463\tVal F1 (Weighted): 0.6381\tVal F1 (Macro): 0.5652\tNo Improve Epochs: 3\n",
      "  [Trial 1] Epoch 121\tTrain Loss: 0.77463\tVal Acc: 0.6461\tVal F1 (Weighted): 0.6369\tVal F1 (Macro): 0.5652\tNo Improve Epochs: 4\n",
      "  [Trial 1] Epoch 122\tTrain Loss: 0.77016\tVal Acc: 0.6478\tVal F1 (Weighted): 0.6382\tVal F1 (Macro): 0.5673\tNo Improve Epochs: 5\n",
      "  [Trial 1] Epoch 123\tTrain Loss: 0.76951\tVal Acc: 0.6471\tVal F1 (Weighted): 0.6382\tVal F1 (Macro): 0.5652\tNo Improve Epochs: 6\n",
      "  [Trial 1] Epoch 124\tTrain Loss: 0.76880\tVal Acc: 0.6491\tVal F1 (Weighted): 0.6374\tVal F1 (Macro): 0.5621\tNo Improve Epochs: 7\n",
      "  [Trial 1] Epoch 125\tTrain Loss: 0.76869\tVal Acc: 0.6483\tVal F1 (Weighted): 0.6379\tVal F1 (Macro): 0.5640\tNo Improve Epochs: 8\n",
      "  [Trial 1] Epoch 126\tTrain Loss: 0.76739\tVal Acc: 0.6467\tVal F1 (Weighted): 0.6390\tVal F1 (Macro): 0.5662\tNo Improve Epochs: 9\n",
      "  [Trial 1] Epoch 127\tTrain Loss: 0.76552\tVal Acc: 0.6482\tVal F1 (Weighted): 0.6373\tVal F1 (Macro): 0.5620\tNo Improve Epochs: 10\n",
      "  [Trial 1] Epoch 128\tTrain Loss: 0.76662\tVal Acc: 0.6470\tVal F1 (Weighted): 0.6374\tVal F1 (Macro): 0.5651\tNo Improve Epochs: 11\n",
      "  [Trial 1] Epoch 129\tTrain Loss: 0.76472\tVal Acc: 0.6463\tVal F1 (Weighted): 0.6372\tVal F1 (Macro): 0.5636\tNo Improve Epochs: 12\n",
      "  [Trial 1] Epoch 130\tTrain Loss: 0.76214\tVal Acc: 0.6469\tVal F1 (Weighted): 0.6379\tVal F1 (Macro): 0.5650\tNo Improve Epochs: 13\n",
      "  [Trial 1] Epoch 131\tTrain Loss: 0.76352\tVal Acc: 0.6488\tVal F1 (Weighted): 0.6388\tVal F1 (Macro): 0.5661\tNo Improve Epochs: 14\n",
      "  [Trial 1] Epoch 132\tTrain Loss: 0.76473\tVal Acc: 0.6485\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5655\tNo Improve Epochs: 15\n",
      "  [Trial 1] Epoch 133\tTrain Loss: 0.76167\tVal Acc: 0.6471\tVal F1 (Weighted): 0.6380\tVal F1 (Macro): 0.5660\tNo Improve Epochs: 16\n",
      "  [Trial 1] Epoch 134\tTrain Loss: 0.76163\tVal Acc: 0.6470\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5673\tNo Improve Epochs: 17\n",
      "  [Trial 1] Epoch 135\tTrain Loss: 0.76255\tVal Acc: 0.6473\tVal F1 (Weighted): 0.6383\tVal F1 (Macro): 0.5654\tNo Improve Epochs: 18\n",
      "  [Trial 1] Epoch 136\tTrain Loss: 0.76196\tVal Acc: 0.6467\tVal F1 (Weighted): 0.6379\tVal F1 (Macro): 0.5660\tNo Improve Epochs: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 21:34:25,562] Trial 1 finished with value: 0.639486902775119 and parameters: {'embedding_dim': 128, 'hidden_dim': 256, 'n_layers': 2, 'n_heads': 16, 'dropout_p': 0.1, 'learning_rate': 2.9579485662059165e-05, 'warmup_epochs': 10, 'patience': 20, 'use_class_weights': False}. Best is trial 1 with value: 0.639486902775119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 1] Epoch 137\tTrain Loss: 0.75733\tVal Acc: 0.6480\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5661\tNo Improve Epochs: 20\n",
      "조기 종료: 20 에포크 동안 성능 개선 없음. Trial 1 종료.\n",
      "Trial 2: 클래스 가중치 미사용.\n",
      "  [Trial 2] TensorBoard 로그 디렉토리: optuna_runs\\v2\\trial_2_params_emb128_heads16_lr2.0e-05_cwFalse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19932\\2319572601.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 5e-6, 5e-5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 2] Epoch 1\tTrain Loss: 1.83984\tVal Acc: 0.3498\tVal F1 (Weighted): 0.1813\tVal F1 (Macro): 0.0740\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 2\tTrain Loss: 1.76803\tVal Acc: 0.4216\tVal F1 (Weighted): 0.2822\tVal F1 (Macro): 0.1416\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 3\tTrain Loss: 1.69020\tVal Acc: 0.4457\tVal F1 (Weighted): 0.3104\tVal F1 (Macro): 0.1566\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 4\tTrain Loss: 1.64635\tVal Acc: 0.4466\tVal F1 (Weighted): 0.3105\tVal F1 (Macro): 0.1567\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 5\tTrain Loss: 1.61443\tVal Acc: 0.4473\tVal F1 (Weighted): 0.3117\tVal F1 (Macro): 0.1581\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 6\tTrain Loss: 1.58802\tVal Acc: 0.4489\tVal F1 (Weighted): 0.3180\tVal F1 (Macro): 0.1657\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 7\tTrain Loss: 1.56475\tVal Acc: 0.4523\tVal F1 (Weighted): 0.3217\tVal F1 (Macro): 0.1723\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 8\tTrain Loss: 1.54425\tVal Acc: 0.4548\tVal F1 (Weighted): 0.3258\tVal F1 (Macro): 0.1806\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 9\tTrain Loss: 1.52740\tVal Acc: 0.4577\tVal F1 (Weighted): 0.3297\tVal F1 (Macro): 0.1850\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 10\tTrain Loss: 1.51176\tVal Acc: 0.4598\tVal F1 (Weighted): 0.3335\tVal F1 (Macro): 0.1915\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 11\tTrain Loss: 1.49979\tVal Acc: 0.4627\tVal F1 (Weighted): 0.3365\tVal F1 (Macro): 0.1950\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 12\tTrain Loss: 1.48611\tVal Acc: 0.4660\tVal F1 (Weighted): 0.3454\tVal F1 (Macro): 0.2077\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 13\tTrain Loss: 1.47212\tVal Acc: 0.4711\tVal F1 (Weighted): 0.3573\tVal F1 (Macro): 0.2236\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 14\tTrain Loss: 1.45593\tVal Acc: 0.4831\tVal F1 (Weighted): 0.3826\tVal F1 (Macro): 0.2560\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 15\tTrain Loss: 1.43323\tVal Acc: 0.4963\tVal F1 (Weighted): 0.4090\tVal F1 (Macro): 0.2876\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 16\tTrain Loss: 1.41416\tVal Acc: 0.5118\tVal F1 (Weighted): 0.4375\tVal F1 (Macro): 0.3279\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 17\tTrain Loss: 1.39058\tVal Acc: 0.5231\tVal F1 (Weighted): 0.4573\tVal F1 (Macro): 0.3496\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 18\tTrain Loss: 1.37069\tVal Acc: 0.5365\tVal F1 (Weighted): 0.4806\tVal F1 (Macro): 0.3810\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 19\tTrain Loss: 1.35556\tVal Acc: 0.5436\tVal F1 (Weighted): 0.4907\tVal F1 (Macro): 0.3933\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 20\tTrain Loss: 1.33920\tVal Acc: 0.5490\tVal F1 (Weighted): 0.4988\tVal F1 (Macro): 0.4031\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 21\tTrain Loss: 1.32470\tVal Acc: 0.5554\tVal F1 (Weighted): 0.5074\tVal F1 (Macro): 0.4158\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 22\tTrain Loss: 1.31203\tVal Acc: 0.5596\tVal F1 (Weighted): 0.5125\tVal F1 (Macro): 0.4215\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 23\tTrain Loss: 1.30057\tVal Acc: 0.5623\tVal F1 (Weighted): 0.5169\tVal F1 (Macro): 0.4266\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 24\tTrain Loss: 1.29240\tVal Acc: 0.5650\tVal F1 (Weighted): 0.5199\tVal F1 (Macro): 0.4314\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 25\tTrain Loss: 1.28364\tVal Acc: 0.5683\tVal F1 (Weighted): 0.5274\tVal F1 (Macro): 0.4402\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 26\tTrain Loss: 1.27565\tVal Acc: 0.5714\tVal F1 (Weighted): 0.5301\tVal F1 (Macro): 0.4437\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 27\tTrain Loss: 1.26581\tVal Acc: 0.5744\tVal F1 (Weighted): 0.5331\tVal F1 (Macro): 0.4491\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 28\tTrain Loss: 1.25847\tVal Acc: 0.5769\tVal F1 (Weighted): 0.5387\tVal F1 (Macro): 0.4561\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 29\tTrain Loss: 1.25125\tVal Acc: 0.5801\tVal F1 (Weighted): 0.5443\tVal F1 (Macro): 0.4605\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 30\tTrain Loss: 1.24554\tVal Acc: 0.5819\tVal F1 (Weighted): 0.5466\tVal F1 (Macro): 0.4635\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 31\tTrain Loss: 1.23845\tVal Acc: 0.5841\tVal F1 (Weighted): 0.5486\tVal F1 (Macro): 0.4671\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 32\tTrain Loss: 1.23437\tVal Acc: 0.5872\tVal F1 (Weighted): 0.5527\tVal F1 (Macro): 0.4727\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 33\tTrain Loss: 1.22697\tVal Acc: 0.5897\tVal F1 (Weighted): 0.5566\tVal F1 (Macro): 0.4741\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 34\tTrain Loss: 1.22057\tVal Acc: 0.5919\tVal F1 (Weighted): 0.5593\tVal F1 (Macro): 0.4782\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 35\tTrain Loss: 1.21351\tVal Acc: 0.5929\tVal F1 (Weighted): 0.5599\tVal F1 (Macro): 0.4781\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 36\tTrain Loss: 1.20902\tVal Acc: 0.5969\tVal F1 (Weighted): 0.5652\tVal F1 (Macro): 0.4832\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 37\tTrain Loss: 1.20452\tVal Acc: 0.5967\tVal F1 (Weighted): 0.5647\tVal F1 (Macro): 0.4825\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 38\tTrain Loss: 1.19834\tVal Acc: 0.5994\tVal F1 (Weighted): 0.5694\tVal F1 (Macro): 0.4883\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 39\tTrain Loss: 1.19554\tVal Acc: 0.6020\tVal F1 (Weighted): 0.5719\tVal F1 (Macro): 0.4902\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 40\tTrain Loss: 1.19016\tVal Acc: 0.6020\tVal F1 (Weighted): 0.5709\tVal F1 (Macro): 0.4886\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 41\tTrain Loss: 1.18483\tVal Acc: 0.6033\tVal F1 (Weighted): 0.5731\tVal F1 (Macro): 0.4934\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 42\tTrain Loss: 1.18047\tVal Acc: 0.6038\tVal F1 (Weighted): 0.5737\tVal F1 (Macro): 0.4937\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 43\tTrain Loss: 1.17683\tVal Acc: 0.6051\tVal F1 (Weighted): 0.5764\tVal F1 (Macro): 0.4959\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 44\tTrain Loss: 1.17250\tVal Acc: 0.6059\tVal F1 (Weighted): 0.5777\tVal F1 (Macro): 0.4939\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 45\tTrain Loss: 1.17077\tVal Acc: 0.6070\tVal F1 (Weighted): 0.5803\tVal F1 (Macro): 0.5009\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 46\tTrain Loss: 1.16355\tVal Acc: 0.6087\tVal F1 (Weighted): 0.5814\tVal F1 (Macro): 0.4973\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 47\tTrain Loss: 1.16079\tVal Acc: 0.6077\tVal F1 (Weighted): 0.5816\tVal F1 (Macro): 0.5017\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 48\tTrain Loss: 1.15799\tVal Acc: 0.6085\tVal F1 (Weighted): 0.5819\tVal F1 (Macro): 0.5033\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 49\tTrain Loss: 1.15558\tVal Acc: 0.6099\tVal F1 (Weighted): 0.5826\tVal F1 (Macro): 0.5019\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 50\tTrain Loss: 1.15330\tVal Acc: 0.6116\tVal F1 (Weighted): 0.5831\tVal F1 (Macro): 0.4980\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 51\tTrain Loss: 1.14988\tVal Acc: 0.6126\tVal F1 (Weighted): 0.5857\tVal F1 (Macro): 0.5060\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 52\tTrain Loss: 1.14473\tVal Acc: 0.6131\tVal F1 (Weighted): 0.5871\tVal F1 (Macro): 0.5058\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 53\tTrain Loss: 1.14160\tVal Acc: 0.6120\tVal F1 (Weighted): 0.5852\tVal F1 (Macro): 0.5061\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 54\tTrain Loss: 1.14015\tVal Acc: 0.6139\tVal F1 (Weighted): 0.5869\tVal F1 (Macro): 0.5022\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 55\tTrain Loss: 1.13756\tVal Acc: 0.6157\tVal F1 (Weighted): 0.5900\tVal F1 (Macro): 0.5068\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 56\tTrain Loss: 1.13219\tVal Acc: 0.6159\tVal F1 (Weighted): 0.5901\tVal F1 (Macro): 0.5160\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 57\tTrain Loss: 1.13195\tVal Acc: 0.6150\tVal F1 (Weighted): 0.5893\tVal F1 (Macro): 0.5107\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 58\tTrain Loss: 1.12698\tVal Acc: 0.6165\tVal F1 (Weighted): 0.5901\tVal F1 (Macro): 0.5073\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 59\tTrain Loss: 1.12748\tVal Acc: 0.6182\tVal F1 (Weighted): 0.5919\tVal F1 (Macro): 0.5111\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 60\tTrain Loss: 1.12228\tVal Acc: 0.6186\tVal F1 (Weighted): 0.5946\tVal F1 (Macro): 0.5176\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 61\tTrain Loss: 1.12016\tVal Acc: 0.6190\tVal F1 (Weighted): 0.5933\tVal F1 (Macro): 0.5047\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 62\tTrain Loss: 1.11843\tVal Acc: 0.6186\tVal F1 (Weighted): 0.5952\tVal F1 (Macro): 0.5199\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 63\tTrain Loss: 1.11450\tVal Acc: 0.6220\tVal F1 (Weighted): 0.5964\tVal F1 (Macro): 0.5120\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 64\tTrain Loss: 1.11211\tVal Acc: 0.6208\tVal F1 (Weighted): 0.5959\tVal F1 (Macro): 0.5160\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 65\tTrain Loss: 1.11024\tVal Acc: 0.6229\tVal F1 (Weighted): 0.6002\tVal F1 (Macro): 0.5182\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 66\tTrain Loss: 1.10721\tVal Acc: 0.6215\tVal F1 (Weighted): 0.5971\tVal F1 (Macro): 0.5168\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 67\tTrain Loss: 1.10448\tVal Acc: 0.6237\tVal F1 (Weighted): 0.5998\tVal F1 (Macro): 0.5211\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 68\tTrain Loss: 1.10559\tVal Acc: 0.6246\tVal F1 (Weighted): 0.6032\tVal F1 (Macro): 0.5255\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 69\tTrain Loss: 1.09875\tVal Acc: 0.6251\tVal F1 (Weighted): 0.6038\tVal F1 (Macro): 0.5248\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 70\tTrain Loss: 1.09645\tVal Acc: 0.6224\tVal F1 (Weighted): 0.6002\tVal F1 (Macro): 0.5235\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 71\tTrain Loss: 1.09450\tVal Acc: 0.6251\tVal F1 (Weighted): 0.6027\tVal F1 (Macro): 0.5238\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 72\tTrain Loss: 1.09168\tVal Acc: 0.6265\tVal F1 (Weighted): 0.6046\tVal F1 (Macro): 0.5249\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 73\tTrain Loss: 1.09046\tVal Acc: 0.6268\tVal F1 (Weighted): 0.6043\tVal F1 (Macro): 0.5245\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 74\tTrain Loss: 1.08911\tVal Acc: 0.6257\tVal F1 (Weighted): 0.6049\tVal F1 (Macro): 0.5274\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 75\tTrain Loss: 1.08714\tVal Acc: 0.6296\tVal F1 (Weighted): 0.6080\tVal F1 (Macro): 0.5273\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 76\tTrain Loss: 1.08645\tVal Acc: 0.6298\tVal F1 (Weighted): 0.6099\tVal F1 (Macro): 0.5275\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 77\tTrain Loss: 1.08280\tVal Acc: 0.6296\tVal F1 (Weighted): 0.6077\tVal F1 (Macro): 0.5276\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 78\tTrain Loss: 1.08061\tVal Acc: 0.6271\tVal F1 (Weighted): 0.6056\tVal F1 (Macro): 0.5251\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 79\tTrain Loss: 1.07861\tVal Acc: 0.6293\tVal F1 (Weighted): 0.6098\tVal F1 (Macro): 0.5277\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 80\tTrain Loss: 1.07631\tVal Acc: 0.6300\tVal F1 (Weighted): 0.6104\tVal F1 (Macro): 0.5307\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 81\tTrain Loss: 1.07490\tVal Acc: 0.6298\tVal F1 (Weighted): 0.6083\tVal F1 (Macro): 0.5251\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 82\tTrain Loss: 1.07317\tVal Acc: 0.6299\tVal F1 (Weighted): 0.6075\tVal F1 (Macro): 0.5282\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 83\tTrain Loss: 1.07353\tVal Acc: 0.6311\tVal F1 (Weighted): 0.6106\tVal F1 (Macro): 0.5285\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 84\tTrain Loss: 1.07012\tVal Acc: 0.6314\tVal F1 (Weighted): 0.6100\tVal F1 (Macro): 0.5339\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 85\tTrain Loss: 1.06708\tVal Acc: 0.6326\tVal F1 (Weighted): 0.6124\tVal F1 (Macro): 0.5340\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 86\tTrain Loss: 1.06670\tVal Acc: 0.6327\tVal F1 (Weighted): 0.6115\tVal F1 (Macro): 0.5280\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 87\tTrain Loss: 1.06247\tVal Acc: 0.6328\tVal F1 (Weighted): 0.6117\tVal F1 (Macro): 0.5325\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 88\tTrain Loss: 1.06228\tVal Acc: 0.6330\tVal F1 (Weighted): 0.6140\tVal F1 (Macro): 0.5366\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 89\tTrain Loss: 1.05878\tVal Acc: 0.6343\tVal F1 (Weighted): 0.6132\tVal F1 (Macro): 0.5348\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 90\tTrain Loss: 1.05679\tVal Acc: 0.6343\tVal F1 (Weighted): 0.6133\tVal F1 (Macro): 0.5341\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 91\tTrain Loss: 1.05642\tVal Acc: 0.6348\tVal F1 (Weighted): 0.6155\tVal F1 (Macro): 0.5361\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 92\tTrain Loss: 1.05337\tVal Acc: 0.6370\tVal F1 (Weighted): 0.6159\tVal F1 (Macro): 0.5374\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 93\tTrain Loss: 1.05191\tVal Acc: 0.6354\tVal F1 (Weighted): 0.6155\tVal F1 (Macro): 0.5367\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 94\tTrain Loss: 1.05021\tVal Acc: 0.6355\tVal F1 (Weighted): 0.6147\tVal F1 (Macro): 0.5310\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 95\tTrain Loss: 1.05069\tVal Acc: 0.6364\tVal F1 (Weighted): 0.6177\tVal F1 (Macro): 0.5385\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 96\tTrain Loss: 1.04635\tVal Acc: 0.6359\tVal F1 (Weighted): 0.6163\tVal F1 (Macro): 0.5371\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 97\tTrain Loss: 1.04592\tVal Acc: 0.6383\tVal F1 (Weighted): 0.6180\tVal F1 (Macro): 0.5400\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 98\tTrain Loss: 1.04448\tVal Acc: 0.6387\tVal F1 (Weighted): 0.6191\tVal F1 (Macro): 0.5417\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 99\tTrain Loss: 1.04004\tVal Acc: 0.6378\tVal F1 (Weighted): 0.6194\tVal F1 (Macro): 0.5420\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 100\tTrain Loss: 1.03967\tVal Acc: 0.6393\tVal F1 (Weighted): 0.6199\tVal F1 (Macro): 0.5412\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 101\tTrain Loss: 1.03807\tVal Acc: 0.6374\tVal F1 (Weighted): 0.6195\tVal F1 (Macro): 0.5375\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 102\tTrain Loss: 1.03623\tVal Acc: 0.6377\tVal F1 (Weighted): 0.6195\tVal F1 (Macro): 0.5363\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 103\tTrain Loss: 1.03696\tVal Acc: 0.6392\tVal F1 (Weighted): 0.6204\tVal F1 (Macro): 0.5399\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 104\tTrain Loss: 1.03465\tVal Acc: 0.6364\tVal F1 (Weighted): 0.6179\tVal F1 (Macro): 0.5385\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 105\tTrain Loss: 1.03399\tVal Acc: 0.6389\tVal F1 (Weighted): 0.6210\tVal F1 (Macro): 0.5406\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 106\tTrain Loss: 1.03149\tVal Acc: 0.6393\tVal F1 (Weighted): 0.6235\tVal F1 (Macro): 0.5457\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 107\tTrain Loss: 1.03045\tVal Acc: 0.6397\tVal F1 (Weighted): 0.6211\tVal F1 (Macro): 0.5422\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 108\tTrain Loss: 1.02841\tVal Acc: 0.6405\tVal F1 (Weighted): 0.6224\tVal F1 (Macro): 0.5439\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 109\tTrain Loss: 1.02851\tVal Acc: 0.6397\tVal F1 (Weighted): 0.6210\tVal F1 (Macro): 0.5393\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 110\tTrain Loss: 1.02645\tVal Acc: 0.6399\tVal F1 (Weighted): 0.6221\tVal F1 (Macro): 0.5409\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 111\tTrain Loss: 1.02566\tVal Acc: 0.6428\tVal F1 (Weighted): 0.6239\tVal F1 (Macro): 0.5436\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 112\tTrain Loss: 1.02101\tVal Acc: 0.6422\tVal F1 (Weighted): 0.6236\tVal F1 (Macro): 0.5459\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 113\tTrain Loss: 1.02031\tVal Acc: 0.6394\tVal F1 (Weighted): 0.6218\tVal F1 (Macro): 0.5422\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 114\tTrain Loss: 1.01828\tVal Acc: 0.6429\tVal F1 (Weighted): 0.6262\tVal F1 (Macro): 0.5460\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 115\tTrain Loss: 1.02009\tVal Acc: 0.6433\tVal F1 (Weighted): 0.6255\tVal F1 (Macro): 0.5499\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 116\tTrain Loss: 1.01736\tVal Acc: 0.6427\tVal F1 (Weighted): 0.6249\tVal F1 (Macro): 0.5442\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 117\tTrain Loss: 1.01456\tVal Acc: 0.6435\tVal F1 (Weighted): 0.6256\tVal F1 (Macro): 0.5473\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 118\tTrain Loss: 1.01503\tVal Acc: 0.6436\tVal F1 (Weighted): 0.6261\tVal F1 (Macro): 0.5462\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 119\tTrain Loss: 1.01456\tVal Acc: 0.6439\tVal F1 (Weighted): 0.6263\tVal F1 (Macro): 0.5450\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 120\tTrain Loss: 1.01136\tVal Acc: 0.6433\tVal F1 (Weighted): 0.6273\tVal F1 (Macro): 0.5523\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 121\tTrain Loss: 1.00969\tVal Acc: 0.6446\tVal F1 (Weighted): 0.6275\tVal F1 (Macro): 0.5517\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 122\tTrain Loss: 1.01209\tVal Acc: 0.6441\tVal F1 (Weighted): 0.6284\tVal F1 (Macro): 0.5531\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 123\tTrain Loss: 1.00726\tVal Acc: 0.6445\tVal F1 (Weighted): 0.6279\tVal F1 (Macro): 0.5504\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 124\tTrain Loss: 1.00568\tVal Acc: 0.6451\tVal F1 (Weighted): 0.6287\tVal F1 (Macro): 0.5493\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 125\tTrain Loss: 1.00474\tVal Acc: 0.6463\tVal F1 (Weighted): 0.6291\tVal F1 (Macro): 0.5497\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 126\tTrain Loss: 1.00393\tVal Acc: 0.6452\tVal F1 (Weighted): 0.6284\tVal F1 (Macro): 0.5524\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 127\tTrain Loss: 1.00397\tVal Acc: 0.6435\tVal F1 (Weighted): 0.6289\tVal F1 (Macro): 0.5559\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 128\tTrain Loss: 1.00237\tVal Acc: 0.6464\tVal F1 (Weighted): 0.6303\tVal F1 (Macro): 0.5560\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 129\tTrain Loss: 1.00084\tVal Acc: 0.6465\tVal F1 (Weighted): 0.6305\tVal F1 (Macro): 0.5566\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 130\tTrain Loss: 0.99867\tVal Acc: 0.6451\tVal F1 (Weighted): 0.6295\tVal F1 (Macro): 0.5525\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 131\tTrain Loss: 0.99769\tVal Acc: 0.6456\tVal F1 (Weighted): 0.6300\tVal F1 (Macro): 0.5563\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 132\tTrain Loss: 0.99752\tVal Acc: 0.6477\tVal F1 (Weighted): 0.6317\tVal F1 (Macro): 0.5566\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 133\tTrain Loss: 0.99669\tVal Acc: 0.6472\tVal F1 (Weighted): 0.6313\tVal F1 (Macro): 0.5566\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 134\tTrain Loss: 0.99311\tVal Acc: 0.6466\tVal F1 (Weighted): 0.6300\tVal F1 (Macro): 0.5502\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 135\tTrain Loss: 0.99300\tVal Acc: 0.6455\tVal F1 (Weighted): 0.6295\tVal F1 (Macro): 0.5521\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 136\tTrain Loss: 0.99303\tVal Acc: 0.6472\tVal F1 (Weighted): 0.6295\tVal F1 (Macro): 0.5492\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 137\tTrain Loss: 0.98994\tVal Acc: 0.6466\tVal F1 (Weighted): 0.6321\tVal F1 (Macro): 0.5595\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 138\tTrain Loss: 0.99144\tVal Acc: 0.6481\tVal F1 (Weighted): 0.6325\tVal F1 (Macro): 0.5566\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 139\tTrain Loss: 0.98877\tVal Acc: 0.6462\tVal F1 (Weighted): 0.6312\tVal F1 (Macro): 0.5545\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 140\tTrain Loss: 0.98750\tVal Acc: 0.6480\tVal F1 (Weighted): 0.6319\tVal F1 (Macro): 0.5560\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 141\tTrain Loss: 0.98533\tVal Acc: 0.6491\tVal F1 (Weighted): 0.6341\tVal F1 (Macro): 0.5617\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 142\tTrain Loss: 0.98572\tVal Acc: 0.6473\tVal F1 (Weighted): 0.6307\tVal F1 (Macro): 0.5531\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 143\tTrain Loss: 0.98427\tVal Acc: 0.6491\tVal F1 (Weighted): 0.6333\tVal F1 (Macro): 0.5601\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 144\tTrain Loss: 0.98296\tVal Acc: 0.6496\tVal F1 (Weighted): 0.6334\tVal F1 (Macro): 0.5570\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 145\tTrain Loss: 0.98360\tVal Acc: 0.6494\tVal F1 (Weighted): 0.6337\tVal F1 (Macro): 0.5576\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 146\tTrain Loss: 0.98135\tVal Acc: 0.6480\tVal F1 (Weighted): 0.6328\tVal F1 (Macro): 0.5575\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 147\tTrain Loss: 0.97918\tVal Acc: 0.6477\tVal F1 (Weighted): 0.6324\tVal F1 (Macro): 0.5598\tNo Improve Epochs: 6\n",
      "  [Trial 2] Epoch 148\tTrain Loss: 0.98160\tVal Acc: 0.6486\tVal F1 (Weighted): 0.6353\tVal F1 (Macro): 0.5613\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 149\tTrain Loss: 0.97734\tVal Acc: 0.6492\tVal F1 (Weighted): 0.6342\tVal F1 (Macro): 0.5605\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 150\tTrain Loss: 0.97874\tVal Acc: 0.6481\tVal F1 (Weighted): 0.6340\tVal F1 (Macro): 0.5598\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 151\tTrain Loss: 0.97733\tVal Acc: 0.6499\tVal F1 (Weighted): 0.6347\tVal F1 (Macro): 0.5585\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 152\tTrain Loss: 0.97227\tVal Acc: 0.6499\tVal F1 (Weighted): 0.6343\tVal F1 (Macro): 0.5592\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 153\tTrain Loss: 0.97370\tVal Acc: 0.6494\tVal F1 (Weighted): 0.6340\tVal F1 (Macro): 0.5587\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 154\tTrain Loss: 0.97080\tVal Acc: 0.6497\tVal F1 (Weighted): 0.6343\tVal F1 (Macro): 0.5574\tNo Improve Epochs: 6\n",
      "  [Trial 2] Epoch 155\tTrain Loss: 0.97036\tVal Acc: 0.6505\tVal F1 (Weighted): 0.6355\tVal F1 (Macro): 0.5607\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 156\tTrain Loss: 0.97136\tVal Acc: 0.6484\tVal F1 (Weighted): 0.6335\tVal F1 (Macro): 0.5573\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 157\tTrain Loss: 0.97100\tVal Acc: 0.6504\tVal F1 (Weighted): 0.6365\tVal F1 (Macro): 0.5619\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 158\tTrain Loss: 0.96875\tVal Acc: 0.6507\tVal F1 (Weighted): 0.6356\tVal F1 (Macro): 0.5592\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 159\tTrain Loss: 0.97032\tVal Acc: 0.6498\tVal F1 (Weighted): 0.6345\tVal F1 (Macro): 0.5571\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 160\tTrain Loss: 0.96841\tVal Acc: 0.6506\tVal F1 (Weighted): 0.6358\tVal F1 (Macro): 0.5595\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 161\tTrain Loss: 0.96990\tVal Acc: 0.6507\tVal F1 (Weighted): 0.6360\tVal F1 (Macro): 0.5635\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 162\tTrain Loss: 0.96571\tVal Acc: 0.6501\tVal F1 (Weighted): 0.6366\tVal F1 (Macro): 0.5622\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 163\tTrain Loss: 0.96554\tVal Acc: 0.6510\tVal F1 (Weighted): 0.6359\tVal F1 (Macro): 0.5617\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 164\tTrain Loss: 0.96572\tVal Acc: 0.6516\tVal F1 (Weighted): 0.6377\tVal F1 (Macro): 0.5610\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 165\tTrain Loss: 0.96315\tVal Acc: 0.6515\tVal F1 (Weighted): 0.6359\tVal F1 (Macro): 0.5592\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 166\tTrain Loss: 0.96438\tVal Acc: 0.6513\tVal F1 (Weighted): 0.6375\tVal F1 (Macro): 0.5635\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 167\tTrain Loss: 0.96209\tVal Acc: 0.6506\tVal F1 (Weighted): 0.6366\tVal F1 (Macro): 0.5604\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 168\tTrain Loss: 0.96367\tVal Acc: 0.6502\tVal F1 (Weighted): 0.6372\tVal F1 (Macro): 0.5647\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 169\tTrain Loss: 0.96272\tVal Acc: 0.6510\tVal F1 (Weighted): 0.6351\tVal F1 (Macro): 0.5578\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 170\tTrain Loss: 0.96050\tVal Acc: 0.6518\tVal F1 (Weighted): 0.6372\tVal F1 (Macro): 0.5627\tNo Improve Epochs: 6\n",
      "  [Trial 2] Epoch 171\tTrain Loss: 0.96034\tVal Acc: 0.6503\tVal F1 (Weighted): 0.6365\tVal F1 (Macro): 0.5609\tNo Improve Epochs: 7\n",
      "  [Trial 2] Epoch 172\tTrain Loss: 0.95829\tVal Acc: 0.6510\tVal F1 (Weighted): 0.6367\tVal F1 (Macro): 0.5657\tNo Improve Epochs: 8\n",
      "  [Trial 2] Epoch 173\tTrain Loss: 0.95864\tVal Acc: 0.6519\tVal F1 (Weighted): 0.6370\tVal F1 (Macro): 0.5611\tNo Improve Epochs: 9\n",
      "  [Trial 2] Epoch 174\tTrain Loss: 0.95840\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6373\tVal F1 (Macro): 0.5608\tNo Improve Epochs: 10\n",
      "  [Trial 2] Epoch 175\tTrain Loss: 0.95724\tVal Acc: 0.6519\tVal F1 (Weighted): 0.6373\tVal F1 (Macro): 0.5609\tNo Improve Epochs: 11\n",
      "  [Trial 2] Epoch 176\tTrain Loss: 0.95702\tVal Acc: 0.6519\tVal F1 (Weighted): 0.6386\tVal F1 (Macro): 0.5627\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 177\tTrain Loss: 0.95788\tVal Acc: 0.6509\tVal F1 (Weighted): 0.6371\tVal F1 (Macro): 0.5630\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 178\tTrain Loss: 0.95715\tVal Acc: 0.6505\tVal F1 (Weighted): 0.6364\tVal F1 (Macro): 0.5627\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 179\tTrain Loss: 0.95535\tVal Acc: 0.6504\tVal F1 (Weighted): 0.6366\tVal F1 (Macro): 0.5623\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 180\tTrain Loss: 0.95258\tVal Acc: 0.6508\tVal F1 (Weighted): 0.6372\tVal F1 (Macro): 0.5626\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 181\tTrain Loss: 0.95457\tVal Acc: 0.6514\tVal F1 (Weighted): 0.6377\tVal F1 (Macro): 0.5637\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 182\tTrain Loss: 0.95574\tVal Acc: 0.6519\tVal F1 (Weighted): 0.6366\tVal F1 (Macro): 0.5617\tNo Improve Epochs: 6\n",
      "  [Trial 2] Epoch 183\tTrain Loss: 0.95282\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6375\tVal F1 (Macro): 0.5631\tNo Improve Epochs: 7\n",
      "  [Trial 2] Epoch 184\tTrain Loss: 0.95419\tVal Acc: 0.6506\tVal F1 (Weighted): 0.6366\tVal F1 (Macro): 0.5630\tNo Improve Epochs: 8\n",
      "  [Trial 2] Epoch 185\tTrain Loss: 0.95322\tVal Acc: 0.6512\tVal F1 (Weighted): 0.6375\tVal F1 (Macro): 0.5640\tNo Improve Epochs: 9\n",
      "  [Trial 2] Epoch 186\tTrain Loss: 0.95263\tVal Acc: 0.6518\tVal F1 (Weighted): 0.6372\tVal F1 (Macro): 0.5616\tNo Improve Epochs: 10\n",
      "  [Trial 2] Epoch 187\tTrain Loss: 0.95367\tVal Acc: 0.6514\tVal F1 (Weighted): 0.6372\tVal F1 (Macro): 0.5624\tNo Improve Epochs: 11\n",
      "  [Trial 2] Epoch 188\tTrain Loss: 0.95072\tVal Acc: 0.6517\tVal F1 (Weighted): 0.6378\tVal F1 (Macro): 0.5642\tNo Improve Epochs: 12\n",
      "  [Trial 2] Epoch 189\tTrain Loss: 0.95081\tVal Acc: 0.6510\tVal F1 (Weighted): 0.6368\tVal F1 (Macro): 0.5649\tNo Improve Epochs: 13\n",
      "  [Trial 2] Epoch 190\tTrain Loss: 0.95289\tVal Acc: 0.6505\tVal F1 (Weighted): 0.6369\tVal F1 (Macro): 0.5615\tNo Improve Epochs: 14\n",
      "  [Trial 2] Epoch 191\tTrain Loss: 0.94994\tVal Acc: 0.6529\tVal F1 (Weighted): 0.6390\tVal F1 (Macro): 0.5648\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 192\tTrain Loss: 0.94902\tVal Acc: 0.6516\tVal F1 (Weighted): 0.6372\tVal F1 (Macro): 0.5626\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 193\tTrain Loss: 0.95067\tVal Acc: 0.6513\tVal F1 (Weighted): 0.6371\tVal F1 (Macro): 0.5634\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 194\tTrain Loss: 0.95128\tVal Acc: 0.6527\tVal F1 (Weighted): 0.6383\tVal F1 (Macro): 0.5630\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 195\tTrain Loss: 0.94817\tVal Acc: 0.6523\tVal F1 (Weighted): 0.6379\tVal F1 (Macro): 0.5648\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 196\tTrain Loss: 0.94916\tVal Acc: 0.6520\tVal F1 (Weighted): 0.6389\tVal F1 (Macro): 0.5661\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 197\tTrain Loss: 0.94753\tVal Acc: 0.6522\tVal F1 (Weighted): 0.6390\tVal F1 (Macro): 0.5649\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 198\tTrain Loss: 0.94983\tVal Acc: 0.6524\tVal F1 (Weighted): 0.6378\tVal F1 (Macro): 0.5648\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 199\tTrain Loss: 0.94774\tVal Acc: 0.6524\tVal F1 (Weighted): 0.6389\tVal F1 (Macro): 0.5651\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 200\tTrain Loss: 0.94780\tVal Acc: 0.6526\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5652\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 201\tTrain Loss: 0.94855\tVal Acc: 0.6517\tVal F1 (Weighted): 0.6376\tVal F1 (Macro): 0.5621\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 202\tTrain Loss: 0.94750\tVal Acc: 0.6523\tVal F1 (Weighted): 0.6381\tVal F1 (Macro): 0.5642\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 203\tTrain Loss: 0.94844\tVal Acc: 0.6517\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5645\tNo Improve Epochs: 6\n",
      "  [Trial 2] Epoch 204\tTrain Loss: 0.94831\tVal Acc: 0.6523\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5657\tNo Improve Epochs: 7\n",
      "  [Trial 2] Epoch 205\tTrain Loss: 0.94795\tVal Acc: 0.6518\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5651\tNo Improve Epochs: 8\n",
      "  [Trial 2] Epoch 206\tTrain Loss: 0.94720\tVal Acc: 0.6515\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5645\tNo Improve Epochs: 9\n",
      "  [Trial 2] Epoch 207\tTrain Loss: 0.94907\tVal Acc: 0.6523\tVal F1 (Weighted): 0.6385\tVal F1 (Macro): 0.5653\tNo Improve Epochs: 10\n",
      "  [Trial 2] Epoch 208\tTrain Loss: 0.94756\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6385\tVal F1 (Macro): 0.5647\tNo Improve Epochs: 11\n",
      "  [Trial 2] Epoch 209\tTrain Loss: 0.94521\tVal Acc: 0.6517\tVal F1 (Weighted): 0.6382\tVal F1 (Macro): 0.5648\tNo Improve Epochs: 12\n",
      "  [Trial 2] Epoch 210\tTrain Loss: 0.94583\tVal Acc: 0.6527\tVal F1 (Weighted): 0.6391\tVal F1 (Macro): 0.5650\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 211\tTrain Loss: 0.94563\tVal Acc: 0.6521\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5652\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 212\tTrain Loss: 0.94442\tVal Acc: 0.6523\tVal F1 (Weighted): 0.6390\tVal F1 (Macro): 0.5645\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 213\tTrain Loss: 0.94512\tVal Acc: 0.6528\tVal F1 (Weighted): 0.6390\tVal F1 (Macro): 0.5658\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 214\tTrain Loss: 0.94423\tVal Acc: 0.6528\tVal F1 (Weighted): 0.6389\tVal F1 (Macro): 0.5658\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 215\tTrain Loss: 0.94537\tVal Acc: 0.6518\tVal F1 (Weighted): 0.6381\tVal F1 (Macro): 0.5647\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 216\tTrain Loss: 0.94589\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6388\tVal F1 (Macro): 0.5663\tNo Improve Epochs: 6\n",
      "  [Trial 2] Epoch 217\tTrain Loss: 0.94462\tVal Acc: 0.6521\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5653\tNo Improve Epochs: 7\n",
      "  [Trial 2] Epoch 218\tTrain Loss: 0.94298\tVal Acc: 0.6530\tVal F1 (Weighted): 0.6394\tVal F1 (Macro): 0.5658\tNo Improve Epochs: 0\n",
      "  [Trial 2] Epoch 219\tTrain Loss: 0.94421\tVal Acc: 0.6524\tVal F1 (Weighted): 0.6388\tVal F1 (Macro): 0.5653\tNo Improve Epochs: 1\n",
      "  [Trial 2] Epoch 220\tTrain Loss: 0.94395\tVal Acc: 0.6524\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5655\tNo Improve Epochs: 2\n",
      "  [Trial 2] Epoch 221\tTrain Loss: 0.94362\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6392\tVal F1 (Macro): 0.5661\tNo Improve Epochs: 3\n",
      "  [Trial 2] Epoch 222\tTrain Loss: 0.94304\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6383\tVal F1 (Macro): 0.5645\tNo Improve Epochs: 4\n",
      "  [Trial 2] Epoch 223\tTrain Loss: 0.94364\tVal Acc: 0.6524\tVal F1 (Weighted): 0.6390\tVal F1 (Macro): 0.5658\tNo Improve Epochs: 5\n",
      "  [Trial 2] Epoch 224\tTrain Loss: 0.94225\tVal Acc: 0.6524\tVal F1 (Weighted): 0.6388\tVal F1 (Macro): 0.5657\tNo Improve Epochs: 6\n",
      "  [Trial 2] Epoch 225\tTrain Loss: 0.94077\tVal Acc: 0.6522\tVal F1 (Weighted): 0.6388\tVal F1 (Macro): 0.5651\tNo Improve Epochs: 7\n",
      "  [Trial 2] Epoch 226\tTrain Loss: 0.94353\tVal Acc: 0.6523\tVal F1 (Weighted): 0.6382\tVal F1 (Macro): 0.5646\tNo Improve Epochs: 8\n",
      "  [Trial 2] Epoch 227\tTrain Loss: 0.94165\tVal Acc: 0.6529\tVal F1 (Weighted): 0.6392\tVal F1 (Macro): 0.5655\tNo Improve Epochs: 9\n",
      "  [Trial 2] Epoch 228\tTrain Loss: 0.94360\tVal Acc: 0.6521\tVal F1 (Weighted): 0.6390\tVal F1 (Macro): 0.5650\tNo Improve Epochs: 10\n",
      "  [Trial 2] Epoch 229\tTrain Loss: 0.94361\tVal Acc: 0.6522\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5647\tNo Improve Epochs: 11\n",
      "  [Trial 2] Epoch 230\tTrain Loss: 0.94104\tVal Acc: 0.6526\tVal F1 (Weighted): 0.6392\tVal F1 (Macro): 0.5653\tNo Improve Epochs: 12\n",
      "  [Trial 2] Epoch 231\tTrain Loss: 0.94385\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6385\tVal F1 (Macro): 0.5654\tNo Improve Epochs: 13\n",
      "  [Trial 2] Epoch 232\tTrain Loss: 0.94094\tVal Acc: 0.6522\tVal F1 (Weighted): 0.6389\tVal F1 (Macro): 0.5650\tNo Improve Epochs: 14\n",
      "  [Trial 2] Epoch 233\tTrain Loss: 0.93904\tVal Acc: 0.6525\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5649\tNo Improve Epochs: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-09 23:30:15,767] Trial 2 finished with value: 0.6394183762195852 and parameters: {'embedding_dim': 128, 'hidden_dim': 128, 'n_layers': 2, 'n_heads': 16, 'dropout_p': 0.30000000000000004, 'learning_rate': 2.024947513625317e-05, 'warmup_epochs': 14, 'patience': 16, 'use_class_weights': False}. Best is trial 1 with value: 0.639486902775119.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 2] Epoch 234\tTrain Loss: 0.94079\tVal Acc: 0.6520\tVal F1 (Weighted): 0.6382\tVal F1 (Macro): 0.5643\tNo Improve Epochs: 16\n",
      "조기 종료: 16 에포크 동안 성능 개선 없음. Trial 2 종료.\n",
      "Trial 3: 클래스 가중치 미사용.\n",
      "  [Trial 3] TensorBoard 로그 디렉토리: optuna_runs\\v2\\trial_3_params_emb256_heads16_lr4.3e-05_cwFalse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19932\\2319572601.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 5e-6, 5e-5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 3] Epoch 1\tTrain Loss: 1.66925\tVal Acc: 0.4460\tVal F1 (Weighted): 0.3158\tVal F1 (Macro): 0.1614\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 2\tTrain Loss: 1.56422\tVal Acc: 0.4465\tVal F1 (Weighted): 0.3293\tVal F1 (Macro): 0.1884\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 3\tTrain Loss: 1.51386\tVal Acc: 0.4628\tVal F1 (Weighted): 0.3546\tVal F1 (Macro): 0.2196\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 4\tTrain Loss: 1.45481\tVal Acc: 0.5022\tVal F1 (Weighted): 0.4224\tVal F1 (Macro): 0.3071\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 5\tTrain Loss: 1.37841\tVal Acc: 0.5380\tVal F1 (Weighted): 0.4867\tVal F1 (Macro): 0.3871\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 6\tTrain Loss: 1.30618\tVal Acc: 0.5635\tVal F1 (Weighted): 0.5212\tVal F1 (Macro): 0.4313\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 7\tTrain Loss: 1.24805\tVal Acc: 0.5837\tVal F1 (Weighted): 0.5534\tVal F1 (Macro): 0.4692\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 8\tTrain Loss: 1.20577\tVal Acc: 0.5932\tVal F1 (Weighted): 0.5579\tVal F1 (Macro): 0.4772\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 9\tTrain Loss: 1.16742\tVal Acc: 0.6063\tVal F1 (Weighted): 0.5759\tVal F1 (Macro): 0.4919\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 10\tTrain Loss: 1.14090\tVal Acc: 0.6121\tVal F1 (Weighted): 0.5894\tVal F1 (Macro): 0.5126\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 11\tTrain Loss: 1.11216\tVal Acc: 0.6238\tVal F1 (Weighted): 0.6008\tVal F1 (Macro): 0.5261\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 12\tTrain Loss: 1.09036\tVal Acc: 0.6273\tVal F1 (Weighted): 0.6005\tVal F1 (Macro): 0.5134\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 13\tTrain Loss: 1.07252\tVal Acc: 0.6297\tVal F1 (Weighted): 0.6104\tVal F1 (Macro): 0.5317\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 14\tTrain Loss: 1.04912\tVal Acc: 0.6296\tVal F1 (Weighted): 0.6168\tVal F1 (Macro): 0.5411\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 15\tTrain Loss: 1.03533\tVal Acc: 0.6351\tVal F1 (Weighted): 0.6177\tVal F1 (Macro): 0.5346\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 16\tTrain Loss: 1.01759\tVal Acc: 0.6369\tVal F1 (Weighted): 0.6230\tVal F1 (Macro): 0.5437\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 17\tTrain Loss: 1.00328\tVal Acc: 0.6361\tVal F1 (Weighted): 0.6271\tVal F1 (Macro): 0.5539\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 18\tTrain Loss: 0.99104\tVal Acc: 0.6394\tVal F1 (Weighted): 0.6277\tVal F1 (Macro): 0.5557\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 19\tTrain Loss: 0.97701\tVal Acc: 0.6433\tVal F1 (Weighted): 0.6254\tVal F1 (Macro): 0.5431\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 20\tTrain Loss: 0.96680\tVal Acc: 0.6466\tVal F1 (Weighted): 0.6337\tVal F1 (Macro): 0.5652\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 21\tTrain Loss: 0.95615\tVal Acc: 0.6494\tVal F1 (Weighted): 0.6369\tVal F1 (Macro): 0.5691\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 22\tTrain Loss: 0.94322\tVal Acc: 0.6450\tVal F1 (Weighted): 0.6310\tVal F1 (Macro): 0.5602\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 23\tTrain Loss: 0.93452\tVal Acc: 0.6474\tVal F1 (Weighted): 0.6339\tVal F1 (Macro): 0.5600\tNo Improve Epochs: 2\n",
      "  [Trial 3] Epoch 24\tTrain Loss: 0.92528\tVal Acc: 0.6511\tVal F1 (Weighted): 0.6374\tVal F1 (Macro): 0.5599\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 25\tTrain Loss: 0.91565\tVal Acc: 0.6503\tVal F1 (Weighted): 0.6398\tVal F1 (Macro): 0.5715\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 26\tTrain Loss: 0.90810\tVal Acc: 0.6431\tVal F1 (Weighted): 0.6357\tVal F1 (Macro): 0.5576\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 27\tTrain Loss: 0.89775\tVal Acc: 0.6489\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5713\tNo Improve Epochs: 2\n",
      "  [Trial 3] Epoch 28\tTrain Loss: 0.88929\tVal Acc: 0.6501\tVal F1 (Weighted): 0.6404\tVal F1 (Macro): 0.5709\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 29\tTrain Loss: 0.88001\tVal Acc: 0.6521\tVal F1 (Weighted): 0.6421\tVal F1 (Macro): 0.5717\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 30\tTrain Loss: 0.87176\tVal Acc: 0.6527\tVal F1 (Weighted): 0.6412\tVal F1 (Macro): 0.5666\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 31\tTrain Loss: 0.86318\tVal Acc: 0.6526\tVal F1 (Weighted): 0.6396\tVal F1 (Macro): 0.5633\tNo Improve Epochs: 2\n",
      "  [Trial 3] Epoch 32\tTrain Loss: 0.85778\tVal Acc: 0.6530\tVal F1 (Weighted): 0.6419\tVal F1 (Macro): 0.5724\tNo Improve Epochs: 3\n",
      "  [Trial 3] Epoch 33\tTrain Loss: 0.84785\tVal Acc: 0.6492\tVal F1 (Weighted): 0.6416\tVal F1 (Macro): 0.5725\tNo Improve Epochs: 4\n",
      "  [Trial 3] Epoch 34\tTrain Loss: 0.84124\tVal Acc: 0.6517\tVal F1 (Weighted): 0.6431\tVal F1 (Macro): 0.5765\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 35\tTrain Loss: 0.83425\tVal Acc: 0.6526\tVal F1 (Weighted): 0.6413\tVal F1 (Macro): 0.5642\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 36\tTrain Loss: 0.82443\tVal Acc: 0.6531\tVal F1 (Weighted): 0.6443\tVal F1 (Macro): 0.5759\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 37\tTrain Loss: 0.81902\tVal Acc: 0.6486\tVal F1 (Weighted): 0.6421\tVal F1 (Macro): 0.5695\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 38\tTrain Loss: 0.81118\tVal Acc: 0.6475\tVal F1 (Weighted): 0.6424\tVal F1 (Macro): 0.5694\tNo Improve Epochs: 2\n",
      "  [Trial 3] Epoch 39\tTrain Loss: 0.80677\tVal Acc: 0.6526\tVal F1 (Weighted): 0.6448\tVal F1 (Macro): 0.5773\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 40\tTrain Loss: 0.79415\tVal Acc: 0.6538\tVal F1 (Weighted): 0.6420\tVal F1 (Macro): 0.5739\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 41\tTrain Loss: 0.79039\tVal Acc: 0.6518\tVal F1 (Weighted): 0.6422\tVal F1 (Macro): 0.5713\tNo Improve Epochs: 2\n",
      "  [Trial 3] Epoch 42\tTrain Loss: 0.78150\tVal Acc: 0.6497\tVal F1 (Weighted): 0.6418\tVal F1 (Macro): 0.5751\tNo Improve Epochs: 3\n",
      "  [Trial 3] Epoch 43\tTrain Loss: 0.77478\tVal Acc: 0.6430\tVal F1 (Weighted): 0.6391\tVal F1 (Macro): 0.5740\tNo Improve Epochs: 4\n",
      "  [Trial 3] Epoch 44\tTrain Loss: 0.76915\tVal Acc: 0.6502\tVal F1 (Weighted): 0.6447\tVal F1 (Macro): 0.5766\tNo Improve Epochs: 5\n",
      "  [Trial 3] Epoch 45\tTrain Loss: 0.76018\tVal Acc: 0.6496\tVal F1 (Weighted): 0.6412\tVal F1 (Macro): 0.5700\tNo Improve Epochs: 6\n",
      "  [Trial 3] Epoch 46\tTrain Loss: 0.74483\tVal Acc: 0.6528\tVal F1 (Weighted): 0.6449\tVal F1 (Macro): 0.5756\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 47\tTrain Loss: 0.74210\tVal Acc: 0.6444\tVal F1 (Weighted): 0.6389\tVal F1 (Macro): 0.5740\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 48\tTrain Loss: 0.73671\tVal Acc: 0.6458\tVal F1 (Weighted): 0.6423\tVal F1 (Macro): 0.5789\tNo Improve Epochs: 2\n",
      "  [Trial 3] Epoch 49\tTrain Loss: 0.73234\tVal Acc: 0.6437\tVal F1 (Weighted): 0.6387\tVal F1 (Macro): 0.5722\tNo Improve Epochs: 3\n",
      "  [Trial 3] Epoch 50\tTrain Loss: 0.72286\tVal Acc: 0.6544\tVal F1 (Weighted): 0.6471\tVal F1 (Macro): 0.5819\tNo Improve Epochs: 0\n",
      "  [Trial 3] Epoch 51\tTrain Loss: 0.71892\tVal Acc: 0.6487\tVal F1 (Weighted): 0.6441\tVal F1 (Macro): 0.5806\tNo Improve Epochs: 1\n",
      "  [Trial 3] Epoch 52\tTrain Loss: 0.71177\tVal Acc: 0.6429\tVal F1 (Weighted): 0.6402\tVal F1 (Macro): 0.5759\tNo Improve Epochs: 2\n",
      "  [Trial 3] Epoch 53\tTrain Loss: 0.70834\tVal Acc: 0.6475\tVal F1 (Weighted): 0.6389\tVal F1 (Macro): 0.5611\tNo Improve Epochs: 3\n",
      "  [Trial 3] Epoch 54\tTrain Loss: 0.70131\tVal Acc: 0.6503\tVal F1 (Weighted): 0.6437\tVal F1 (Macro): 0.5801\tNo Improve Epochs: 4\n",
      "  [Trial 3] Epoch 55\tTrain Loss: 0.69618\tVal Acc: 0.6479\tVal F1 (Weighted): 0.6438\tVal F1 (Macro): 0.5792\tNo Improve Epochs: 5\n",
      "  [Trial 3] Epoch 56\tTrain Loss: 0.69139\tVal Acc: 0.6460\tVal F1 (Weighted): 0.6433\tVal F1 (Macro): 0.5780\tNo Improve Epochs: 6\n",
      "  [Trial 3] Epoch 57\tTrain Loss: 0.68112\tVal Acc: 0.6459\tVal F1 (Weighted): 0.6418\tVal F1 (Macro): 0.5773\tNo Improve Epochs: 7\n",
      "  [Trial 3] Epoch 58\tTrain Loss: 0.67496\tVal Acc: 0.6489\tVal F1 (Weighted): 0.6416\tVal F1 (Macro): 0.5747\tNo Improve Epochs: 8\n",
      "  [Trial 3] Epoch 59\tTrain Loss: 0.66892\tVal Acc: 0.6471\tVal F1 (Weighted): 0.6432\tVal F1 (Macro): 0.5791\tNo Improve Epochs: 9\n",
      "  [Trial 3] Epoch 60\tTrain Loss: 0.66608\tVal Acc: 0.6413\tVal F1 (Weighted): 0.6384\tVal F1 (Macro): 0.5744\tNo Improve Epochs: 10\n",
      "  [Trial 3] Epoch 61\tTrain Loss: 0.66240\tVal Acc: 0.6472\tVal F1 (Weighted): 0.6427\tVal F1 (Macro): 0.5803\tNo Improve Epochs: 11\n",
      "  [Trial 3] Epoch 62\tTrain Loss: 0.65949\tVal Acc: 0.6485\tVal F1 (Weighted): 0.6436\tVal F1 (Macro): 0.5776\tNo Improve Epochs: 12\n",
      "  [Trial 3] Epoch 63\tTrain Loss: 0.65089\tVal Acc: 0.6462\tVal F1 (Weighted): 0.6428\tVal F1 (Macro): 0.5783\tNo Improve Epochs: 13\n",
      "  [Trial 3] Epoch 64\tTrain Loss: 0.64705\tVal Acc: 0.6436\tVal F1 (Weighted): 0.6410\tVal F1 (Macro): 0.5765\tNo Improve Epochs: 14\n",
      "  [Trial 3] Epoch 65\tTrain Loss: 0.64117\tVal Acc: 0.6446\tVal F1 (Weighted): 0.6403\tVal F1 (Macro): 0.5758\tNo Improve Epochs: 15\n",
      "  [Trial 3] Epoch 66\tTrain Loss: 0.63739\tVal Acc: 0.6434\tVal F1 (Weighted): 0.6392\tVal F1 (Macro): 0.5760\tNo Improve Epochs: 16\n",
      "  [Trial 3] Epoch 67\tTrain Loss: 0.63726\tVal Acc: 0.6510\tVal F1 (Weighted): 0.6435\tVal F1 (Macro): 0.5771\tNo Improve Epochs: 17\n",
      "  [Trial 3] Epoch 68\tTrain Loss: 0.63250\tVal Acc: 0.6399\tVal F1 (Weighted): 0.6370\tVal F1 (Macro): 0.5740\tNo Improve Epochs: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-10 01:03:19,927] Trial 3 finished with value: 0.6471016727207676 and parameters: {'embedding_dim': 256, 'hidden_dim': 256, 'n_layers': 4, 'n_heads': 16, 'dropout_p': 0.2, 'learning_rate': 4.267030055500867e-05, 'warmup_epochs': 13, 'patience': 19, 'use_class_weights': False}. Best is trial 3 with value: 0.6471016727207676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 3] Epoch 69\tTrain Loss: 0.61875\tVal Acc: 0.6408\tVal F1 (Weighted): 0.6385\tVal F1 (Macro): 0.5736\tNo Improve Epochs: 19\n",
      "조기 종료: 19 에포크 동안 성능 개선 없음. Trial 3 종료.\n",
      "Trial 4: 계산된 클래스 가중치: [9.46429443359375, 10.485962867736816, 7.630941867828369, 5.603141784667969, 2.8589727878570557, 10.10208511352539, 24.574878692626953]\n",
      "  [Trial 4] TensorBoard 로그 디렉토리: optuna_runs\\v2\\trial_4_params_emb256_heads16_lr1.2e-05_cwTrue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19932\\2319572601.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 5e-6, 5e-5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Trial 4] Epoch 1\tTrain Loss: 1.95281\tVal Acc: 0.3524\tVal F1 (Weighted): 0.3328\tVal F1 (Macro): 0.2182\tNo Improve Epochs: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-07-10 01:04:45,046] Trial 4 failed with parameters: {'embedding_dim': 256, 'hidden_dim': 128, 'n_layers': 4, 'n_heads': 16, 'dropout_p': 0.2, 'learning_rate': 1.2234684762261562e-05, 'warmup_epochs': 10, 'patience': 11, 'use_class_weights': True} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\envs\\tensor\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19932\\2319572601.py\", line 54, in objective\n",
      "    val_f1_weighted = Transformer_Train(\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19932\\2591231837.py\", line 29, in Transformer_Train\n",
      "    total_loss += loss.item()\n",
      "KeyboardInterrupt\n",
      "[W 2025-07-10 01:04:45,052] Trial 4 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m      2\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(),\n\u001b[0;32m      4\u001b[0m     pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mMedianPruner(n_startup_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, interval_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptuna 최적화 시작...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Optuna 최적화 결과 ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m최적의 하이퍼파라미터 조합 (Best Trial): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\optuna\\study\\study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    252\u001b[0m ):\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensor\\lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[4], line 54\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     51\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(log_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(save_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 54\u001b[0m val_f1_weighted \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer_Train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_plateau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_plateau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_f1_weighted\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36mTransformer_Train\u001b[1;34m(epoch, device, train_loader, val_loader, NN, loss_function, optimizer, scheduler_plateau, warmup_epochs, log_dir, save_path, patience, trial)\u001b[0m\n\u001b[0;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 29\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[0;32m     32\u001b[0m NN\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Optuna Study 저장 폴더 및 파일 경로 설정\n",
    "OPTUNA_STORAGE_DIR = 'Optuna_Storage'\n",
    "STUDY_SAVE_PATH = os.path.join(OPTUNA_STORAGE_DIR, 'optuna_study.pkl')\n",
    "\n",
    "# Optuna 저장 폴더가 없다면 생성\n",
    "os.makedirs(OPTUNA_STORAGE_DIR, exist_ok=True)\n",
    "\n",
    "# Study 객체를 저장할 변수 미리 선언\n",
    "study = None\n",
    "\n",
    "# 이전에 저장된 Study가 있는지 확인하고 로드\n",
    "if os.path.exists(STUDY_SAVE_PATH):\n",
    "    print(f\"이전 Study '{STUDY_SAVE_PATH}'를 로드합니다...\")\n",
    "    try:\n",
    "        study = joblib.load(STUDY_SAVE_PATH)\n",
    "        print(f\"Study 로드 완료. 현재 {len(study.trials)}개의 트라이얼 기록이 있습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Study 로드 중 오류 발생: {e}. 새로운 Study를 생성합니다.\")\n",
    "        # 로드 실패 시 새로운 Study 생성\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            sampler=optuna.samplers.TPESampler(),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=30, interval_steps=10)\n",
    "        )\n",
    "else:\n",
    "    print(f\"저장된 Study 파일이 없습니다. 새로운 Study를 생성합니다.\")\n",
    "    # 저장된 파일이 없다면 새로운 Study 생성\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(),\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=30, interval_steps=10)\n",
    "    )\n",
    "\n",
    "print(\"Optuna 최적화 시작...\")\n",
    "# 최적화 실행\n",
    "# n_trials는 추가로 실행할 횟수를 의미합니다.\n",
    "# 만약 이미 5개의 트라이얼을 실행했고, 총 10개를 하고 싶다면 n_trials=5로 다시 호출합니다.\n",
    "study.optimize(objeㄹctive, n_trials=5)\n",
    "\n",
    "# 최적화가 끝난 후 Study 객체 저장\n",
    "print(f\"최적화 결과를 '{STUDY_SAVE_PATH}'에 저장합니다...\")\n",
    "joblib.dump(study, STUDY_SAVE_PATH)\n",
    "print(\"Study 저장 완료.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Optuna 최적화 결과 ---\")\n",
    "print(f\"최적의 하이퍼파라미터 조합 (Best Trial): {study.best_trial.params}\")\n",
    "print(f\"최적의 검증 Weighted F1 (Best Value): {study.best_trial.value:.4f}\")\n",
    "\n",
    "print(\"\\n--- 모든 시도 결과 ---\")\n",
    "for i, trial in enumerate(study.trials):\n",
    "    print(f\"Trial {i}: Value={trial.value:.4f}, Params={trial.params}, State={trial.state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb961e-a06f-4007-8406-2623fa7ac1c8",
   "metadata": {},
   "source": [
    "> tensorboard --logdir optuna_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5b1c00-0d10-43e9-8cfa-c8c131c0765a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적화 결과를 'Optuna_Storage\\optuna_study.pkl'에 저장합니다...\n",
      "Study 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "OPTUNA_STORAGE_DIR = 'Optuna_Storage'\n",
    "STUDY_SAVE_PATH = os.path.join(OPTUNA_STORAGE_DIR, 'optuna_study.pkl')\n",
    "\n",
    "# Optuna 저장 폴더가 없다면 생성\n",
    "os.makedirs(OPTUNA_STORAGE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"최적화 결과를 '{STUDY_SAVE_PATH}'에 저장합니다...\")\n",
    "joblib.dump(study, STUDY_SAVE_PATH)\n",
    "print(\"Study 저장 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805dd5cc-b52c-4ba3-a837-0a80e8d611f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
